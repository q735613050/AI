{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.regularizers import l2\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import load_model\n",
    "from keras.models import model_from_json\n",
    "\n",
    "import pydot\n",
    "import graphviz\n",
    "import scipy.misc\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "\n",
    "import pickle\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils import np_utils \n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from keras.utils.training_utils import multi_gpu_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)\n",
    "from keras.utils import to_categorical\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + '~/anaconda3/lib/bin/pydot/'\n",
    "os.environ[\"PATH\"] += os.pathsep + '~/anaconda3/lib/bin/graphviz/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking GPU settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 5880965095158818871\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 11286970368\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 6682384220751552359\n",
      "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7\"\n",
      "]\n"
     ] 
    }
   ],
   "source": [
    "#LIsting available devices \n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using AWS p2 instance with 1 gpu and 4 cpus \n",
    "config = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU': 4},log_device_placement=True ) \n",
    "sess = tf.Session(config=config) \n",
    "keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X train:  (50000, 32, 32, 3)\n",
      "Shape of Y train:  (50000, 10)\n",
      "Shape of X test:  (10000, 32, 32, 3)\n",
      "Shape of Y test:  (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.load('X_train.npy')\n",
    "Y_train = np.load('Y_train.npy')\n",
    "X_test = np.load('X_test.npy')\n",
    "Y_test = np.load('Y_test.npy')\n",
    "\n",
    "#One hot encoding Y \n",
    "Y_train = to_categorical(Y_train)\n",
    "Y_test = to_categorical(Y_test)\n",
    "\n",
    "print('Shape of X train: ',X_train.shape)\n",
    "print('Shape of Y train: ',Y_train.shape)\n",
    "print('Shape of X test: ',X_test.shape)\n",
    "print('Shape of Y test: ',Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coursera deeplearning.ai specialization assignment code as completed and modified for resnet version 1\n",
    "\n",
    "def identity_block(X, filters, stage, block):\n",
    "    \"\"\"\n",
    "    Implementation of the identity block where the input skips over one convolutional layer\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    stage -- integer, used to name the layers, depending on their position in the network\n",
    "    block -- string/character, used to name the layers, depending on their position in the network\n",
    "    \n",
    "    Returns:\n",
    "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2 = filters\n",
    "    \n",
    "    # Save the input value. You'll need this later to add back to the main path. \n",
    "    X_shortcut = X\n",
    "    \n",
    "    # First component of main path\n",
    "    X = Conv2D(filters = F1, kernel_size = (3, 3), strides = (1,1), padding = 'same', name = conv_name_base + '2a', kernel_initializer ='he_normal',kernel_regularizer=l2(1e-4))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # Second component of main path (≈2 lines)\n",
    "    X = Conv2D(filters = F2, kernel_size = (3, 3), strides = (1,1), padding = 'same', name = conv_name_base + '2c', kernel_initializer ='he_normal',kernel_regularizer=l2(1e-4))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    X = Add()([X_shortcut,X])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coursera deeplearning.ai specialization assignment code as completed and modified for resnet version 1\n",
    "\n",
    "def convolutional_block(X,filters, stage, block):\n",
    "    \"\"\"\n",
    "    Implementation of the convolutional block in ResNet to reduce feature map size, increase number of filters\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    stage -- integer, used to name the layers, depending on their position in the network\n",
    "    block -- string/character, used to name the layers, depending on their position in the network\n",
    "    \n",
    "    Returns:\n",
    "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2 = filters\n",
    "    \n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "\n",
    "    ##### MAIN PATH #####\n",
    "    # First component of main path \n",
    "    X = Conv2D(F1, (3, 3), strides = (2,2), name = conv_name_base + '2a',padding='same', kernel_initializer ='he_normal',kernel_regularizer=l2(1e-4))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Second component of main path (≈2 lines)\n",
    "    X = Conv2D(F2, (3, 3), strides = (1,1), name = conv_name_base + '2c',padding='same', kernel_initializer ='he_normal',kernel_regularizer=l2(1e-4))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
    "\n",
    "    #Shortcut path to match dimensions\n",
    "    X_shortcut = Conv2D(F2, (1, 1), strides = (2,2), name = conv_name_base + '1',padding='same' ,kernel_initializer ='he_normal',kernel_regularizer=l2(1e-4))(X_shortcut)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    X = Add()([X_shortcut,X])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet_v1(input_shape = (32, 32, 3), classes = 10):\n",
    "    \"\"\"\n",
    "    Implementation of the ResNet\n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "    classes -- integer, number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    X = X_input\n",
    "    \n",
    "    # Initial Convolutional layer\n",
    "    X = Conv2D(16, (3, 3), strides = (1, 1), name = 'conv1', padding = 'same', kernel_initializer='he_normal',kernel_regularizer=l2(1e-4))(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Stage 1 with three resnet blocks \n",
    "    X = identity_block(X,[16, 16], stage=1, block='a')\n",
    "    X = identity_block(X, [16, 16], stage=1, block='b')\n",
    "    X = identity_block(X, [16, 16], stage=1, block='c')\n",
    "\n",
    "    # Stage 2 : 1 convolutional and 2 identity blocks\n",
    "    X = convolutional_block(X, filters = [32, 32], stage = 2, block='a')\n",
    "    X = identity_block(X, [32, 32], stage=2, block='b')\n",
    "    X = identity_block(X, [32,32], stage=2, block='c')\n",
    "\n",
    "\n",
    "    # Stage 3: 1 convolutional and 2 identity blocks\n",
    "    X = convolutional_block(X, filters = [64, 64], stage = 3, block='a')\n",
    "    X = identity_block(X, [64,64], stage=3, block='b')\n",
    "    X = identity_block(X, [64,64], stage=3, block='c')\n",
    " \n",
    "\n",
    "    # AVGPOOL\n",
    "    X = AveragePooling2D(pool_size = (8,8), name='avg_pool')(X)\n",
    "\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer ='he_normal')(X)\n",
    "    \n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X, name='ResNet_v1')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 32, 32, 16)   448         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 32, 32, 16)   64          conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 16)   0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "res1a_branch2a (Conv2D)         (None, 32, 32, 16)   2320        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn1a_branch2a (BatchNormalizati (None, 32, 32, 16)   64          res1a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 16)   0           bn1a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res1a_branch2c (Conv2D)         (None, 32, 32, 16)   2320        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn1a_branch2c (BatchNormalizati (None, 32, 32, 16)   64          res1a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 32, 16)   0           activation_1[0][0]               \n",
      "                                                                 bn1a_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 16)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res1b_branch2a (Conv2D)         (None, 32, 32, 16)   2320        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn1b_branch2a (BatchNormalizati (None, 32, 32, 16)   64          res1b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 16)   0           bn1b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res1b_branch2c (Conv2D)         (None, 32, 32, 16)   2320        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn1b_branch2c (BatchNormalizati (None, 32, 32, 16)   64          res1b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 32, 32, 16)   0           activation_3[0][0]               \n",
      "                                                                 bn1b_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 16)   0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res1c_branch2a (Conv2D)         (None, 32, 32, 16)   2320        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn1c_branch2a (BatchNormalizati (None, 32, 32, 16)   64          res1c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 16)   0           bn1c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res1c_branch2c (Conv2D)         (None, 32, 32, 16)   2320        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn1c_branch2c (BatchNormalizati (None, 32, 32, 16)   64          res1c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 32, 32, 16)   0           activation_5[0][0]               \n",
      "                                                                 bn1c_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 16)   0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 16, 16, 32)   4640        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 16, 16, 32)   128         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 16, 32)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 16, 16, 32)   9248        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 16, 16, 32)   544         activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 16, 16, 32)   128         res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 16, 16, 32)   0           res2a_branch1[0][0]              \n",
      "                                                                 bn2a_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 32)   0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 16, 16, 32)   9248        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 16, 16, 32)   128         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 32)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 16, 16, 32)   9248        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 16, 16, 32)   128         res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 16, 16, 32)   0           activation_9[0][0]               \n",
      "                                                                 bn2b_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 32)   0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 16, 16, 32)   9248        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 16, 16, 32)   128         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16, 16, 32)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 16, 16, 32)   9248        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 16, 16, 32)   128         res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 16, 16, 32)   0           activation_11[0][0]              \n",
      "                                                                 bn2c_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 32)   0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 8, 8, 64)     18496       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 8, 8, 64)     256         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 8, 8, 64)     0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 8, 8, 64)     36928       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 8, 8, 64)     2112        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 8, 8, 64)     256         res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 8, 8, 64)     0           res3a_branch1[0][0]              \n",
      "                                                                 bn3a_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 8, 8, 64)     0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 8, 8, 64)     36928       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 8, 8, 64)     256         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 8, 8, 64)     0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 8, 8, 64)     36928       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 8, 8, 64)     256         res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 8, 8, 64)     0           activation_15[0][0]              \n",
      "                                                                 bn3b_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 8, 8, 64)     0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 8, 8, 64)     36928       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 8, 8, 64)     256         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 8, 8, 64)     0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 8, 8, 64)     36928       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 8, 8, 64)     256         res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 8, 8, 64)     0           activation_17[0][0]              \n",
      "                                                                 bn3c_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 8, 8, 64)     0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (AveragePooling2D)     (None, 1, 1, 64)     0           activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 64)           0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fc10 (Dense)                    (None, 10)           650         flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 274,442\n",
      "Trainable params: 273,066\n",
      "Non-trainable params: 1,376\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Number of gpus\n",
    "n_gpu = 1\n",
    "\n",
    "#Single GPU Training\n",
    "if n_gpu <=1:\n",
    "    model = ResNet_v1(input_shape = (32, 32, 3), classes = 10)\n",
    "\n",
    "#Multi GPU Training\n",
    "else:\n",
    "    with tf.device(\"/device:CPU:0\"):\n",
    "        model = ResNet_v1(input_shape = (32, 32, 3), classes = 10)\n",
    "        #Recommended so that the weights are stored and updated in\n",
    "        #the CPU so as to avoid problems with weight sharing between GPUs \n",
    "   \n",
    "    model = multi_gpu_model(model, gpus=n_gpu)\n",
    "        \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"5082pt\" viewBox=\"0.00 0.00 398.00 5082.00\" width=\"398pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 5078)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-5078 394,-5078 394,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 140430263547664 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>140430263547664</title>\n",
       "<polygon fill=\"none\" points=\"183,-5037.5 183,-5073.5 308,-5073.5 308,-5037.5 183,-5037.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"245.5\" y=\"-5051.8\">input_1: InputLayer</text>\n",
       "</g>\n",
       "<!-- 140430263547776 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>140430263547776</title>\n",
       "<polygon fill=\"none\" points=\"194,-4964.5 194,-5000.5 297,-5000.5 297,-4964.5 194,-4964.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"245.5\" y=\"-4978.8\">conv1: Conv2D</text>\n",
       "</g>\n",
       "<!-- 140430263547664&#45;&gt;140430263547776 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>140430263547664-&gt;140430263547776</title>\n",
       "<path d=\"M245.5,-5037.4551C245.5,-5029.3828 245.5,-5019.6764 245.5,-5010.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"249.0001,-5010.5903 245.5,-5000.5904 242.0001,-5010.5904 249.0001,-5010.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263548392 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>140430263548392</title>\n",
       "<polygon fill=\"none\" points=\"151.5,-4891.5 151.5,-4927.5 339.5,-4927.5 339.5,-4891.5 151.5,-4891.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"245.5\" y=\"-4905.8\">bn_conv1: BatchNormalization</text>\n",
       "</g>\n",
       "<!-- 140430263547776&#45;&gt;140430263548392 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>140430263547776-&gt;140430263548392</title>\n",
       "<path d=\"M245.5,-4964.4551C245.5,-4956.3828 245.5,-4946.6764 245.5,-4937.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"249.0001,-4937.5903 245.5,-4927.5904 242.0001,-4937.5904 249.0001,-4937.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263548336 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>140430263548336</title>\n",
       "<polygon fill=\"none\" points=\"171.5,-4818.5 171.5,-4854.5 319.5,-4854.5 319.5,-4818.5 171.5,-4818.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"245.5\" y=\"-4832.8\">activation_1: Activation</text>\n",
       "</g>\n",
       "<!-- 140430263548392&#45;&gt;140430263548336 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>140430263548392-&gt;140430263548336</title>\n",
       "<path d=\"M245.5,-4891.4551C245.5,-4883.3828 245.5,-4873.6764 245.5,-4864.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"249.0001,-4864.5903 245.5,-4854.5904 242.0001,-4864.5904 249.0001,-4864.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263549120 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>140430263549120</title>\n",
       "<polygon fill=\"none\" points=\"115,-4745.5 115,-4781.5 270,-4781.5 270,-4745.5 115,-4745.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"192.5\" y=\"-4759.8\">res1a_branch2a: Conv2D</text>\n",
       "</g>\n",
       "<!-- 140430263548336&#45;&gt;140430263549120 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>140430263548336-&gt;140430263549120</title>\n",
       "<path d=\"M232.3989,-4818.4551C226.156,-4809.8564 218.5668,-4799.4034 211.6901,-4789.9316\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"214.3415,-4787.6262 205.6341,-4781.5904 208.677,-4791.7388 214.3415,-4787.6262\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263583520 -->\n",
       "<g class=\"node\" id=\"node10\">\n",
       "<title>140430263583520</title>\n",
       "<polygon fill=\"none\" points=\"204.5,-4380.5 204.5,-4416.5 284.5,-4416.5 284.5,-4380.5 204.5,-4380.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"244.5\" y=\"-4394.8\">add_1: Add</text>\n",
       "</g>\n",
       "<!-- 140430263548336&#45;&gt;140430263583520 -->\n",
       "<g class=\"edge\" id=\"edge9\">\n",
       "<title>140430263548336-&gt;140430263583520</title>\n",
       "<path d=\"M260.255,-4818.4045C280.2543,-4791.9894 313.5,-4740.5513 313.5,-4690.5 313.5,-4690.5 313.5,-4690.5 313.5,-4544.5 313.5,-4502.8732 312.4913,-4490.0421 293.5,-4453 288.1667,-4442.5975 280.3503,-4432.6421 272.5201,-4424.1527\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"274.8675,-4421.5455 265.396,-4416.7976 269.8394,-4426.4157 274.8675,-4421.5455\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263549176 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>140430263549176</title>\n",
       "<polygon fill=\"none\" points=\"68,-4672.5 68,-4708.5 285,-4708.5 285,-4672.5 68,-4672.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"176.5\" y=\"-4686.8\">bn1a_branch2a: BatchNormalization</text>\n",
       "</g>\n",
       "<!-- 140430263549120&#45;&gt;140430263549176 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>140430263549120-&gt;140430263549176</title>\n",
       "<path d=\"M188.5449,-4745.4551C186.7565,-4737.2951 184.602,-4727.4652 182.6126,-4718.3887\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"186.0249,-4717.6091 180.465,-4708.5904 179.1872,-4719.1079 186.0249,-4717.6091\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263549568 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>140430263549568</title>\n",
       "<polygon fill=\"none\" points=\"102.5,-4599.5 102.5,-4635.5 250.5,-4635.5 250.5,-4599.5 102.5,-4599.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"176.5\" y=\"-4613.8\">activation_2: Activation</text>\n",
       "</g>\n",
       "<!-- 140430263549176&#45;&gt;140430263549568 -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>140430263549176-&gt;140430263549568</title>\n",
       "<path d=\"M176.5,-4672.4551C176.5,-4664.3828 176.5,-4654.6764 176.5,-4645.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"180.0001,-4645.5903 176.5,-4635.5904 173.0001,-4645.5904 180.0001,-4645.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263582792 -->\n",
       "<g class=\"node\" id=\"node8\">\n",
       "<title>140430263582792</title>\n",
       "<polygon fill=\"none\" points=\"99,-4526.5 99,-4562.5 254,-4562.5 254,-4526.5 99,-4526.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"176.5\" y=\"-4540.8\">res1a_branch2c: Conv2D</text>\n",
       "</g>\n",
       "<!-- 140430263549568&#45;&gt;140430263582792 -->\n",
       "<g class=\"edge\" id=\"edge7\">\n",
       "<title>140430263549568-&gt;140430263582792</title>\n",
       "<path d=\"M176.5,-4599.4551C176.5,-4591.3828 176.5,-4581.6764 176.5,-4572.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"180.0001,-4572.5903 176.5,-4562.5904 173.0001,-4572.5904 180.0001,-4572.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263583184 -->\n",
       "<g class=\"node\" id=\"node9\">\n",
       "<title>140430263583184</title>\n",
       "<polygon fill=\"none\" points=\"68,-4453.5 68,-4489.5 285,-4489.5 285,-4453.5 68,-4453.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"176.5\" y=\"-4467.8\">bn1a_branch2c: BatchNormalization</text>\n",
       "</g>\n",
       "<!-- 140430263582792&#45;&gt;140430263583184 -->\n",
       "<g class=\"edge\" id=\"edge8\">\n",
       "<title>140430263582792-&gt;140430263583184</title>\n",
       "<path d=\"M176.5,-4526.4551C176.5,-4518.3828 176.5,-4508.6764 176.5,-4499.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"180.0001,-4499.5903 176.5,-4489.5904 173.0001,-4499.5904 180.0001,-4499.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263583184&#45;&gt;140430263583520 -->\n",
       "<g class=\"edge\" id=\"edge10\">\n",
       "<title>140430263583184-&gt;140430263583520</title>\n",
       "<path d=\"M193.309,-4453.4551C201.5639,-4444.5932 211.6535,-4433.7616 220.6864,-4424.0646\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"223.3937,-4426.2932 227.6487,-4416.5904 218.2716,-4421.522 223.3937,-4426.2932\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263583576 -->\n",
       "<g class=\"node\" id=\"node11\">\n",
       "<title>140430263583576</title>\n",
       "<polygon fill=\"none\" points=\"170.5,-4307.5 170.5,-4343.5 318.5,-4343.5 318.5,-4307.5 170.5,-4307.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"244.5\" y=\"-4321.8\">activation_3: Activation</text>\n",
       "</g>\n",
       "<!-- 140430263583520&#45;&gt;140430263583576 -->\n",
       "<g class=\"edge\" id=\"edge11\">\n",
       "<title>140430263583520-&gt;140430263583576</title>\n",
       "<path d=\"M244.5,-4380.4551C244.5,-4372.3828 244.5,-4362.6764 244.5,-4353.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"248.0001,-4353.5903 244.5,-4343.5904 241.0001,-4353.5904 248.0001,-4353.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263583632 -->\n",
       "<g class=\"node\" id=\"node12\">\n",
       "<title>140430263583632</title>\n",
       "<polygon fill=\"none\" points=\"99,-4234.5 99,-4270.5 254,-4270.5 254,-4234.5 99,-4234.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"176.5\" y=\"-4248.8\">res1b_branch2a: Conv2D</text>\n",
       "</g>\n",
       "<!-- 140430263583576&#45;&gt;140430263583632 -->\n",
       "<g class=\"edge\" id=\"edge12\">\n",
       "<title>140430263583576-&gt;140430263583632</title>\n",
       "<path d=\"M227.691,-4307.4551C219.4361,-4298.5932 209.3465,-4287.7616 200.3136,-4278.0646\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"202.7284,-4275.522 193.3513,-4270.5904 197.6063,-4280.2932 202.7284,-4275.522\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263585144 -->\n",
       "<g class=\"node\" id=\"node17\">\n",
       "<title>140430263585144</title>\n",
       "<polygon fill=\"none\" points=\"189.5,-3869.5 189.5,-3905.5 269.5,-3905.5 269.5,-3869.5 189.5,-3869.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"229.5\" y=\"-3883.8\">add_2: Add</text>\n",
       "</g>\n",
       "<!-- 140430263583576&#45;&gt;140430263585144 -->\n",
       "<g class=\"edge\" id=\"edge17\">\n",
       "<title>140430263583576-&gt;140430263585144</title>\n",
       "<path d=\"M255.952,-4307.3993C271.8032,-4280.5636 298.5,-4228.1457 298.5,-4179.5 298.5,-4179.5 298.5,-4179.5 298.5,-4033.5 298.5,-3991.9658 298.4417,-3978.9635 279.5,-3942 274.1199,-3931.501 266.1615,-3921.5184 258.1684,-3913.0337\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"260.4163,-3910.3298 250.891,-3905.6909 255.4445,-3915.2573 260.4163,-3910.3298\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263584024 -->\n",
       "<g class=\"node\" id=\"node13\">\n",
       "<title>140430263584024</title>\n",
       "<polygon fill=\"none\" points=\"52.5,-4161.5 52.5,-4197.5 270.5,-4197.5 270.5,-4161.5 52.5,-4161.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"161.5\" y=\"-4175.8\">bn1b_branch2a: BatchNormalization</text>\n",
       "</g>\n",
       "<!-- 140430263583632&#45;&gt;140430263584024 -->\n",
       "<g class=\"edge\" id=\"edge13\">\n",
       "<title>140430263583632-&gt;140430263584024</title>\n",
       "<path d=\"M172.7921,-4234.4551C171.1154,-4226.2951 169.0956,-4216.4652 167.2306,-4207.3887\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"170.6584,-4206.6812 165.2172,-4197.5904 163.8016,-4208.0902 170.6584,-4206.6812\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263584360 -->\n",
       "<g class=\"node\" id=\"node14\">\n",
       "<title>140430263584360</title>\n",
       "<polygon fill=\"none\" points=\"87.5,-4088.5 87.5,-4124.5 235.5,-4124.5 235.5,-4088.5 87.5,-4088.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"161.5\" y=\"-4102.8\">activation_4: Activation</text>\n",
       "</g>\n",
       "<!-- 140430263584024&#45;&gt;140430263584360 -->\n",
       "<g class=\"edge\" id=\"edge14\">\n",
       "<title>140430263584024-&gt;140430263584360</title>\n",
       "<path d=\"M161.5,-4161.4551C161.5,-4153.3828 161.5,-4143.6764 161.5,-4134.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"165.0001,-4134.5903 161.5,-4124.5904 158.0001,-4134.5904 165.0001,-4134.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263584416 -->\n",
       "<g class=\"node\" id=\"node15\">\n",
       "<title>140430263584416</title>\n",
       "<polygon fill=\"none\" points=\"84,-4015.5 84,-4051.5 239,-4051.5 239,-4015.5 84,-4015.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"161.5\" y=\"-4029.8\">res1b_branch2c: Conv2D</text>\n",
       "</g>\n",
       "<!-- 140430263584360&#45;&gt;140430263584416 -->\n",
       "<g class=\"edge\" id=\"edge15\">\n",
       "<title>140430263584360-&gt;140430263584416</title>\n",
       "<path d=\"M161.5,-4088.4551C161.5,-4080.3828 161.5,-4070.6764 161.5,-4061.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"165.0001,-4061.5903 161.5,-4051.5904 158.0001,-4061.5904 165.0001,-4061.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263584808 -->\n",
       "<g class=\"node\" id=\"node16\">\n",
       "<title>140430263584808</title>\n",
       "<polygon fill=\"none\" points=\"52.5,-3942.5 52.5,-3978.5 270.5,-3978.5 270.5,-3942.5 52.5,-3942.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"161.5\" y=\"-3956.8\">bn1b_branch2c: BatchNormalization</text>\n",
       "</g>\n",
       "<!-- 140430263584416&#45;&gt;140430263584808 -->\n",
       "<g class=\"edge\" id=\"edge16\">\n",
       "<title>140430263584416-&gt;140430263584808</title>\n",
       "<path d=\"M161.5,-4015.4551C161.5,-4007.3828 161.5,-3997.6764 161.5,-3988.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"165.0001,-3988.5903 161.5,-3978.5904 158.0001,-3988.5904 165.0001,-3988.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263584808&#45;&gt;140430263585144 -->\n",
       "<g class=\"edge\" id=\"edge18\">\n",
       "<title>140430263584808-&gt;140430263585144</title>\n",
       "<path d=\"M178.309,-3942.4551C186.5639,-3933.5932 196.6535,-3922.7616 205.6864,-3913.0646\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"208.3937,-3915.2932 212.6487,-3905.5904 203.2716,-3910.522 208.3937,-3915.2932\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263585200 -->\n",
       "<g class=\"node\" id=\"node18\">\n",
       "<title>140430263585200</title>\n",
       "<polygon fill=\"none\" points=\"155.5,-3796.5 155.5,-3832.5 303.5,-3832.5 303.5,-3796.5 155.5,-3796.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"229.5\" y=\"-3810.8\">activation_5: Activation</text>\n",
       "</g>\n",
       "<!-- 140430263585144&#45;&gt;140430263585200 -->\n",
       "<g class=\"edge\" id=\"edge19\">\n",
       "<title>140430263585144-&gt;140430263585200</title>\n",
       "<path d=\"M229.5,-3869.4551C229.5,-3861.3828 229.5,-3851.6764 229.5,-3842.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"233.0001,-3842.5903 229.5,-3832.5904 226.0001,-3842.5904 233.0001,-3842.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263585256 -->\n",
       "<g class=\"node\" id=\"node19\">\n",
       "<title>140430263585256</title>\n",
       "<polygon fill=\"none\" points=\"84,-3723.5 84,-3759.5 239,-3759.5 239,-3723.5 84,-3723.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"161.5\" y=\"-3737.8\">res1c_branch2a: Conv2D</text>\n",
       "</g>\n",
       "<!-- 140430263585200&#45;&gt;140430263585256 -->\n",
       "<g class=\"edge\" id=\"edge20\">\n",
       "<title>140430263585200-&gt;140430263585256</title>\n",
       "<path d=\"M212.691,-3796.4551C204.4361,-3787.5932 194.3465,-3776.7616 185.3136,-3767.0646\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"187.7284,-3764.522 178.3513,-3759.5904 182.6063,-3769.2932 187.7284,-3764.522\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263549904 -->\n",
       "<g class=\"node\" id=\"node24\">\n",
       "<title>140430263549904</title>\n",
       "<polygon fill=\"none\" points=\"174.5,-3358.5 174.5,-3394.5 254.5,-3394.5 254.5,-3358.5 174.5,-3358.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"214.5\" y=\"-3372.8\">add_3: Add</text>\n",
       "</g>\n",
       "<!-- 140430263585200&#45;&gt;140430263549904 -->\n",
       "<g class=\"edge\" id=\"edge25\">\n",
       "<title>140430263585200-&gt;140430263549904</title>\n",
       "<path d=\"M240.952,-3796.3993C256.8032,-3769.5636 283.5,-3717.1457 283.5,-3668.5 283.5,-3668.5 283.5,-3668.5 283.5,-3522.5 283.5,-3480.8732 282.4913,-3468.0421 263.5,-3431 258.1667,-3420.5975 250.3503,-3410.6421 242.5201,-3402.1527\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"244.8675,-3399.5455 235.396,-3394.7976 239.8394,-3404.4157 244.8675,-3399.5455\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263585648 -->\n",
       "<g class=\"node\" id=\"node20\">\n",
       "<title>140430263585648</title>\n",
       "<polygon fill=\"none\" points=\"38,-3650.5 38,-3686.5 255,-3686.5 255,-3650.5 38,-3650.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"146.5\" y=\"-3664.8\">bn1c_branch2a: BatchNormalization</text>\n",
       "</g>\n",
       "<!-- 140430263585256&#45;&gt;140430263585648 -->\n",
       "<g class=\"edge\" id=\"edge21\">\n",
       "<title>140430263585256-&gt;140430263585648</title>\n",
       "<path d=\"M157.7921,-3723.4551C156.1154,-3715.2951 154.0956,-3705.4652 152.2306,-3696.3887\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"155.6584,-3695.6812 150.2172,-3686.5904 148.8016,-3697.0902 155.6584,-3695.6812\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263585984 -->\n",
       "<g class=\"node\" id=\"node21\">\n",
       "<title>140430263585984</title>\n",
       "<polygon fill=\"none\" points=\"72.5,-3577.5 72.5,-3613.5 220.5,-3613.5 220.5,-3577.5 72.5,-3577.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"146.5\" y=\"-3591.8\">activation_6: Activation</text>\n",
       "</g>\n",
       "<!-- 140430263585648&#45;&gt;140430263585984 -->\n",
       "<g class=\"edge\" id=\"edge22\">\n",
       "<title>140430263585648-&gt;140430263585984</title>\n",
       "<path d=\"M146.5,-3650.4551C146.5,-3642.3828 146.5,-3632.6764 146.5,-3623.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"150.0001,-3623.5903 146.5,-3613.5904 143.0001,-3623.5904 150.0001,-3623.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263586040 -->\n",
       "<g class=\"node\" id=\"node22\">\n",
       "<title>140430263586040</title>\n",
       "<polygon fill=\"none\" points=\"69,-3504.5 69,-3540.5 224,-3540.5 224,-3504.5 69,-3504.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"146.5\" y=\"-3518.8\">res1c_branch2c: Conv2D</text>\n",
       "</g>\n",
       "<!-- 140430263585984&#45;&gt;140430263586040 -->\n",
       "<g class=\"edge\" id=\"edge23\">\n",
       "<title>140430263585984-&gt;140430263586040</title>\n",
       "<path d=\"M146.5,-3577.4551C146.5,-3569.3828 146.5,-3559.6764 146.5,-3550.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"150.0001,-3550.5903 146.5,-3540.5904 143.0001,-3550.5904 150.0001,-3550.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263586432 -->\n",
       "<g class=\"node\" id=\"node23\">\n",
       "<title>140430263586432</title>\n",
       "<polygon fill=\"none\" points=\"38,-3431.5 38,-3467.5 255,-3467.5 255,-3431.5 38,-3431.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"146.5\" y=\"-3445.8\">bn1c_branch2c: BatchNormalization</text>\n",
       "</g>\n",
       "<!-- 140430263586040&#45;&gt;140430263586432 -->\n",
       "<g class=\"edge\" id=\"edge24\">\n",
       "<title>140430263586040-&gt;140430263586432</title>\n",
       "<path d=\"M146.5,-3504.4551C146.5,-3496.3828 146.5,-3486.6764 146.5,-3477.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"150.0001,-3477.5903 146.5,-3467.5904 143.0001,-3477.5904 150.0001,-3477.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263586432&#45;&gt;140430263549904 -->\n",
       "<g class=\"edge\" id=\"edge26\">\n",
       "<title>140430263586432-&gt;140430263549904</title>\n",
       "<path d=\"M163.309,-3431.4551C171.5639,-3422.5932 181.6535,-3411.7616 190.6864,-3402.0646\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"193.3937,-3404.2932 197.6487,-3394.5904 188.2716,-3399.522 193.3937,-3404.2932\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263611464 -->\n",
       "<g class=\"node\" id=\"node25\">\n",
       "<title>140430263611464</title>\n",
       "<polygon fill=\"none\" points=\"140.5,-3285.5 140.5,-3321.5 288.5,-3321.5 288.5,-3285.5 140.5,-3285.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"214.5\" y=\"-3299.8\">activation_7: Activation</text>\n",
       "</g>\n",
       "<!-- 140430263549904&#45;&gt;140430263611464 -->\n",
       "<g class=\"edge\" id=\"edge27\">\n",
       "<title>140430263549904-&gt;140430263611464</title>\n",
       "<path d=\"M214.5,-3358.4551C214.5,-3350.3828 214.5,-3340.6764 214.5,-3331.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"218.0001,-3331.5903 214.5,-3321.5904 211.0001,-3331.5904 218.0001,-3331.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263611520 -->\n",
       "<g class=\"node\" id=\"node26\">\n",
       "<title>140430263611520</title>\n",
       "<polygon fill=\"none\" points=\"84,-3212.5 84,-3248.5 239,-3248.5 239,-3212.5 84,-3212.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"161.5\" y=\"-3226.8\">res2a_branch2a: Conv2D</text>\n",
       "</g>\n",
       "<!-- 140430263611464&#45;&gt;140430263611520 -->\n",
       "<g class=\"edge\" id=\"edge28\">\n",
       "<title>140430263611464-&gt;140430263611520</title>\n",
       "<path d=\"M201.3989,-3285.4551C195.156,-3276.8564 187.5668,-3266.4034 180.6901,-3256.9316\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"183.3415,-3254.6262 174.6341,-3248.5904 177.677,-3258.7388 183.3415,-3254.6262\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263612696 -->\n",
       "<g class=\"node\" id=\"node30\">\n",
       "<title>140430263612696</title>\n",
       "<polygon fill=\"none\" points=\"241,-3139.5 241,-3175.5 390,-3175.5 390,-3139.5 241,-3139.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"315.5\" y=\"-3153.8\">res2a_branch1: Conv2D</text>\n",
       "</g>\n",
       "<!-- 140430263611464&#45;&gt;140430263612696 -->\n",
       "<g class=\"edge\" id=\"edge32\">\n",
       "<title>140430263611464-&gt;140430263612696</title>\n",
       "<path d=\"M227.0875,-3285.3042C244.6273,-3259.9496 276.5466,-3213.8089 296.8533,-3184.4546\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"299.943,-3186.1403 302.7539,-3175.9251 294.1863,-3182.1579 299.943,-3186.1403\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263611912 -->\n",
       "<g class=\"node\" id=\"node27\">\n",
       "<title>140430263611912</title>\n",
       "<polygon fill=\"none\" points=\"6,-3139.5 6,-3175.5 223,-3175.5 223,-3139.5 6,-3139.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"114.5\" y=\"-3153.8\">bn2a_branch2a: BatchNormalization</text>\n",
       "</g>\n",
       "<!-- 140430263611520&#45;&gt;140430263611912 -->\n",
       "<g class=\"edge\" id=\"edge29\">\n",
       "<title>140430263611520-&gt;140430263611912</title>\n",
       "<path d=\"M149.882,-3212.4551C144.4024,-3203.9441 137.7531,-3193.6165 131.7045,-3184.2219\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"134.5035,-3182.1037 126.1472,-3175.5904 128.6178,-3185.8931 134.5035,-3182.1037\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263612248 -->\n",
       "<g class=\"node\" id=\"node28\">\n",
       "<title>140430263612248</title>\n",
       "<polygon fill=\"none\" points=\"72.5,-3066.5 72.5,-3102.5 220.5,-3102.5 220.5,-3066.5 72.5,-3066.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"146.5\" y=\"-3080.8\">activation_8: Activation</text>\n",
       "</g>\n",
       "<!-- 140430263611912&#45;&gt;140430263612248 -->\n",
       "<g class=\"edge\" id=\"edge30\">\n",
       "<title>140430263611912-&gt;140430263612248</title>\n",
       "<path d=\"M122.4101,-3139.4551C126.064,-3131.1196 130.4818,-3121.0416 134.531,-3111.8042\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"137.7607,-3113.1542 138.57,-3102.5904 131.3496,-3110.3439 137.7607,-3113.1542\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263612304 -->\n",
       "<g class=\"node\" id=\"node29\">\n",
       "<title>140430263612304</title>\n",
       "<polygon fill=\"none\" points=\"85,-2993.5 85,-3029.5 240,-3029.5 240,-2993.5 85,-2993.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"162.5\" y=\"-3007.8\">res2a_branch2c: Conv2D</text>\n",
       "</g>\n",
       "<!-- 140430263612248&#45;&gt;140430263612304 -->\n",
       "<g class=\"edge\" id=\"edge31\">\n",
       "<title>140430263612248-&gt;140430263612304</title>\n",
       "<path d=\"M150.4551,-3066.4551C152.2435,-3058.2951 154.398,-3048.4652 156.3874,-3039.3887\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"159.8128,-3040.1079 158.535,-3029.5904 152.9751,-3038.6091 159.8128,-3040.1079\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263613144 -->\n",
       "<g class=\"node\" id=\"node31\">\n",
       "<title>140430263613144</title>\n",
       "<polygon fill=\"none\" points=\"62,-2920.5 62,-2956.5 279,-2956.5 279,-2920.5 62,-2920.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"170.5\" y=\"-2934.8\">bn2a_branch2c: BatchNormalization</text>\n",
       "</g>\n",
       "<!-- 140430263612304&#45;&gt;140430263613144 -->\n",
       "<g class=\"edge\" id=\"edge33\">\n",
       "<title>140430263612304-&gt;140430263613144</title>\n",
       "<path d=\"M164.4775,-2993.4551C165.3622,-2985.3828 166.4259,-2975.6764 167.4116,-2966.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"170.9072,-2966.9122 168.5175,-2956.5904 163.9489,-2966.1495 170.9072,-2966.9122\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263613480 -->\n",
       "<g class=\"node\" id=\"node32\">\n",
       "<title>140430263613480</title>\n",
       "<polygon fill=\"none\" points=\"198.5,-2847.5 198.5,-2883.5 278.5,-2883.5 278.5,-2847.5 198.5,-2847.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-2861.8\">add_4: Add</text>\n",
       "</g>\n",
       "<!-- 140430263612696&#45;&gt;140430263613480 -->\n",
       "<g class=\"edge\" id=\"edge34\">\n",
       "<title>140430263612696-&gt;140430263613480</title>\n",
       "<path d=\"M316.9798,-3139.2385C319.5632,-3098.0576 321.7248,-2995.6552 287.5,-2920 282.6818,-2909.3492 275.0108,-2899.3237 267.1552,-2890.8464\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"269.4688,-2888.207 259.9656,-2883.523 264.4736,-2893.1109 269.4688,-2888.207\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263613144&#45;&gt;140430263613480 -->\n",
       "<g class=\"edge\" id=\"edge35\">\n",
       "<title>140430263613144-&gt;140430263613480</title>\n",
       "<path d=\"M187.309,-2920.4551C195.5639,-2911.5932 205.6535,-2900.7616 214.6864,-2891.0646\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"217.3937,-2893.2932 221.6487,-2883.5904 212.2716,-2888.522 217.3937,-2893.2932\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263613536 -->\n",
       "<g class=\"node\" id=\"node33\">\n",
       "<title>140430263613536</title>\n",
       "<polygon fill=\"none\" points=\"164.5,-2774.5 164.5,-2810.5 312.5,-2810.5 312.5,-2774.5 164.5,-2774.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-2788.8\">activation_9: Activation</text>\n",
       "</g>\n",
       "<!-- 140430263613480&#45;&gt;140430263613536 -->\n",
       "<g class=\"edge\" id=\"edge36\">\n",
       "<title>140430263613480-&gt;140430263613536</title>\n",
       "<path d=\"M238.5,-2847.4551C238.5,-2839.3828 238.5,-2829.6764 238.5,-2820.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"242.0001,-2820.5903 238.5,-2810.5904 235.0001,-2820.5904 242.0001,-2820.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263613592 -->\n",
       "<g class=\"node\" id=\"node34\">\n",
       "<title>140430263613592</title>\n",
       "<polygon fill=\"none\" points=\"93,-2701.5 93,-2737.5 248,-2737.5 248,-2701.5 93,-2701.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"170.5\" y=\"-2715.8\">res2b_branch2a: Conv2D</text>\n",
       "</g>\n",
       "<!-- 140430263613536&#45;&gt;140430263613592 -->\n",
       "<g class=\"edge\" id=\"edge37\">\n",
       "<title>140430263613536-&gt;140430263613592</title>\n",
       "<path d=\"M221.691,-2774.4551C213.4361,-2765.5932 203.3465,-2754.7616 194.3136,-2745.0646\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"196.7284,-2742.522 187.3513,-2737.5904 191.6063,-2747.2932 196.7284,-2742.522\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263615104 -->\n",
       "<g class=\"node\" id=\"node39\">\n",
       "<title>140430263615104</title>\n",
       "<polygon fill=\"none\" points=\"183.5,-2336.5 183.5,-2372.5 263.5,-2372.5 263.5,-2336.5 183.5,-2336.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"223.5\" y=\"-2350.8\">add_5: Add</text>\n",
       "</g>\n",
       "<!-- 140430263613536&#45;&gt;140430263615104 -->\n",
       "<g class=\"edge\" id=\"edge42\">\n",
       "<title>140430263613536-&gt;140430263615104</title>\n",
       "<path d=\"M249.952,-2774.3993C265.8032,-2747.5636 292.5,-2695.1457 292.5,-2646.5 292.5,-2646.5 292.5,-2646.5 292.5,-2500.5 292.5,-2458.9658 292.4417,-2445.9635 273.5,-2409 268.1199,-2398.501 260.1615,-2388.5184 252.1684,-2380.0337\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"254.4163,-2377.3298 244.891,-2372.6909 249.4445,-2382.2573 254.4163,-2377.3298\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263613984 -->\n",
       "<g class=\"node\" id=\"node35\">\n",
       "<title>140430263613984</title>\n",
       "<polygon fill=\"none\" points=\"46.5,-2628.5 46.5,-2664.5 264.5,-2664.5 264.5,-2628.5 46.5,-2628.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"155.5\" y=\"-2642.8\">bn2b_branch2a: BatchNormalization</text>\n",
       "</g>\n",
       "<!-- 140430263613592&#45;&gt;140430263613984 -->\n",
       "<g class=\"edge\" id=\"edge38\">\n",
       "<title>140430263613592-&gt;140430263613984</title>\n",
       "<path d=\"M166.7921,-2701.4551C165.1154,-2693.2951 163.0956,-2683.4652 161.2306,-2674.3887\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"164.6584,-2673.6812 159.2172,-2664.5904 157.8016,-2675.0902 164.6584,-2673.6812\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263614320 -->\n",
       "<g class=\"node\" id=\"node36\">\n",
       "<title>140430263614320</title>\n",
       "<polygon fill=\"none\" points=\"78,-2555.5 78,-2591.5 233,-2591.5 233,-2555.5 78,-2555.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"155.5\" y=\"-2569.8\">activation_10: Activation</text>\n",
       "</g>\n",
       "<!-- 140430263613984&#45;&gt;140430263614320 -->\n",
       "<g class=\"edge\" id=\"edge39\">\n",
       "<title>140430263613984-&gt;140430263614320</title>\n",
       "<path d=\"M155.5,-2628.4551C155.5,-2620.3828 155.5,-2610.6764 155.5,-2601.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"159.0001,-2601.5903 155.5,-2591.5904 152.0001,-2601.5904 159.0001,-2601.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263614376 -->\n",
       "<g class=\"node\" id=\"node37\">\n",
       "<title>140430263614376</title>\n",
       "<polygon fill=\"none\" points=\"78,-2482.5 78,-2518.5 233,-2518.5 233,-2482.5 78,-2482.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"155.5\" y=\"-2496.8\">res2b_branch2c: Conv2D</text>\n",
       "</g>\n",
       "<!-- 140430263614320&#45;&gt;140430263614376 -->\n",
       "<g class=\"edge\" id=\"edge40\">\n",
       "<title>140430263614320-&gt;140430263614376</title>\n",
       "<path d=\"M155.5,-2555.4551C155.5,-2547.3828 155.5,-2537.6764 155.5,-2528.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"159.0001,-2528.5903 155.5,-2518.5904 152.0001,-2528.5904 159.0001,-2528.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263614768 -->\n",
       "<g class=\"node\" id=\"node38\">\n",
       "<title>140430263614768</title>\n",
       "<polygon fill=\"none\" points=\"46.5,-2409.5 46.5,-2445.5 264.5,-2445.5 264.5,-2409.5 46.5,-2409.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"155.5\" y=\"-2423.8\">bn2b_branch2c: BatchNormalization</text>\n",
       "</g>\n",
       "<!-- 140430263614376&#45;&gt;140430263614768 -->\n",
       "<g class=\"edge\" id=\"edge41\">\n",
       "<title>140430263614376-&gt;140430263614768</title>\n",
       "<path d=\"M155.5,-2482.4551C155.5,-2474.3828 155.5,-2464.6764 155.5,-2455.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"159.0001,-2455.5903 155.5,-2445.5904 152.0001,-2455.5904 159.0001,-2455.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263614768&#45;&gt;140430263615104 -->\n",
       "<g class=\"edge\" id=\"edge43\">\n",
       "<title>140430263614768-&gt;140430263615104</title>\n",
       "<path d=\"M172.309,-2409.4551C180.5639,-2400.5932 190.6535,-2389.7616 199.6864,-2380.0646\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"202.3937,-2382.2932 206.6487,-2372.5904 197.2716,-2377.522 202.3937,-2382.2932\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263615160 -->\n",
       "<g class=\"node\" id=\"node40\">\n",
       "<title>140430263615160</title>\n",
       "<polygon fill=\"none\" points=\"146,-2263.5 146,-2299.5 301,-2299.5 301,-2263.5 146,-2263.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"223.5\" y=\"-2277.8\">activation_11: Activation</text>\n",
       "</g>\n",
       "<!-- 140430263615104&#45;&gt;140430263615160 -->\n",
       "<g class=\"edge\" id=\"edge44\">\n",
       "<title>140430263615104-&gt;140430263615160</title>\n",
       "<path d=\"M223.5,-2336.4551C223.5,-2328.3828 223.5,-2318.6764 223.5,-2309.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"227.0001,-2309.5903 223.5,-2299.5904 220.0001,-2309.5904 227.0001,-2309.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263615216 -->\n",
       "<g class=\"node\" id=\"node41\">\n",
       "<title>140430263615216</title>\n",
       "<polygon fill=\"none\" points=\"78,-2190.5 78,-2226.5 233,-2226.5 233,-2190.5 78,-2190.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"155.5\" y=\"-2204.8\">res2c_branch2a: Conv2D</text>\n",
       "</g>\n",
       "<!-- 140430263615160&#45;&gt;140430263615216 -->\n",
       "<g class=\"edge\" id=\"edge45\">\n",
       "<title>140430263615160-&gt;140430263615216</title>\n",
       "<path d=\"M206.691,-2263.4551C198.4361,-2254.5932 188.3465,-2243.7616 179.3136,-2234.0646\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"181.7284,-2231.522 172.3513,-2226.5904 176.6063,-2236.2932 181.7284,-2231.522\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263645464 -->\n",
       "<g class=\"node\" id=\"node46\">\n",
       "<title>140430263645464</title>\n",
       "<polygon fill=\"none\" points=\"168.5,-1825.5 168.5,-1861.5 248.5,-1861.5 248.5,-1825.5 168.5,-1825.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"208.5\" y=\"-1839.8\">add_6: Add</text>\n",
       "</g>\n",
       "<!-- 140430263615160&#45;&gt;140430263645464 -->\n",
       "<g class=\"edge\" id=\"edge50\">\n",
       "<title>140430263615160-&gt;140430263645464</title>\n",
       "<path d=\"M234.952,-2263.3993C250.8032,-2236.5636 277.5,-2184.1457 277.5,-2135.5 277.5,-2135.5 277.5,-2135.5 277.5,-1989.5 277.5,-1947.8732 276.4913,-1935.0421 257.5,-1898 252.1667,-1887.5975 244.3503,-1877.6421 236.5201,-1869.1527\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"238.8675,-1866.5455 229.396,-1861.7976 233.8394,-1871.4157 238.8675,-1866.5455\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263586768 -->\n",
       "<g class=\"node\" id=\"node42\">\n",
       "<title>140430263586768</title>\n",
       "<polygon fill=\"none\" points=\"32,-2117.5 32,-2153.5 249,-2153.5 249,-2117.5 32,-2117.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"140.5\" y=\"-2131.8\">bn2c_branch2a: BatchNormalization</text>\n",
       "</g>\n",
       "<!-- 140430263615216&#45;&gt;140430263586768 -->\n",
       "<g class=\"edge\" id=\"edge46\">\n",
       "<title>140430263615216-&gt;140430263586768</title>\n",
       "<path d=\"M151.7921,-2190.4551C150.1154,-2182.2951 148.0956,-2172.4652 146.2306,-2163.3887\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"149.6584,-2162.6812 144.2172,-2153.5904 142.8016,-2164.0902 149.6584,-2162.6812\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263644680 -->\n",
       "<g class=\"node\" id=\"node43\">\n",
       "<title>140430263644680</title>\n",
       "<polygon fill=\"none\" points=\"63,-2044.5 63,-2080.5 218,-2080.5 218,-2044.5 63,-2044.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"140.5\" y=\"-2058.8\">activation_12: Activation</text>\n",
       "</g>\n",
       "<!-- 140430263586768&#45;&gt;140430263644680 -->\n",
       "<g class=\"edge\" id=\"edge47\">\n",
       "<title>140430263586768-&gt;140430263644680</title>\n",
       "<path d=\"M140.5,-2117.4551C140.5,-2109.3828 140.5,-2099.6764 140.5,-2090.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"144.0001,-2090.5903 140.5,-2080.5904 137.0001,-2090.5904 144.0001,-2090.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263644736 -->\n",
       "<g class=\"node\" id=\"node44\">\n",
       "<title>140430263644736</title>\n",
       "<polygon fill=\"none\" points=\"63,-1971.5 63,-2007.5 218,-2007.5 218,-1971.5 63,-1971.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"140.5\" y=\"-1985.8\">res2c_branch2c: Conv2D</text>\n",
       "</g>\n",
       "<!-- 140430263644680&#45;&gt;140430263644736 -->\n",
       "<g class=\"edge\" id=\"edge48\">\n",
       "<title>140430263644680-&gt;140430263644736</title>\n",
       "<path d=\"M140.5,-2044.4551C140.5,-2036.3828 140.5,-2026.6764 140.5,-2017.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"144.0001,-2017.5903 140.5,-2007.5904 137.0001,-2017.5904 144.0001,-2017.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263645128 -->\n",
       "<g class=\"node\" id=\"node45\">\n",
       "<title>140430263645128</title>\n",
       "<polygon fill=\"none\" points=\"32,-1898.5 32,-1934.5 249,-1934.5 249,-1898.5 32,-1898.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"140.5\" y=\"-1912.8\">bn2c_branch2c: BatchNormalization</text>\n",
       "</g>\n",
       "<!-- 140430263644736&#45;&gt;140430263645128 -->\n",
       "<g class=\"edge\" id=\"edge49\">\n",
       "<title>140430263644736-&gt;140430263645128</title>\n",
       "<path d=\"M140.5,-1971.4551C140.5,-1963.3828 140.5,-1953.6764 140.5,-1944.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"144.0001,-1944.5903 140.5,-1934.5904 137.0001,-1944.5904 144.0001,-1944.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263645128&#45;&gt;140430263645464 -->\n",
       "<g class=\"edge\" id=\"edge51\">\n",
       "<title>140430263645128-&gt;140430263645464</title>\n",
       "<path d=\"M157.309,-1898.4551C165.5639,-1889.5932 175.6535,-1878.7616 184.6864,-1869.0646\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"187.3937,-1871.2932 191.6487,-1861.5904 182.2716,-1866.522 187.3937,-1871.2932\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263645520 -->\n",
       "<g class=\"node\" id=\"node47\">\n",
       "<title>140430263645520</title>\n",
       "<polygon fill=\"none\" points=\"131,-1752.5 131,-1788.5 286,-1788.5 286,-1752.5 131,-1752.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"208.5\" y=\"-1766.8\">activation_13: Activation</text>\n",
       "</g>\n",
       "<!-- 140430263645464&#45;&gt;140430263645520 -->\n",
       "<g class=\"edge\" id=\"edge52\">\n",
       "<title>140430263645464-&gt;140430263645520</title>\n",
       "<path d=\"M208.5,-1825.4551C208.5,-1817.3828 208.5,-1807.6764 208.5,-1798.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"212.0001,-1798.5903 208.5,-1788.5904 205.0001,-1798.5904 212.0001,-1798.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263645576 -->\n",
       "<g class=\"node\" id=\"node48\">\n",
       "<title>140430263645576</title>\n",
       "<polygon fill=\"none\" points=\"78,-1679.5 78,-1715.5 233,-1715.5 233,-1679.5 78,-1679.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"155.5\" y=\"-1693.8\">res3a_branch2a: Conv2D</text>\n",
       "</g>\n",
       "<!-- 140430263645520&#45;&gt;140430263645576 -->\n",
       "<g class=\"edge\" id=\"edge53\">\n",
       "<title>140430263645520-&gt;140430263645576</title>\n",
       "<path d=\"M195.3989,-1752.4551C189.156,-1743.8564 181.5668,-1733.4034 174.6901,-1723.9316\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"177.3415,-1721.6262 168.6341,-1715.5904 171.677,-1725.7388 177.3415,-1721.6262\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263646752 -->\n",
       "<g class=\"node\" id=\"node52\">\n",
       "<title>140430263646752</title>\n",
       "<polygon fill=\"none\" points=\"235,-1606.5 235,-1642.5 384,-1642.5 384,-1606.5 235,-1606.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"309.5\" y=\"-1620.8\">res3a_branch1: Conv2D</text>\n",
       "</g>\n",
       "<!-- 140430263645520&#45;&gt;140430263646752 -->\n",
       "<g class=\"edge\" id=\"edge57\">\n",
       "<title>140430263645520-&gt;140430263646752</title>\n",
       "<path d=\"M221.0875,-1752.3042C238.6273,-1726.9496 270.5466,-1680.8089 290.8533,-1651.4546\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"293.943,-1653.1403 296.7539,-1642.9251 288.1863,-1649.1579 293.943,-1653.1403\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263645968 -->\n",
       "<g class=\"node\" id=\"node49\">\n",
       "<title>140430263645968</title>\n",
       "<polygon fill=\"none\" points=\"0,-1606.5 0,-1642.5 217,-1642.5 217,-1606.5 0,-1606.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"108.5\" y=\"-1620.8\">bn3a_branch2a: BatchNormalization</text>\n",
       "</g>\n",
       "<!-- 140430263645576&#45;&gt;140430263645968 -->\n",
       "<g class=\"edge\" id=\"edge54\">\n",
       "<title>140430263645576-&gt;140430263645968</title>\n",
       "<path d=\"M143.882,-1679.4551C138.4024,-1670.9441 131.7531,-1660.6165 125.7045,-1651.2219\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"128.5035,-1649.1037 120.1472,-1642.5904 122.6178,-1652.8931 128.5035,-1649.1037\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263646304 -->\n",
       "<g class=\"node\" id=\"node50\">\n",
       "<title>140430263646304</title>\n",
       "<polygon fill=\"none\" points=\"63,-1533.5 63,-1569.5 218,-1569.5 218,-1533.5 63,-1533.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"140.5\" y=\"-1547.8\">activation_14: Activation</text>\n",
       "</g>\n",
       "<!-- 140430263645968&#45;&gt;140430263646304 -->\n",
       "<g class=\"edge\" id=\"edge55\">\n",
       "<title>140430263645968-&gt;140430263646304</title>\n",
       "<path d=\"M116.4101,-1606.4551C120.064,-1598.1196 124.4818,-1588.0416 128.531,-1578.8042\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"131.7607,-1580.1542 132.57,-1569.5904 125.3496,-1577.3439 131.7607,-1580.1542\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263646360 -->\n",
       "<g class=\"node\" id=\"node51\">\n",
       "<title>140430263646360</title>\n",
       "<polygon fill=\"none\" points=\"79,-1460.5 79,-1496.5 234,-1496.5 234,-1460.5 79,-1460.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"156.5\" y=\"-1474.8\">res3a_branch2c: Conv2D</text>\n",
       "</g>\n",
       "<!-- 140430263646304&#45;&gt;140430263646360 -->\n",
       "<g class=\"edge\" id=\"edge56\">\n",
       "<title>140430263646304-&gt;140430263646360</title>\n",
       "<path d=\"M144.4551,-1533.4551C146.2435,-1525.2951 148.398,-1515.4652 150.3874,-1506.3887\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"153.8128,-1507.1079 152.535,-1496.5904 146.9751,-1505.6091 153.8128,-1507.1079\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263647200 -->\n",
       "<g class=\"node\" id=\"node53\">\n",
       "<title>140430263647200</title>\n",
       "<polygon fill=\"none\" points=\"56,-1387.5 56,-1423.5 273,-1423.5 273,-1387.5 56,-1387.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"164.5\" y=\"-1401.8\">bn3a_branch2c: BatchNormalization</text>\n",
       "</g>\n",
       "<!-- 140430263646360&#45;&gt;140430263647200 -->\n",
       "<g class=\"edge\" id=\"edge58\">\n",
       "<title>140430263646360-&gt;140430263647200</title>\n",
       "<path d=\"M158.4775,-1460.4551C159.3622,-1452.3828 160.4259,-1442.6764 161.4116,-1433.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"164.9072,-1433.9122 162.5175,-1423.5904 157.9489,-1433.1495 164.9072,-1433.9122\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263647536 -->\n",
       "<g class=\"node\" id=\"node54\">\n",
       "<title>140430263647536</title>\n",
       "<polygon fill=\"none\" points=\"192.5,-1314.5 192.5,-1350.5 272.5,-1350.5 272.5,-1314.5 192.5,-1314.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"232.5\" y=\"-1328.8\">add_7: Add</text>\n",
       "</g>\n",
       "<!-- 140430263646752&#45;&gt;140430263647536 -->\n",
       "<g class=\"edge\" id=\"edge59\">\n",
       "<title>140430263646752-&gt;140430263647536</title>\n",
       "<path d=\"M310.9798,-1606.2385C313.5632,-1565.0576 315.7248,-1462.6552 281.5,-1387 276.6818,-1376.3492 269.0108,-1366.3237 261.1552,-1357.8464\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"263.4688,-1355.207 253.9656,-1350.523 258.4736,-1360.1109 263.4688,-1355.207\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263647200&#45;&gt;140430263647536 -->\n",
       "<g class=\"edge\" id=\"edge60\">\n",
       "<title>140430263647200-&gt;140430263647536</title>\n",
       "<path d=\"M181.309,-1387.4551C189.5639,-1378.5932 199.6535,-1367.7616 208.6864,-1358.0646\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"211.3937,-1360.2932 215.6487,-1350.5904 206.2716,-1355.522 211.3937,-1360.2932\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263647592 -->\n",
       "<g class=\"node\" id=\"node55\">\n",
       "<title>140430263647592</title>\n",
       "<polygon fill=\"none\" points=\"155,-1241.5 155,-1277.5 310,-1277.5 310,-1241.5 155,-1241.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"232.5\" y=\"-1255.8\">activation_15: Activation</text>\n",
       "</g>\n",
       "<!-- 140430263647536&#45;&gt;140430263647592 -->\n",
       "<g class=\"edge\" id=\"edge61\">\n",
       "<title>140430263647536-&gt;140430263647592</title>\n",
       "<path d=\"M232.5,-1314.4551C232.5,-1306.3828 232.5,-1296.6764 232.5,-1287.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"236.0001,-1287.5903 232.5,-1277.5904 229.0001,-1287.5904 236.0001,-1287.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263647648 -->\n",
       "<g class=\"node\" id=\"node56\">\n",
       "<title>140430263647648</title>\n",
       "<polygon fill=\"none\" points=\"87,-1168.5 87,-1204.5 242,-1204.5 242,-1168.5 87,-1168.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"164.5\" y=\"-1182.8\">res3b_branch2a: Conv2D</text>\n",
       "</g>\n",
       "<!-- 140430263647592&#45;&gt;140430263647648 -->\n",
       "<g class=\"edge\" id=\"edge62\">\n",
       "<title>140430263647592-&gt;140430263647648</title>\n",
       "<path d=\"M215.691,-1241.4551C207.4361,-1232.5932 197.3465,-1221.7616 188.3136,-1212.0646\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"190.7284,-1209.522 181.3513,-1204.5904 185.6063,-1214.2932 190.7284,-1209.522\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263681992 -->\n",
       "<g class=\"node\" id=\"node61\">\n",
       "<title>140430263681992</title>\n",
       "<polygon fill=\"none\" points=\"177.5,-803.5 177.5,-839.5 257.5,-839.5 257.5,-803.5 177.5,-803.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"217.5\" y=\"-817.8\">add_8: Add</text>\n",
       "</g>\n",
       "<!-- 140430263647592&#45;&gt;140430263681992 -->\n",
       "<g class=\"edge\" id=\"edge67\">\n",
       "<title>140430263647592-&gt;140430263681992</title>\n",
       "<path d=\"M243.952,-1241.3993C259.8032,-1214.5636 286.5,-1162.1457 286.5,-1113.5 286.5,-1113.5 286.5,-1113.5 286.5,-967.5 286.5,-925.9658 286.4417,-912.9635 267.5,-876 262.1199,-865.501 254.1615,-855.5184 246.1684,-847.0337\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"248.4163,-844.3298 238.891,-839.6909 243.4445,-849.2573 248.4163,-844.3298\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263648040 -->\n",
       "<g class=\"node\" id=\"node57\">\n",
       "<title>140430263648040</title>\n",
       "<polygon fill=\"none\" points=\"40.5,-1095.5 40.5,-1131.5 258.5,-1131.5 258.5,-1095.5 40.5,-1095.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"149.5\" y=\"-1109.8\">bn3b_branch2a: BatchNormalization</text>\n",
       "</g>\n",
       "<!-- 140430263647648&#45;&gt;140430263648040 -->\n",
       "<g class=\"edge\" id=\"edge63\">\n",
       "<title>140430263647648-&gt;140430263648040</title>\n",
       "<path d=\"M160.7921,-1168.4551C159.1154,-1160.2951 157.0956,-1150.4652 155.2306,-1141.3887\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"158.6584,-1140.6812 153.2172,-1131.5904 151.8016,-1142.0902 158.6584,-1140.6812\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263615384 -->\n",
       "<g class=\"node\" id=\"node58\">\n",
       "<title>140430263615384</title>\n",
       "<polygon fill=\"none\" points=\"72,-1022.5 72,-1058.5 227,-1058.5 227,-1022.5 72,-1022.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"149.5\" y=\"-1036.8\">activation_16: Activation</text>\n",
       "</g>\n",
       "<!-- 140430263648040&#45;&gt;140430263615384 -->\n",
       "<g class=\"edge\" id=\"edge64\">\n",
       "<title>140430263648040-&gt;140430263615384</title>\n",
       "<path d=\"M149.5,-1095.4551C149.5,-1087.3828 149.5,-1077.6764 149.5,-1068.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"153.0001,-1068.5903 149.5,-1058.5904 146.0001,-1068.5904 153.0001,-1068.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263681264 -->\n",
       "<g class=\"node\" id=\"node59\">\n",
       "<title>140430263681264</title>\n",
       "<polygon fill=\"none\" points=\"72,-949.5 72,-985.5 227,-985.5 227,-949.5 72,-949.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"149.5\" y=\"-963.8\">res3b_branch2c: Conv2D</text>\n",
       "</g>\n",
       "<!-- 140430263615384&#45;&gt;140430263681264 -->\n",
       "<g class=\"edge\" id=\"edge65\">\n",
       "<title>140430263615384-&gt;140430263681264</title>\n",
       "<path d=\"M149.5,-1022.4551C149.5,-1014.3828 149.5,-1004.6764 149.5,-995.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"153.0001,-995.5903 149.5,-985.5904 146.0001,-995.5904 153.0001,-995.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263681656 -->\n",
       "<g class=\"node\" id=\"node60\">\n",
       "<title>140430263681656</title>\n",
       "<polygon fill=\"none\" points=\"40.5,-876.5 40.5,-912.5 258.5,-912.5 258.5,-876.5 40.5,-876.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"149.5\" y=\"-890.8\">bn3b_branch2c: BatchNormalization</text>\n",
       "</g>\n",
       "<!-- 140430263681264&#45;&gt;140430263681656 -->\n",
       "<g class=\"edge\" id=\"edge66\">\n",
       "<title>140430263681264-&gt;140430263681656</title>\n",
       "<path d=\"M149.5,-949.4551C149.5,-941.3828 149.5,-931.6764 149.5,-922.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"153.0001,-922.5903 149.5,-912.5904 146.0001,-922.5904 153.0001,-922.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263681656&#45;&gt;140430263681992 -->\n",
       "<g class=\"edge\" id=\"edge68\">\n",
       "<title>140430263681656-&gt;140430263681992</title>\n",
       "<path d=\"M166.309,-876.4551C174.5639,-867.5932 184.6535,-856.7616 193.6864,-847.0646\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"196.3937,-849.2932 200.6487,-839.5904 191.2716,-844.522 196.3937,-849.2932\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263682048 -->\n",
       "<g class=\"node\" id=\"node62\">\n",
       "<title>140430263682048</title>\n",
       "<polygon fill=\"none\" points=\"140,-730.5 140,-766.5 295,-766.5 295,-730.5 140,-730.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"217.5\" y=\"-744.8\">activation_17: Activation</text>\n",
       "</g>\n",
       "<!-- 140430263681992&#45;&gt;140430263682048 -->\n",
       "<g class=\"edge\" id=\"edge69\">\n",
       "<title>140430263681992-&gt;140430263682048</title>\n",
       "<path d=\"M217.5,-803.4551C217.5,-795.3828 217.5,-785.6764 217.5,-776.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"221.0001,-776.5903 217.5,-766.5904 214.0001,-776.5904 221.0001,-776.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263682104 -->\n",
       "<g class=\"node\" id=\"node63\">\n",
       "<title>140430263682104</title>\n",
       "<polygon fill=\"none\" points=\"72,-657.5 72,-693.5 227,-693.5 227,-657.5 72,-657.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"149.5\" y=\"-671.8\">res3c_branch2a: Conv2D</text>\n",
       "</g>\n",
       "<!-- 140430263682048&#45;&gt;140430263682104 -->\n",
       "<g class=\"edge\" id=\"edge70\">\n",
       "<title>140430263682048-&gt;140430263682104</title>\n",
       "<path d=\"M200.691,-730.4551C192.4361,-721.5932 182.3465,-710.7616 173.3136,-701.0646\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"175.7284,-698.522 166.3513,-693.5904 170.6063,-703.2932 175.7284,-698.522\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263683616 -->\n",
       "<g class=\"node\" id=\"node68\">\n",
       "<title>140430263683616</title>\n",
       "<polygon fill=\"none\" points=\"162.5,-292.5 162.5,-328.5 242.5,-328.5 242.5,-292.5 162.5,-292.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"202.5\" y=\"-306.8\">add_9: Add</text>\n",
       "</g>\n",
       "<!-- 140430263682048&#45;&gt;140430263683616 -->\n",
       "<g class=\"edge\" id=\"edge75\">\n",
       "<title>140430263682048-&gt;140430263683616</title>\n",
       "<path d=\"M228.952,-730.3993C244.8032,-703.5636 271.5,-651.1457 271.5,-602.5 271.5,-602.5 271.5,-602.5 271.5,-456.5 271.5,-414.8732 270.4913,-402.0421 251.5,-365 246.1667,-354.5975 238.3503,-344.6421 230.5201,-336.1527\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"232.8675,-333.5455 223.396,-328.7976 227.8394,-338.4157 232.8675,-333.5455\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263682496 -->\n",
       "<g class=\"node\" id=\"node64\">\n",
       "<title>140430263682496</title>\n",
       "<polygon fill=\"none\" points=\"26,-584.5 26,-620.5 243,-620.5 243,-584.5 26,-584.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"134.5\" y=\"-598.8\">bn3c_branch2a: BatchNormalization</text>\n",
       "</g>\n",
       "<!-- 140430263682104&#45;&gt;140430263682496 -->\n",
       "<g class=\"edge\" id=\"edge71\">\n",
       "<title>140430263682104-&gt;140430263682496</title>\n",
       "<path d=\"M145.7921,-657.4551C144.1154,-649.2951 142.0956,-639.4652 140.2306,-630.3887\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"143.6584,-629.6812 138.2172,-620.5904 136.8016,-631.0902 143.6584,-629.6812\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263682832 -->\n",
       "<g class=\"node\" id=\"node65\">\n",
       "<title>140430263682832</title>\n",
       "<polygon fill=\"none\" points=\"57,-511.5 57,-547.5 212,-547.5 212,-511.5 57,-511.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"134.5\" y=\"-525.8\">activation_18: Activation</text>\n",
       "</g>\n",
       "<!-- 140430263682496&#45;&gt;140430263682832 -->\n",
       "<g class=\"edge\" id=\"edge72\">\n",
       "<title>140430263682496-&gt;140430263682832</title>\n",
       "<path d=\"M134.5,-584.4551C134.5,-576.3828 134.5,-566.6764 134.5,-557.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"138.0001,-557.5903 134.5,-547.5904 131.0001,-557.5904 138.0001,-557.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263682888 -->\n",
       "<g class=\"node\" id=\"node66\">\n",
       "<title>140430263682888</title>\n",
       "<polygon fill=\"none\" points=\"57,-438.5 57,-474.5 212,-474.5 212,-438.5 57,-438.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"134.5\" y=\"-452.8\">res3c_branch2c: Conv2D</text>\n",
       "</g>\n",
       "<!-- 140430263682832&#45;&gt;140430263682888 -->\n",
       "<g class=\"edge\" id=\"edge73\">\n",
       "<title>140430263682832-&gt;140430263682888</title>\n",
       "<path d=\"M134.5,-511.4551C134.5,-503.3828 134.5,-493.6764 134.5,-484.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"138.0001,-484.5903 134.5,-474.5904 131.0001,-484.5904 138.0001,-484.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263683280 -->\n",
       "<g class=\"node\" id=\"node67\">\n",
       "<title>140430263683280</title>\n",
       "<polygon fill=\"none\" points=\"26,-365.5 26,-401.5 243,-401.5 243,-365.5 26,-365.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"134.5\" y=\"-379.8\">bn3c_branch2c: BatchNormalization</text>\n",
       "</g>\n",
       "<!-- 140430263682888&#45;&gt;140430263683280 -->\n",
       "<g class=\"edge\" id=\"edge74\">\n",
       "<title>140430263682888-&gt;140430263683280</title>\n",
       "<path d=\"M134.5,-438.4551C134.5,-430.3828 134.5,-420.6764 134.5,-411.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"138.0001,-411.5903 134.5,-401.5904 131.0001,-411.5904 138.0001,-411.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263683280&#45;&gt;140430263683616 -->\n",
       "<g class=\"edge\" id=\"edge76\">\n",
       "<title>140430263683280-&gt;140430263683616</title>\n",
       "<path d=\"M151.309,-365.4551C159.5639,-356.5932 169.6535,-345.7616 178.6864,-336.0646\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"181.3937,-338.2932 185.6487,-328.5904 176.2716,-333.522 181.3937,-338.2932\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263683672 -->\n",
       "<g class=\"node\" id=\"node69\">\n",
       "<title>140430263683672</title>\n",
       "<polygon fill=\"none\" points=\"125,-219.5 125,-255.5 280,-255.5 280,-219.5 125,-219.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"202.5\" y=\"-233.8\">activation_19: Activation</text>\n",
       "</g>\n",
       "<!-- 140430263683616&#45;&gt;140430263683672 -->\n",
       "<g class=\"edge\" id=\"edge77\">\n",
       "<title>140430263683616-&gt;140430263683672</title>\n",
       "<path d=\"M202.5,-292.4551C202.5,-284.3828 202.5,-274.6764 202.5,-265.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"206.0001,-265.5903 202.5,-255.5904 199.0001,-265.5904 206.0001,-265.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263683728 -->\n",
       "<g class=\"node\" id=\"node70\">\n",
       "<title>140430263683728</title>\n",
       "<polygon fill=\"none\" points=\"113,-146.5 113,-182.5 292,-182.5 292,-146.5 113,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"202.5\" y=\"-160.8\">avg_pool: AveragePooling2D</text>\n",
       "</g>\n",
       "<!-- 140430263683672&#45;&gt;140430263683728 -->\n",
       "<g class=\"edge\" id=\"edge78\">\n",
       "<title>140430263683672-&gt;140430263683728</title>\n",
       "<path d=\"M202.5,-219.4551C202.5,-211.3828 202.5,-201.6764 202.5,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"206.0001,-192.5903 202.5,-182.5904 199.0001,-192.5904 206.0001,-192.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263683896 -->\n",
       "<g class=\"node\" id=\"node71\">\n",
       "<title>140430263683896</title>\n",
       "<polygon fill=\"none\" points=\"147.5,-73.5 147.5,-109.5 257.5,-109.5 257.5,-73.5 147.5,-73.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"202.5\" y=\"-87.8\">flatten_1: Flatten</text>\n",
       "</g>\n",
       "<!-- 140430263683728&#45;&gt;140430263683896 -->\n",
       "<g class=\"edge\" id=\"edge79\">\n",
       "<title>140430263683728-&gt;140430263683896</title>\n",
       "<path d=\"M202.5,-146.4551C202.5,-138.3828 202.5,-128.6764 202.5,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"206.0001,-119.5903 202.5,-109.5904 199.0001,-119.5904 206.0001,-119.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140430263684008 -->\n",
       "<g class=\"node\" id=\"node72\">\n",
       "<title>140430263684008</title>\n",
       "<polygon fill=\"none\" points=\"161.5,-.5 161.5,-36.5 243.5,-36.5 243.5,-.5 161.5,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"202.5\" y=\"-14.8\">fc10: Dense</text>\n",
       "</g>\n",
       "<!-- 140430263683896&#45;&gt;140430263684008 -->\n",
       "<g class=\"edge\" id=\"edge80\">\n",
       "<title>140430263683896-&gt;140430263684008</title>\n",
       "<path d=\"M202.5,-73.4551C202.5,-65.3828 202.5,-55.6764 202.5,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"206.0001,-46.5903 202.5,-36.5904 199.0001,-46.5904 206.0001,-46.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(model, to_file='resnetv1_model.png', show_shapes=True, show_layer_names=False)\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callback function\n",
    "\n",
    "This single callback function saves the loss history, validation and training accuracies, and implements learning rate decay after 80, 120, 160 and 180 epochs. The function also keeps track of validation accuracy in all the epochs and saves the model architecture and weights in an epoch to the disk if the validation accuracy in that epoch is better than the best validation accuracy obtained in any of the previous epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCallbackFunction(keras.callbacks.Callback):\n",
    "\n",
    "    def on_train_begin(self, logs={} ):\n",
    "        #Learning rate schedule\n",
    "        #Changed after 80,120,160,180 epochs \n",
    "        \n",
    "        self.k = 0\n",
    "        \n",
    "        #Keeping track of number of epochs \n",
    "        self.epoch_n = 0 \n",
    "        \n",
    "        #Learning rates list\n",
    "        self.lrs_in_epoch = [1e-4,1e-5,1e-6,1e-7]\n",
    "        \n",
    "        #History of losses and accuracies \n",
    "        self.loss = []\n",
    "        self.val_acc =[]\n",
    "        self.train_acc = []\n",
    "\n",
    "        #monitoring improvement of validation accuracy \n",
    "        #Setting initial val acc to negative infinity \n",
    "        self.val_prev = -float(\"inf\")\n",
    "        \n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.loss.append(logs.get('loss'))\n",
    "      \n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        \n",
    "        #Storing validation and training accuracies of the epoch\n",
    "        self.val_acc.append(logs.get('val_acc'))\n",
    "        self.train_acc.append(logs.get('acc'))\n",
    "\n",
    "        #Incrementing number of epochs \n",
    "        self.epoch_n +=1\n",
    "        \n",
    "        #Saving model if val acc improves compared to best previous epoch\n",
    "        if logs.get('val_acc') > self.val_prev: \n",
    "            print('Validation accuracy improved! Saving model. \\n')\n",
    "        \n",
    "            #Saving model \n",
    "            json_string = model.to_json()\n",
    "            with open('resnet_v1_models/model_epoch'+str(self.epoch_n)+'_json.pkl', 'wb') as m:\n",
    "                pickle.dump(json_string, m)\n",
    "            model.save_weights('resnet_v1_models/model_epoch'+str(self.epoch_n)+'_weights.h5')\n",
    "            \n",
    "            #Saving current better val acc to compare with next epoch's val acc\n",
    "            self.val_prev = logs.get('val_acc')\n",
    "            \n",
    "        else: \n",
    "            print('Validation accuracy did not improve. Moving on. \\n')\n",
    "        \n",
    "        #Printing learning rate \n",
    "        LR = K.get_value(self.model.optimizer.lr)\n",
    "        print('Current learning rate: ',LR )\n",
    "\n",
    "            \n",
    "        #Adjusting learning rate     \n",
    "        if self.epoch_n == 80 or self.epoch_n == 120 or self.epoch_n == 160 or self.epoch_n == 180:\n",
    "            K.set_value(self.model.optimizer.lr,self.lrs_in_epoch[self.k])\n",
    "            self.k+=1\n",
    "    \n",
    "\n",
    "#Main \n",
    "\n",
    "#Creating an instance of the callback function\n",
    "history_cb = MyCallbackFunction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling and fitting model \n",
    "\n",
    "Using adam optimizer, categorical cross-entropy as loss function and a batch size of 32. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real time data augmentation enabled.\n",
      "\n",
      "Initial Learning rate:  0.001\n",
      "Epoch 1/200\n",
      "1563/1562 [==============================] - 74s 47ms/step - loss: 1.5092 - acc: 0.4952 - val_loss: 1.2819 - val_acc: 0.5885\n",
      "Validation accuracy improved! Saving model. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 2/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 1.1185 - acc: 0.6515 - val_loss: 1.0249 - val_acc: 0.6902\n",
      "Validation accuracy improved! Saving model. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 3/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.9693 - acc: 0.7118 - val_loss: 0.9156 - val_acc: 0.7359\n",
      "Validation accuracy improved! Saving model. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 4/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.8900 - acc: 0.7430 - val_loss: 0.8640 - val_acc: 0.7575\n",
      "Validation accuracy improved! Saving model. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 5/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.8287 - acc: 0.7676 - val_loss: 0.8188 - val_acc: 0.7707\n",
      "Validation accuracy improved! Saving model. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 6/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.7879 - acc: 0.7817 - val_loss: 0.7834 - val_acc: 0.7915\n",
      "Validation accuracy improved! Saving model. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 7/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.7523 - acc: 0.7964 - val_loss: 0.7814 - val_acc: 0.7918\n",
      "Validation accuracy improved! Saving model. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 8/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.7269 - acc: 0.8060 - val_loss: 0.7585 - val_acc: 0.8029\n",
      "Validation accuracy improved! Saving model. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 9/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.7131 - acc: 0.8146 - val_loss: 0.7195 - val_acc: 0.8175\n",
      "Validation accuracy improved! Saving model. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 10/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.6908 - acc: 0.8231 - val_loss: 0.7322 - val_acc: 0.8107\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 11/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.6788 - acc: 0.8269 - val_loss: 0.7167 - val_acc: 0.8187\n",
      "Validation accuracy improved! Saving model. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 12/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.6702 - acc: 0.8316 - val_loss: 0.7240 - val_acc: 0.8103\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 13/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.6519 - acc: 0.8390 - val_loss: 0.6771 - val_acc: 0.8292\n",
      "Validation accuracy improved! Saving model. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 14/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.6466 - acc: 0.8398 - val_loss: 0.6648 - val_acc: 0.8369\n",
      "Validation accuracy improved! Saving model. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 15/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.6356 - acc: 0.8444 - val_loss: 0.6765 - val_acc: 0.8359\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 16/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.6218 - acc: 0.8503 - val_loss: 0.6676 - val_acc: 0.8380\n",
      "Validation accuracy improved! Saving model. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 17/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.6165 - acc: 0.8521 - val_loss: 0.6500 - val_acc: 0.8414\n",
      "Validation accuracy improved! Saving model. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 18/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.6130 - acc: 0.8551 - val_loss: 0.6585 - val_acc: 0.8399\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 19/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.6025 - acc: 0.8586 - val_loss: 0.6473 - val_acc: 0.8434\n",
      "Validation accuracy improved! Saving model. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 20/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.6005 - acc: 0.8600 - val_loss: 0.6422 - val_acc: 0.8455\n",
      "Validation accuracy improved! Saving model. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 21/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.5927 - acc: 0.8633 - val_loss: 0.6619 - val_acc: 0.8459\n",
      "Validation accuracy improved! Saving model. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 22/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.5904 - acc: 0.8628 - val_loss: 0.6377 - val_acc: 0.8500\n",
      "Validation accuracy improved! Saving model. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 23/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.5886 - acc: 0.8657 - val_loss: 0.6329 - val_acc: 0.8506\n",
      "Validation accuracy improved! Saving model. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 24/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.5787 - acc: 0.8676 - val_loss: 0.6441 - val_acc: 0.8506\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 25/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.5762 - acc: 0.8697 - val_loss: 0.6403 - val_acc: 0.8495\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 26/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.5714 - acc: 0.8725 - val_loss: 0.6188 - val_acc: 0.8591\n",
      "Validation accuracy improved! Saving model. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 27/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.5691 - acc: 0.8726 - val_loss: 0.6339 - val_acc: 0.8536\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 28/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.5661 - acc: 0.8731 - val_loss: 0.6310 - val_acc: 0.8538\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 29/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.5660 - acc: 0.8747 - val_loss: 0.6234 - val_acc: 0.8563\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 30/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.5643 - acc: 0.8757 - val_loss: 0.6089 - val_acc: 0.8635\n",
      "Validation accuracy improved! Saving model. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 31/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.5566 - acc: 0.8785 - val_loss: 0.6410 - val_acc: 0.8507\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 32/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.5519 - acc: 0.8786 - val_loss: 0.6225 - val_acc: 0.8609\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 33/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.5562 - acc: 0.8783 - val_loss: 0.6184 - val_acc: 0.8574\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 34/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.5525 - acc: 0.8800 - val_loss: 0.6251 - val_acc: 0.8548\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 35/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.5465 - acc: 0.8814 - val_loss: 0.6132 - val_acc: 0.8631\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 36/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.5454 - acc: 0.8816 - val_loss: 0.6105 - val_acc: 0.8629\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 37/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.5415 - acc: 0.8847 - val_loss: 0.6256 - val_acc: 0.8592\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 38/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.5392 - acc: 0.8845 - val_loss: 0.6286 - val_acc: 0.8569\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 39/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.5384 - acc: 0.8849 - val_loss: 0.6348 - val_acc: 0.8598\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 40/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.5396 - acc: 0.8823 - val_loss: 0.6335 - val_acc: 0.8578\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 41/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.5354 - acc: 0.8847 - val_loss: 0.6188 - val_acc: 0.8637\n",
      "Validation accuracy improved! Saving model. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 42/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.5307 - acc: 0.8870 - val_loss: 0.6123 - val_acc: 0.8628\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 43/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.5373 - acc: 0.8858 - val_loss: 0.6326 - val_acc: 0.8549\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 44/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.5303 - acc: 0.8881 - val_loss: 0.6195 - val_acc: 0.8617\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 45/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.5315 - acc: 0.8857 - val_loss: 0.6013 - val_acc: 0.8692\n",
      "Validation accuracy improved! Saving model. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 46/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.5314 - acc: 0.8875 - val_loss: 0.6151 - val_acc: 0.8635\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 47/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.5261 - acc: 0.8868 - val_loss: 0.6076 - val_acc: 0.8617\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 48/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.5240 - acc: 0.8898 - val_loss: 0.5950 - val_acc: 0.8666\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 49/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.5247 - acc: 0.8911 - val_loss: 0.6013 - val_acc: 0.8665\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 50/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.5175 - acc: 0.8932 - val_loss: 0.5999 - val_acc: 0.8660\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 51/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.5237 - acc: 0.8900 - val_loss: 0.6197 - val_acc: 0.8601\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 52/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.5175 - acc: 0.8924 - val_loss: 0.5806 - val_acc: 0.8733\n",
      "Validation accuracy improved! Saving model. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 53/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.5168 - acc: 0.8932 - val_loss: 0.5945 - val_acc: 0.8749\n",
      "Validation accuracy improved! Saving model. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 54/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.5146 - acc: 0.8939 - val_loss: 0.6135 - val_acc: 0.8622\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 55/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.5171 - acc: 0.8938 - val_loss: 0.6042 - val_acc: 0.8669\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 56/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.5140 - acc: 0.8934 - val_loss: 0.5853 - val_acc: 0.8728\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 57/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.5152 - acc: 0.8941 - val_loss: 0.6233 - val_acc: 0.8632\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 58/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.5122 - acc: 0.8938 - val_loss: 0.6127 - val_acc: 0.8657\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 59/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.5104 - acc: 0.8957 - val_loss: 0.6024 - val_acc: 0.8678\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 60/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.5091 - acc: 0.8958 - val_loss: 0.5964 - val_acc: 0.8702\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 61/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.5130 - acc: 0.8945 - val_loss: 0.5951 - val_acc: 0.8699\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 62/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.5077 - acc: 0.8955 - val_loss: 0.6075 - val_acc: 0.8679\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 63/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.5117 - acc: 0.8940 - val_loss: 0.6057 - val_acc: 0.8677\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 64/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.5074 - acc: 0.8968 - val_loss: 0.5955 - val_acc: 0.8715\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 65/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.5072 - acc: 0.8966 - val_loss: 0.5845 - val_acc: 0.8735\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 66/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.5044 - acc: 0.8970 - val_loss: 0.5898 - val_acc: 0.8731\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 67/200\n",
      "1563/1562 [==============================] - 72s 46ms/step - loss: 0.4997 - acc: 0.8994 - val_loss: 0.6285 - val_acc: 0.8630\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 68/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.5008 - acc: 0.9001 - val_loss: 0.5888 - val_acc: 0.8755\n",
      "Validation accuracy improved! Saving model. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 69/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.5001 - acc: 0.8982 - val_loss: 0.5912 - val_acc: 0.8734\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 70/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.5012 - acc: 0.8984 - val_loss: 0.5965 - val_acc: 0.8717\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 71/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.4984 - acc: 0.9003 - val_loss: 0.5784 - val_acc: 0.8766\n",
      "Validation accuracy improved! Saving model. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 72/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.5012 - acc: 0.8987 - val_loss: 0.5889 - val_acc: 0.8719\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 73/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.4975 - acc: 0.9011 - val_loss: 0.5889 - val_acc: 0.8743\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 74/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.4963 - acc: 0.9003 - val_loss: 0.5774 - val_acc: 0.8745\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 75/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.4952 - acc: 0.9014 - val_loss: 0.5956 - val_acc: 0.8710\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 76/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.4943 - acc: 0.9013 - val_loss: 0.6205 - val_acc: 0.8636\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 77/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.4961 - acc: 0.8990 - val_loss: 0.6061 - val_acc: 0.8705\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 78/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.4924 - acc: 0.9015 - val_loss: 0.5867 - val_acc: 0.8713\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 79/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.4969 - acc: 0.8992 - val_loss: 0.6035 - val_acc: 0.8696\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 80/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.4949 - acc: 0.9004 - val_loss: 0.5935 - val_acc: 0.8717\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  0.001\n",
      "Epoch 81/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.4084 - acc: 0.9308 - val_loss: 0.5110 - val_acc: 0.8979\n",
      "Validation accuracy improved! Saving model. \n",
      "\n",
      "Current learning rate:  1e-04\n",
      "Epoch 82/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.3772 - acc: 0.9411 - val_loss: 0.5007 - val_acc: 0.8987\n",
      "Validation accuracy improved! Saving model. \n",
      "\n",
      "Current learning rate:  1e-04\n",
      "Epoch 83/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.3606 - acc: 0.9440 - val_loss: 0.4973 - val_acc: 0.8984\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-04\n",
      "Epoch 84/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.3496 - acc: 0.9472 - val_loss: 0.4898 - val_acc: 0.9002\n",
      "Validation accuracy improved! Saving model. \n",
      "\n",
      "Current learning rate:  1e-04\n",
      "Epoch 85/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.3400 - acc: 0.9497 - val_loss: 0.4899 - val_acc: 0.9013\n",
      "Validation accuracy improved! Saving model. \n",
      "\n",
      "Current learning rate:  1e-04\n",
      "Epoch 86/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.3292 - acc: 0.9516 - val_loss: 0.4834 - val_acc: 0.9012\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-04\n",
      "Epoch 87/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.3221 - acc: 0.9530 - val_loss: 0.4782 - val_acc: 0.9034\n",
      "Validation accuracy improved! Saving model. \n",
      "\n",
      "Current learning rate:  1e-04\n",
      "Epoch 88/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.3156 - acc: 0.9540 - val_loss: 0.4760 - val_acc: 0.9039\n",
      "Validation accuracy improved! Saving model. \n",
      "\n",
      "Current learning rate:  1e-04\n",
      "Epoch 89/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.3095 - acc: 0.9556 - val_loss: 0.4693 - val_acc: 0.9061\n",
      "Validation accuracy improved! Saving model. \n",
      "\n",
      "Current learning rate:  1e-04\n",
      "Epoch 90/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.3047 - acc: 0.9564 - val_loss: 0.4686 - val_acc: 0.9047\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-04\n",
      "Epoch 91/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.2980 - acc: 0.9575 - val_loss: 0.4653 - val_acc: 0.9058\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-04\n",
      "Epoch 92/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.2935 - acc: 0.9575 - val_loss: 0.4681 - val_acc: 0.9044\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-04\n",
      "Epoch 93/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.2862 - acc: 0.9596 - val_loss: 0.4607 - val_acc: 0.9076\n",
      "Validation accuracy improved! Saving model. \n",
      "\n",
      "Current learning rate:  1e-04\n",
      "Epoch 94/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.2826 - acc: 0.9595 - val_loss: 0.4613 - val_acc: 0.9050\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-04\n",
      "Epoch 95/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.2824 - acc: 0.9592 - val_loss: 0.4630 - val_acc: 0.9041\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-04\n",
      "Epoch 96/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.2725 - acc: 0.9626 - val_loss: 0.4587 - val_acc: 0.9076\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-04\n",
      "Epoch 97/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.2678 - acc: 0.9624 - val_loss: 0.4580 - val_acc: 0.9057\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-04\n",
      "Epoch 98/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.2654 - acc: 0.9635 - val_loss: 0.4625 - val_acc: 0.9073\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-04\n",
      "Epoch 99/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.2620 - acc: 0.9640 - val_loss: 0.4555 - val_acc: 0.9075\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-04\n",
      "Epoch 100/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.2548 - acc: 0.9661 - val_loss: 0.4599 - val_acc: 0.9056\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-04\n",
      "Epoch 101/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.2530 - acc: 0.9660 - val_loss: 0.4547 - val_acc: 0.9066\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-04\n",
      "Epoch 102/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.2501 - acc: 0.9662 - val_loss: 0.4557 - val_acc: 0.9037\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-04\n",
      "Epoch 103/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.2483 - acc: 0.9658 - val_loss: 0.4552 - val_acc: 0.9045\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-04\n",
      "Epoch 104/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.2454 - acc: 0.9672 - val_loss: 0.4640 - val_acc: 0.9050\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-04\n",
      "Epoch 105/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.2424 - acc: 0.9671 - val_loss: 0.4517 - val_acc: 0.9061\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-04\n",
      "Epoch 106/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.2399 - acc: 0.9672 - val_loss: 0.4554 - val_acc: 0.9042\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-04\n",
      "Epoch 107/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.2364 - acc: 0.9686 - val_loss: 0.4542 - val_acc: 0.9045\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-04\n",
      "Epoch 108/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.2338 - acc: 0.9681 - val_loss: 0.4533 - val_acc: 0.9042\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-04\n",
      "Epoch 109/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.2310 - acc: 0.9691 - val_loss: 0.4548 - val_acc: 0.9055\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-04\n",
      "Epoch 110/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.2302 - acc: 0.9679 - val_loss: 0.4512 - val_acc: 0.9050\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-04\n",
      "Epoch 111/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.2272 - acc: 0.9696 - val_loss: 0.4499 - val_acc: 0.9061\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-04\n",
      "Epoch 112/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.2238 - acc: 0.9700 - val_loss: 0.4513 - val_acc: 0.9058\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-04\n",
      "Epoch 113/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.2202 - acc: 0.9713 - val_loss: 0.4508 - val_acc: 0.9058\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-04\n",
      "Epoch 114/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.2184 - acc: 0.9714 - val_loss: 0.4523 - val_acc: 0.9047\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-04\n",
      "Epoch 115/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.2153 - acc: 0.9719 - val_loss: 0.4568 - val_acc: 0.9052\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-04\n",
      "Epoch 116/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.2151 - acc: 0.9718 - val_loss: 0.4582 - val_acc: 0.9057\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-04\n",
      "Epoch 117/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.2125 - acc: 0.9727 - val_loss: 0.4673 - val_acc: 0.9032\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-04\n",
      "Epoch 118/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.2100 - acc: 0.9728 - val_loss: 0.4597 - val_acc: 0.9038\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-04\n",
      "Epoch 119/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.2113 - acc: 0.9713 - val_loss: 0.4544 - val_acc: 0.9017\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-04\n",
      "Epoch 120/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.2059 - acc: 0.9732 - val_loss: 0.4516 - val_acc: 0.9069\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-04\n",
      "Epoch 121/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.2000 - acc: 0.9751 - val_loss: 0.4449 - val_acc: 0.9062\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-05\n",
      "Epoch 122/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.1921 - acc: 0.9786 - val_loss: 0.4420 - val_acc: 0.9076\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-05\n",
      "Epoch 123/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.1916 - acc: 0.9793 - val_loss: 0.4425 - val_acc: 0.9079\n",
      "Validation accuracy improved! Saving model. \n",
      "\n",
      "Current learning rate:  1e-05\n",
      "Epoch 124/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.1907 - acc: 0.9786 - val_loss: 0.4409 - val_acc: 0.9081\n",
      "Validation accuracy improved! Saving model. \n",
      "\n",
      "Current learning rate:  1e-05\n",
      "Epoch 125/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.1916 - acc: 0.9782 - val_loss: 0.4417 - val_acc: 0.9082\n",
      "Validation accuracy improved! Saving model. \n",
      "\n",
      "Current learning rate:  1e-05\n",
      "Epoch 126/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.1877 - acc: 0.9804 - val_loss: 0.4422 - val_acc: 0.9084\n",
      "Validation accuracy improved! Saving model. \n",
      "\n",
      "Current learning rate:  1e-05\n",
      "Epoch 127/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.1904 - acc: 0.9793 - val_loss: 0.4400 - val_acc: 0.9088\n",
      "Validation accuracy improved! Saving model. \n",
      "\n",
      "Current learning rate:  1e-05\n",
      "Epoch 128/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.1867 - acc: 0.9806 - val_loss: 0.4416 - val_acc: 0.9081\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-05\n",
      "Epoch 129/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.1864 - acc: 0.9808 - val_loss: 0.4412 - val_acc: 0.9083\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-05\n",
      "Epoch 130/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.1848 - acc: 0.9811 - val_loss: 0.4421 - val_acc: 0.9081\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-05\n",
      "Epoch 131/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.1859 - acc: 0.9808 - val_loss: 0.4415 - val_acc: 0.9073\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-05\n",
      "Epoch 132/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.1850 - acc: 0.9809 - val_loss: 0.4446 - val_acc: 0.9081\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-05\n",
      "Epoch 133/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.1848 - acc: 0.9804 - val_loss: 0.4443 - val_acc: 0.9088\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-05\n",
      "Epoch 134/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.1855 - acc: 0.9808 - val_loss: 0.4444 - val_acc: 0.9080\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-05\n",
      "Epoch 135/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.1829 - acc: 0.9813 - val_loss: 0.4437 - val_acc: 0.9077\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-05\n",
      "Epoch 136/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.1815 - acc: 0.9819 - val_loss: 0.4438 - val_acc: 0.9086\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-05\n",
      "Epoch 137/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.1811 - acc: 0.9820 - val_loss: 0.4443 - val_acc: 0.9066\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-05\n",
      "Epoch 138/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.1817 - acc: 0.9813 - val_loss: 0.4448 - val_acc: 0.9072\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-05\n",
      "Epoch 139/200\n",
      "1563/1562 [==============================] - 71s 46ms/step - loss: 0.1816 - acc: 0.9820 - val_loss: 0.4440 - val_acc: 0.9074\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-05\n",
      "Epoch 140/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.1836 - acc: 0.9806 - val_loss: 0.4435 - val_acc: 0.9071\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-05\n",
      "Epoch 141/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.1796 - acc: 0.9824 - val_loss: 0.4442 - val_acc: 0.9086\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-05\n",
      "Epoch 142/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.1828 - acc: 0.9801 - val_loss: 0.4455 - val_acc: 0.9078\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-05\n",
      "Epoch 143/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.1807 - acc: 0.9816 - val_loss: 0.4463 - val_acc: 0.9075\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-05\n",
      "Epoch 144/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.1790 - acc: 0.9818 - val_loss: 0.4469 - val_acc: 0.9086\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-05\n",
      "Epoch 145/200\n",
      "1563/1562 [==============================] - 71s 46ms/step - loss: 0.1790 - acc: 0.9819 - val_loss: 0.4466 - val_acc: 0.9074\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-05\n",
      "Epoch 146/200\n",
      "1563/1562 [==============================] - 72s 46ms/step - loss: 0.1788 - acc: 0.9826 - val_loss: 0.4475 - val_acc: 0.9081\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-05\n",
      "Epoch 147/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.1794 - acc: 0.9811 - val_loss: 0.4461 - val_acc: 0.9076\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-05\n",
      "Epoch 148/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.1785 - acc: 0.9823 - val_loss: 0.4457 - val_acc: 0.9084\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-05\n",
      "Epoch 149/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.1760 - acc: 0.9829 - val_loss: 0.4461 - val_acc: 0.9071\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-05\n",
      "Epoch 150/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.1764 - acc: 0.9833 - val_loss: 0.4452 - val_acc: 0.9072\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-05\n",
      "Epoch 151/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.1772 - acc: 0.9827 - val_loss: 0.4450 - val_acc: 0.9069\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-05\n",
      "Epoch 152/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.1756 - acc: 0.9830 - val_loss: 0.4461 - val_acc: 0.9081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-05\n",
      "Epoch 153/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.1772 - acc: 0.9822 - val_loss: 0.4490 - val_acc: 0.9070\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-05\n",
      "Epoch 154/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.1751 - acc: 0.9831 - val_loss: 0.4471 - val_acc: 0.9071\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-05\n",
      "Epoch 155/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.1747 - acc: 0.9832 - val_loss: 0.4482 - val_acc: 0.9070\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-05\n",
      "Epoch 156/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.1738 - acc: 0.9833 - val_loss: 0.4481 - val_acc: 0.9081\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-05\n",
      "Epoch 157/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.1758 - acc: 0.9826 - val_loss: 0.4483 - val_acc: 0.9071\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-05\n",
      "Epoch 158/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.1751 - acc: 0.9828 - val_loss: 0.4493 - val_acc: 0.9068\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-05\n",
      "Epoch 159/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.1745 - acc: 0.9827 - val_loss: 0.4500 - val_acc: 0.9063\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-05\n",
      "Epoch 160/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.1753 - acc: 0.9825 - val_loss: 0.4487 - val_acc: 0.9061\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-05\n",
      "Epoch 161/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.1727 - acc: 0.9833 - val_loss: 0.4485 - val_acc: 0.9065\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-06\n",
      "Epoch 162/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.1736 - acc: 0.9835 - val_loss: 0.4483 - val_acc: 0.9061\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-06\n",
      "Epoch 163/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.1718 - acc: 0.9844 - val_loss: 0.4485 - val_acc: 0.9061\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-06\n",
      "Epoch 164/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.1714 - acc: 0.9841 - val_loss: 0.4481 - val_acc: 0.9062\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-06\n",
      "Epoch 165/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.1745 - acc: 0.9828 - val_loss: 0.4479 - val_acc: 0.9062\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-06\n",
      "Epoch 166/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.1728 - acc: 0.9837 - val_loss: 0.4478 - val_acc: 0.9062\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-06\n",
      "Epoch 167/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.1725 - acc: 0.9841 - val_loss: 0.4481 - val_acc: 0.9059\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-06\n",
      "Epoch 168/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.1729 - acc: 0.9837 - val_loss: 0.4479 - val_acc: 0.9059\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-06\n",
      "Epoch 169/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.1720 - acc: 0.9843 - val_loss: 0.4480 - val_acc: 0.9064\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-06\n",
      "Epoch 170/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.1739 - acc: 0.9834 - val_loss: 0.4477 - val_acc: 0.9065\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-06\n",
      "Epoch 171/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.1720 - acc: 0.9840 - val_loss: 0.4477 - val_acc: 0.9062\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-06\n",
      "Epoch 172/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.1731 - acc: 0.9838 - val_loss: 0.4480 - val_acc: 0.9063\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-06\n",
      "Epoch 173/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.1722 - acc: 0.9836 - val_loss: 0.4480 - val_acc: 0.9066\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-06\n",
      "Epoch 174/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.1726 - acc: 0.9837 - val_loss: 0.4480 - val_acc: 0.9064\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-06\n",
      "Epoch 175/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.1721 - acc: 0.9835 - val_loss: 0.4479 - val_acc: 0.9067\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-06\n",
      "Epoch 176/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.1725 - acc: 0.9835 - val_loss: 0.4479 - val_acc: 0.9068\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-06\n",
      "Epoch 177/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.1720 - acc: 0.9836 - val_loss: 0.4479 - val_acc: 0.9074\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-06\n",
      "Epoch 178/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.1715 - acc: 0.9839 - val_loss: 0.4477 - val_acc: 0.9068\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-06\n",
      "Epoch 179/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.1702 - acc: 0.9850 - val_loss: 0.4478 - val_acc: 0.9064\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-06\n",
      "Epoch 180/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.1725 - acc: 0.9839 - val_loss: 0.4479 - val_acc: 0.9063\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-06\n",
      "Epoch 181/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.1731 - acc: 0.9834 - val_loss: 0.4479 - val_acc: 0.9064\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-07\n",
      "Epoch 182/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.1734 - acc: 0.9839 - val_loss: 0.4479 - val_acc: 0.9065\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-07\n",
      "Epoch 183/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.1714 - acc: 0.9840 - val_loss: 0.4479 - val_acc: 0.9065\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-07\n",
      "Epoch 184/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.1714 - acc: 0.9840 - val_loss: 0.4479 - val_acc: 0.9064\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-07\n",
      "Epoch 185/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.1725 - acc: 0.9838 - val_loss: 0.4479 - val_acc: 0.9065\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-07\n",
      "Epoch 186/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.1715 - acc: 0.9843 - val_loss: 0.4479 - val_acc: 0.9064\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-07\n",
      "Epoch 187/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.1714 - acc: 0.9850 - val_loss: 0.4479 - val_acc: 0.9065\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-07\n",
      "Epoch 188/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.1706 - acc: 0.9846 - val_loss: 0.4479 - val_acc: 0.9064\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-07\n",
      "Epoch 189/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.1721 - acc: 0.9836 - val_loss: 0.4479 - val_acc: 0.9063\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-07\n",
      "Epoch 190/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.1723 - acc: 0.9834 - val_loss: 0.4479 - val_acc: 0.9063\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-07\n",
      "Epoch 191/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.1722 - acc: 0.9835 - val_loss: 0.4479 - val_acc: 0.9063\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-07\n",
      "Epoch 192/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.1725 - acc: 0.9838 - val_loss: 0.4479 - val_acc: 0.9063\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-07\n",
      "Epoch 193/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.1723 - acc: 0.9839 - val_loss: 0.4479 - val_acc: 0.9064\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-07\n",
      "Epoch 194/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.1720 - acc: 0.9837 - val_loss: 0.4479 - val_acc: 0.9064\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-07\n",
      "Epoch 195/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.1733 - acc: 0.9831 - val_loss: 0.4479 - val_acc: 0.9065\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-07\n",
      "Epoch 196/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.1711 - acc: 0.9841 - val_loss: 0.4479 - val_acc: 0.9064\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-07\n",
      "Epoch 197/200\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.1738 - acc: 0.9834 - val_loss: 0.4479 - val_acc: 0.9065\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-07\n",
      "Epoch 198/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.1733 - acc: 0.9838 - val_loss: 0.4479 - val_acc: 0.9066\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-07\n",
      "Epoch 199/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.1721 - acc: 0.9832 - val_loss: 0.4479 - val_acc: 0.9067\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-07\n",
      "Epoch 200/200\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.1720 - acc: 0.9838 - val_loss: 0.4479 - val_acc: 0.9066\n",
      "Validation accuracy did not improve. Moving on. \n",
      "\n",
      "Current learning rate:  1e-07\n",
      "10000/10000 [==============================] - 3s 332us/step\n",
      "Loss = 0.44789256501197816\n",
      "Test Accuracy = 0.9066\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3Xl8VfWd//HXR4zijkqqVNC4W2rr0tS1dZzqdJQ62v5sZ7AzrXZs6TL+qq0zHdDWWquttS2tVCviitaquBZlEyoiIFuAEHYJyBICJBCyJ2T7zh/3JLlJ7s05SU5yc27ez8fjPnLuOd97zudwL5977vd8F3POISIi6eWgVAcgIiLhU3IXEUlDSu4iImlIyV1EJA0puYuIpCEldxGRNKTkLiKShpTcRUTSkJK7iEgaOjhVBx46dKjLyspK1eFFRCJp+fLle51zmX7lUpbcs7KyyMnJSdXhRUQiycy2BSmnahkRkTSk5C4ikoaU3EVE0pCSu4hIGlJyFxFJQ0ruIiJpSMldRCQNRS65f7ingvHvbGRv5YFUhyIi0m9FLrlv2lPJhHfzKamqS3UoIiL9VuSSu4iI+FNyFxFJQ0ruIiJpKLLJ3blURyAi0n9FLrmbpToCEZH+L3LJXURE/Cm5i4ikISV3EZE0FNnk7tAdVRGRZCKX3HU/VUTEn29yN7PBZrbUzFaZ2Voz+0WCMreYWbGZ5XqPb/dOuCIiEkSQCbIPAF9wzlWaWQawwMxmOOcWtyv3snPutvBDFBGRrvJN7s45B1R6TzO8hyq8RUT6sUB17mY2yMxygSJgtnNuSYJiN5pZnpm9amYjQo0yAfVQFRFJLlByd841OufOB4YDF5nZue2KvAVkOec+DcwBJifaj5mNMbMcM8spLi7uVsDqoSoi4q9LrWWcc6XAe8A17dbvc841z57xBPCZJK+f5JzLds5lZ2ZmdiNcEREJIkhrmUwzG+ItHwZcDWxoV2ZY3NPrgfVhBikiIl0TpLXMMGCymQ0i9mUwxTn3tpndB+Q456YCPzSz64EGoAS4pbcCFhERf0Fay+QBFyRYf0/c8jhgXLih+cXVl0cTEYmWyPVQVR9VERF/EUzuIiLiR8ldRCQNRTa5a1RIEZHkIpfc1YlJRMRf5JK7iIj4U3IXEUlDSu4iImkossldnZhERJKLXHLX/VQREX+RS+4iIuJPyV1EJA0puYuIpCEldxGRNBS55G7qoioi4ityyV1ERPwpuYuIpCEldxGRNBRkguzBZrbUzFaZ2Voz+0WCMoea2ctmlm9mS8wsqzeCjaceqiIiyQW5cj8AfME5dx5wPnCNmV3SrsytwH7n3BnAH4DfhBtmK91OFRHx55vcXUyl9zTDe7S/br4BmOwtvwpcZWrWIiKSMoHq3M1skJnlAkXAbOfcknZFTgJ2ADjnGoAy4PgwAxURkeACJXfnXKNz7nxgOHCRmZ3brkiiq/QOteJmNsbMcswsp7i4uOvRiohIIF1qLeOcKwXeA65pt6kAGAFgZgcDxwAlCV4/yTmX7ZzLzszM7FbALfvSHKoiIkkFaS2TaWZDvOXDgKuBDe2KTQVu9pa/CrzrXO+0Z1FNvoiIv4MDlBkGTDazQcS+DKY45942s/uAHOfcVOAp4Hkzyyd2xT661yIWERFfvsndOZcHXJBg/T1xy7XA18INTUREuks9VEVE0lBkk7t6qIqIJBe55K4bqiIi/iKX3EVExJ+Su4hIGlJyFxFJQ5FN7rqfKiKSXOSSu2nQXxERX5FL7iIi4k/JXUQkDSm5i4ikocgm914adFJEJC1EL7nrfqqIiK/oJXcREfGl5C4ikoaU3EVE0lBkk7tup4qIJBe55K77qSIi/oJMkD3CzOaa2XozW2tmtycoc6WZlZlZrve4J9G+RESkbwSZILsBuNM5t8LMjgKWm9ls59y6duXmO+euCz9EERHpKt8rd+fcLufcCm+5AlgPnNTbgYmISPd1qc7dzLKAC4AlCTZfamarzGyGmX0yhNg6pQ6qIiLJBamWAcDMjgReA+5wzpW327wCOMU5V2lmo4A3gTMT7GMMMAbg5JNP7lbATV5Wr6lr7NbrRUQGgkBX7maWQSyxv+Cce739dudcuXOu0lueDmSY2dAE5SY557Kdc9mZmZndCvhvuYUAjJ+9sVuvFxEZCIK0ljHgKWC9c258kjIneuUws4u8/e4LM9BmtfWxK/ZqXbmLiCQVpFrmcuAbwGozy/XW3QWcDOCcmwh8Ffi+mTUANcBo10vDNjbPxKQ6dxGR5HyTu3NuAT59h5xzjwCPhBVUZ8yLxKmPqohIUpHroSoiIv4im9xVLSMiklzkkntzUt9UVJnaQERE+rHIJfequoZUhyAi0u9FLrmLiIg/JXcRkTSk5C4ikoYil9zNNF2HiIifyCV3ERHxF7nkrut2ERF/kUvuIiLiL3LJXVXuIiL+IpfcRUTEX+SSuy7cRUT8RS65i4iIPyV3EZE0FLnkrk5MIiL+IpfcRUTEn5K7iEga8k3uZjbCzOaa2XozW2tmtycoY2Y2wczyzSzPzC7snXDVWkZEJAjfCbKBBuBO59wKMzsKWG5ms51z6+LKXAuc6T0uBh7z/oZOVe4iIv58r9ydc7uccyu85QpgPXBSu2I3AM+5mMXAEDMbFnq0IiISSJfq3M0sC7gAWNJu00nAjrjnBXT8AsDMxphZjpnlFBcXdy1SEREJLHByN7MjgdeAO5xz5e03J3iJ67DCuUnOuWznXHZmZmbXIk0id0cpO0qqQ9mXiEi6CFLnjpllEEvsLzjnXk9QpAAYEfd8OFDY8/ASRtOy1NDYxJcfXQjA1ge/1DuHExGJoCCtZQx4CljvnBufpNhU4Jteq5lLgDLn3K4Q44yLp3U5Z9v+3jiEiEjkBblyvxz4BrDazHK9dXcBJwM45yYC04FRQD5QDXwr/FBj1FhGRMSfb3J3zi3AJ6c65xzwX2EF1emx4pZHT1rcF4cUEYkc9VAVEUlDkUvuqpYREfEXveSu7C4i4ityyV1ERPwpuYuIpCEldxGRNBS55G66pSoi4ityyb2+sSnVIYiI9HuRS+5rCstSHYKISL8XueTuOow1KSIi7UUuuaudu4iIv+gld91QFRHxFbnknsz2fZqwQ0SkWdok9+LK2lSHICLSb0QuuSercy+vbejbQERE+rHIJfdbLstKuP4Hf1nRt4GIiPRjkUvuRxyaeH6RmvrGTl839rU8/uG3c3sjJBGRfidyyb2zppDXPjyfzcWVCbe9tGwH23TTVUQGiCATZD9tZkVmtibJ9ivNrMzMcr3HPeGHGcz6XeVc9ft5qTq8iEi/EWSC7GeBR4DnOikz3zl3XSgRiYhIj/leuTvn3gdK+iCWQIJ0YsoaO42dpTUAvLWqkEWb9/V2WD1W39jELc8sZdWO0lSHIiJpIMiVexCXmtkqoBD4b+fc2kSFzGwMMAbg5JNP7taBjjksI1C5uRuKyBhk/O9rq7t1nL720d4q3ttYzM79Ncz+8T+kOhwRibgwbqiuAE5xzp0H/Al4M1lB59wk51y2cy47MzOzWwc7+8QjA5VzEJnELiISth4nd+dcuXOu0lueDmSY2dAeR5ZUsLFlPiquCvWoReW1LNi0N9R9JqJBL0UkDD1O7mZ2olmsgaKZXeTtsxcruYOlv6cXftTp9rveWE3W2GmBj/rlRxfyH08tYfm2ElZu3x/4dUEl+8raureKK387l6IKDa8gIsEFaQr5IrAIONvMCszsVjP7npl9zyvyVWCNV+c+ARjtXP8ddf13szYC8Ncl27v0usKyWHK98bFFfOXPH3T5uG+u3Mm+ygO+5dr/0z2z8CO27qtmet6uLh9TRAauIK1lbnLODXPOZTjnhjvnnnLOTXTOTfS2P+Kc+6Rz7jzn3CXOua5nvi7p2ZC/j8zNT7i+uq7t2DRXj5/Hr6av79Gxmu0uq+WOl3MZ8/zypGW6M079ztIaPtxT0YPIRCRdRa6Ham/YUlzJyHtmMWXZDm776wqWflRCflElk97fEsr+m+d93VMebtXK5Q++yxf/8H6H9Wt2llFT1/lwDCKS3pTcgfveXgfAGyt38nbeLv718UVttne1CqerdpXVcMfLuUDyOwpB67lKq+u47k8L+JG3PxEZmJTcgfc2Fne6/a43Ojap/MVba7nxsXBqoH759jrW7CwPZV/NA6jlpqgzVENjE0s/6jd93kQGrAGZ3P+WuzPh+h37gw8s9szCrSzfFn6rmWS6WiXvUtSo8k/v5vOvjy9i2VYleJFUGpDJ/faXWqss3lzZmugL9teEdoxZa3eztrAMgC61HeqkbNWBBhq8+vtkmodn6G57pR+9nMv3nl9OfWMTdQ2dHyuR/KLYqJz3v72uw01qEek7kUvu3WlV0pk7elg3vXjLPm776wpOHde2zfx3n1/OlyYsaLOup7F/8uez+N5fkre4CeMYb6zcycy1u7n4V39n5D0zu72fVQVl/NZrdioifS+ssWUGrNGTFne6/faXVjLqU8M6LdPY1HqZ7XdDdc76okBx9bRSpqSqrluvi+9sVampD0VSJnJX7sOPPSzVISTV1NQxpf4tt5DvdtK+HWDW2j2hxZDswn3l9v2Mn/0hAOsKy3l+0dbQjhlv2dZw7kPUNTS1+dITka6J3JX7oQcPSnUIST04cwNXnpXJT99MOK9JBw/N3MCRg4O9BX61LVc8NJfy2nre+dEVQMc69+ZetT/+p7MYNWE+AN+4NCvQsVPhrJ/O4JLTjuOlMZemOhSRSIrclXtfax4XPohJ72/h608uYcvexIOW7SipaWmi2Njk+PN7m3loZtt66VqfuWABXlte0KFD1PaSakqr6+NuqAa76m1obOLbk5elrOlkZxZvUYsbke5Scvdx+YPvhrq/Lz+6sNPtu8oS92KNT9V3vrKKbz61NGG5rt5Q3bG/hjnri7jjpZVde2EArywv4DczN4S+XxHxp+SeIlNydiTdtrustqUZoiXJ1nuTDELW/Lp9VXWcftf0luaYPZXol8DawjJeXBrrvfu33J0JZ5F6akHno3NCbPiHsur6ngcpIi2U3FNgdUEZ415PPpHIJb/+O2NfzwOSV6/si2vNMnHe5pblJ+a3jofT2OR4IYShE6auKuTUcdPZtq9tddOXJixoOY/bX8rlhgS/SoK0lf/C7+e13AcQkXAouafAvzyywLfM6yt28vqKAiYv2gZATie9YR+c0Vr18czCrW22zdtYTFFc/XxOkp6jndXQT8srBGD9rnCGSEgk/t7Gk/PDGbBNZCCLXGuZgeTHU1a1LE/r5njuO0truHFi6xg4X53YdlC0LcWxHqX1Aa6wk92jba6a6amte6soqa7j/mnhDLUsMpApuQ8AO0qSt/hpnme2MMmN3GVbS5jrDaz25IKPOOTgg7jqEye0KdNZFZOf+NZBV/7uvW7vR0TaUrXMADZ3Y1GbG7PvrN3doczXJi5qqTdfvm0/t07OYdzreYGbWgLM31Sc8Iapc45zftb9IQ5EJDkl9wHsW88sa/P8tr8Gaw754tId7Cn3nzKw2TeeWsqtk2PHKquup6I2lugvC7mZqYi08q2WMbOngeuAIufcuQm2G/AwMAqoBm5xzq0IO1DpfXU+I07Ge6CLUxA2Twd43n3vAPA//3x20jb9ItJzQa7cnwWu6WT7tcCZ3mMM8FjPw5L+bsGmzic4ac8BZTWtVTMaMVKkdwWZIPt9oLN+4DcAz7mYxcAQM+t8GESJvP1d7HRUUdvA/7yyyr+giIQijDr3k4D47pYF3roOzGyMmeWYWU5xcdeu/CT63lkX3uiXItK5MJJ7ov7xCZtSOOcmOeeynXPZmZmZIRxaREQSCSO5FwAj4p4PBwpD2G9SN100wr+QiMgAFkZynwp802IuAcqcc93rThlYyHPtiYikmSBNIV8ErgSGmlkB8HMgA8A5NxGYTqwZZD6xppDf6q1gmx2W0X8n7JDUejuvkFOOO4JPDT8m1aGIpJRvcnfO3eSz3QH/FVpEAdz5xbN4eqH/ULIy8DR3xNr64JdSHIlIakWyh+oRh2pInIFi1MPJhwKurW/kQIP/zFUiA1Ekk7sMHOu8YYaLKw7w2QfmtPR0BTjnZzO55Fd/D7SfZxd+xGZvBEyRgUDJXSJhzvo9FFcc4GlvZqfs++cAyTtTNcQNpdDY5Lj3rXV8xWeKQ5F0ouQu/V72/XPYX13XZl2yaQabJZq7tfJAQ6hxifRnSu7S7+2tPMCizfsAONDQRE2dfz3723GTm3RleGKRdKE7kxIJjU2xBP3Gyp1MX+3fjSLRiJPJJhsXSUe6cpdI+MC7cofY1Xu8/KJKNsXdaG2vUVfuMgDpyl0i7+rx84DEbdtnrN7F91+ITS+g63YZSHTlLmmjtN1N111lNS2JXWSgUXKXtHH+fbPbPL/12Zw2zxNVuW/YXc6T87d0WL91bxVrdpaFGl93OefIKyjVjWHpEiV3SVsbO6mHb3btw/O5f1psysCy6vqWq/8rf/ce1/1pAQDLt5VQVJF4SsDa+kbWex2tesvUVYVc/8hC3srr5fH4JK0ouUvaam5h08wS1Lo3Xwzvr6rjvPve4fz7ZjN1VdsRq298bBHXTVjQ8vzxeZtZuX0/AHe+soprH55PaXUdT87fwrO9MObR5uIqALaoh610gZK7DBidTQD+33FTAP46weTfRRWtnaZ+PWMDX/nzBwAs9lrx1NQ3cv+09dz71rqwwm0VQnWMc47nF2+jSh25BgwldxlQVheU8ff1Haf727G/umW5K7l0X1WsGmfBpr0d91lSTVnAuWadc1w9fh5vrtyZtEyiXx5BLczfx8/eXMMv3lrb7X1ItCi5y4DyL48s4NbJOYx5LoessdNa1n+4p7XKY3d54vr1zpTVtCbxT907C4DPPzSXq7xmms2amlxLdVFdQxNff2Ixq3aU4lysvf4dL+cmPYZLPHtlIFV1sSv2kqquTWwu0RXZ5P7xYwanOgSJsDAm6y6pam16Gd/7taK2gXv+tgZoOwbOrrIaTrtrOqffNR2AD/dU8MHmfYx7fXXCljy9QZ10B47IJnd1JZe+sDtuGIP8okoK4qpvLvxla9PL9z8sbvO65xZta1nOKygFYH5c1c0T72/h/U2trwnyee5JtUwYZqzexRl3TQ80tk8Yqusa2ozuKV0T2eQu0hcu+XXrePFXj5/HhL9vSlhuXrvkHu/6R2JDDRfFVfc8MH09D83cCPhfTfeH1u3OOb7/wgoamhyFZTUt62vrGznrpzN4O6+wk1d3z8h7ZrXMrCVdFyi5m9k1ZrbRzPLNbGyC7beYWbGZ5XqPb4cfals3fmZ4bx9CpIMpOQXdfu3v3vmwR8c2g2VbS8gaO43iis6HPG6vqw1u9lfVtblJPHPN7oTl9pTXUtfQlHCI5TDMXJv4uM65Ll/V5xWUsnVvVbdj+SB/b5t7K/2db3I3s0HAo8C1wEjgJjMbmaDoy865873HkyHH2cGPrj6TaT/8XG8fRiQUb61KfmVbU9f5dIF/eje/ZfmJ92O9aZdvK2lZt66wnPwi/w5b4D++zrrCcpZvK+GWZ5fxH08taamC2VtVl7B885dG0CqjXWU1HfofdMd/PruMM+6e0aXXXP/IQq783XuByi7bWtImkVfU1vP1J5fwnedy2qzbsLt3O7D1RJAr94uAfOfcFudcHfAScEPvhuXPzBg57OhUhyESSKLml8227K3i7J/ObHm+oyRWrz/vw2L2t0uqTV42vXNKa7v8URPmc/X493lwxoaWce8709jk+M5zOcxau5uK2rZXoqMmzOfGxxaR7/XubR5RM9nQB81rzWJfPFljp9GUIHnvKqsha+w0Lv31uzwUwlX+3I3FSeO646WVfOXPXZ91a8mWfTQ0NlFb38jXJi7i25OXtWyr80YizS9qbVX1rWeWcc0fk8/xm0j2/bP545ye/YILKkhyPwnYEfe8wFvX3o1mlmdmr5rZiFCi86GbqhIV7ydoB5/M5x+ay71T13Lz00u54Jdtx8uZs74IgKoENzUnztvMTU8s9t1/YWkNs9ft4bvPL+dT974TKKZECRtg3sZYPNv2VfOA1/lr5Y5ScnfEbiJv2lPBki37WFfYeoXb2f2JRGrrW8913OureSWnNR2tLSznf1/NI2vsNC5/8F0qDzTwZm4hK7eXBt7/1FWFTFm2g3+btJgJ7+a3dHZbW1jO9NW7cM7RfPolVXU8Ojf2Sypn2/6WfZTX1vOTV1e16SRWXHGAnaU1bf7t9lbW8cc5ie/bhC1Ick+UQdu/028BWc65TwNzgMkJd2Q2xsxyzCynuLhrb3Ay/37xyaHsR6Q3lSSp1kjm2Q+2+pbZXVbbpq1+IoWlNUxZtoPObst+9/kc9lYeSHqzGCA+t8fXvyfqkXvjYx/w5UcXsmL7fv7pD+/zb5MWt7lpvGF3Bd+evKzDKJ7JnPOzmVTXNVB1oIEXl27nf17Na9l23Z8W8LKX7HeW1nDuz2cl3Mf4dza2LLefbvGHL67kJ6/F9rlpTwXOq8qvrmvkBy+s4O431/DZB+a0lP/trI1tXv/Ugo+YMGcTU3IK2rxvn31gDpc/+C6n3TW9TaurvhJkPPcCIP5KfDjQpgLRORf/W/AJ4DeJduScmwRMAsjOzg6lEcAZHzsyjN2I9HvjZ7f9OR/fkife3W+sZmpuIat/8c/c9MRitu2r5vdfOw+Ite8/5rCMNuVnrd3DrLVtq42aJ0TZXVbL1ePnccrxh7ds++2sjWQedShXnfOxTuP9f94QDdCxTn7O+iLOv282G355DYMzBrFy+36+8ucPmP7DzzPy4x2rW0fekzhpBzUh7r7FuT+fxZTvXsrHhwzm+CMObVOuybkOncX+umR7h/1V17V+Qfzy7dYvuN/O2kjGIGPMFae3Kb91XxUn9nHfnCBX7suAM83sVDM7BBgNTI0vYGbD4p5eD3QcnKOXfPPSLIYeeah/QZEB4oUl26k40MCizfvYti9Wf3/3m6tbtr+y3L/FT4N3qd48EUrzfpr95NU8PnP/nA6vS6amPvEN43N+NpP73lrX8uUyasJ8ln5UkrBsdyWaTP1fH1/E534zt8NVfGNT218pyXT2ZfOr6R3vKYyetJg/xH05z91Q5H+QHrIgY0Sb2Sjgj8Ag4Gnn3ANmdh+Q45ybama/JpbUG4AS4PvOuU7vmmRnZ7ucnJzOinSZ309UEUmN80cMaamH93PuSUfz6vcu45yfzfQv3ImvfWZ4oC+y9m6+9BQmx3VC645bLsvyrVpLNHNYEGa23DmX7Vcu0DR7zrnpwPR26+6JWx4HjOtqkCIyMBSW1vgX8qzZWR7onoOf7iR2oMeJHYLdM+ltadVD9S+3XpzqEEQkgaIudrp6cEbvdIoaSNIquX/uzKE8dbPvrxURkbSXVskd4KpPnJDqEEREUi5QnXvUzP7RFSzdWsLwYw9n4+7yhHevRUTSWVom9zNPOIozTzgKgPOGH6PkLiIDTtpVy7Q35PBDmHrb5Vz36WEsHPsF7rj6zFSHJCLS69Lyyr29Tw8fwiNfvxCA2/7xDMpq6jnmsAw+2LyPZ275LEccejBFFbW8klPA3A1FbcaMEBGJokCdmHpDb3RiCstHe6s4evDB7Nhfw+0vrWTUp4Zx6WnH88mPH92lXnmJnDTkMO69/pNthg4VkYGntzsxKbl3UVOTY9GWffzk1Tx2ltZw3BGH8K3Lsvj/V53Z0kP24dHnc97wIeQXVTI4YxCDDjJ2lFQz+JBBfHHkCQzOGNSyv617q1iQv5eTjj2MC0ccyzGHZ/Da8gLufGVVh2PffOkpPL94W5vu0T+6+iy+fvHJfLingn9/cknL+he+fTGXnzGUitp6nlm4tc24JFnHH87Wdt3Jk8l/4FrueDmXt/N2tVn/iWFHs36X/1jWD48+n5++uYaK2gbfsiIDiZJ7P1VWXc/u8lrOPvGoXtl/U5PjQEMTgw4yzCBjUOvtkaoDDfxl8Ta+8/nTOOigtgMyrdlZRklVHVeclel7jMoDDWQMMs7+6UwyjzqUcdeew4+nrOL1H1zGhScf26bsjpJqymvr+cSJR2MWGyvkO8/l8I9nf4wvX3ASxx5+CH+c8yGfHj6EK8/O5C+Lt/GNS07hYC/uxiZHfWMTFbUNHHLwQYx6eD47S2v4zudP5UBDE3d/6ROU1zTw4IwNXHTqsXztMyM47a7picIWSQtK7tKn9lYe6FcDsb22vICxr+dR39gfZhIVCU+/GFtGBo7+lNghNldu83y59Y1NFFcc4LIH3+WS045j8ZZwRw8USSdK7hIZGYMO4uNDDkt6xeOcY21hOT95NY91Ae4HiKQzJXdJG2bGuScdw/TbP+9b9oPNe1ldUMbcjUX6BSBpScldBqTLTh/KZacP5bv/cLp/YWLzeG4vqeaEowdTXlNPwf4a7nt7XaAWQyKpoOQuEsDgjEGc5Q1pccxhGYw47nBmBPiF0BnnHM7FhsPdXFxJwf5q/rpkOzX1jVx+xlB2l9Uyw5uv9NjDM2hscjQ0OaoTTI4t0fLa9y/r9WMouYukiFmsmeuJxwxumV/z3z6rCd8lHGk/toyIyEAUKLmb2TVmttHM8s1sbILth5rZy972JWaWFXagIiISnG9yN7NBwKPAtcBI4CYzG9mu2K3AfufcGcAfgN+EHaiIiAQX5Mr9IiDfObfFOVcHvATc0K7MDcBkb/lV4CozM0REJCWCJPeTgB1xzwu8dQnLOOcagDLg+DACFBGRrguS3BNdgbcf6CNIGcxsjJnlmFlOcXFxkPhERKQbgiT3AmBE3PPhQGGyMmZ2MHAM0KHbn3NuknMu2zmXnZnpP2qhiIh0T5Dkvgw408xONbNDgNHA1HZlpgI3e8tfBd51qRpuUkREgg35a2ajgD8Cg4CnnXMPmNl9QI5zbqqZDQaeBy4gdsU+2jm3xWefxcC2bsY9FNjbzdf2FzqH1It6/KBz6C/68hxOcc75Vn2kbDz3njCznCDjGfdnOofUi3r8oHPoL/rjOaiHqohIGlJyFxFJQ1FN7pNSHUAIdA6pF/X4QefQX/S7c4hknbuIiHQuqlfuIiLSicgld78RKlMQz1YzW21muWbAMOBHAAAEVUlEQVSW4607zsxmm9km7++x3nozswle7HlmdmHcfm72ym8ys5vj1n/G23++99oej9ljZk+bWZGZrYlb1+sxJztGiOdwr5nt9N6LXK8Jb/O2cV48G83sn+PWJ/w8ef06lnixvuz18QhtBFQzG2Fmc81svZmtNbPbvfWReR86OYdIvA9mNtjMlprZKi/+X3T3mGGdV6his8FE40Gsnf1m4DTgEGAVMDLFMW0FhrZb9xAw1lseC/zGWx4FzCA2XMMlwBJv/XHAFu/vsd7ysd62pcCl3mtmANeGEPMVwIXAmr6MOdkxQjyHe4H/TlB2pPdZORQ41fsMDers8wRMIdZfA2Ai8H1v+QfARG95NPByN+MfBlzoLR8FfOjFGZn3oZNziMT74P27HOktZwBLvH/bLh0zzPMK85GypNjND9OlwKy45+OAcSmOaSsdk/tGYFjcf4CN3vLjwE3tywE3AY/HrX/cWzcM2BC3vk25HsadRdvE2OsxJztGiOdwL4mTSpvPCTDL+ywl/Dx5/+n3Age3/9w1v9ZbPtgrZyG8H38D/imK70OCc4jc+wAcDqwALu7qMcM8rzAfUauWCTJCZV9zwDtmttzMxnjrTnDO7QLw/n7MW58s/s7WFyRY3xv6IuZkxwjTbV61xdNx1Q1dPYfjgVIXG+G0/TmEPgKq9/P+AmJXjpF8H9qdA0TkfTCzQWaWCxQBs4ldaXf1mGGeV2iiltwDjT7Zxy53zl1IbDKT/zKzKzopmyz+rq7vS1GK+THgdOB8YBfwe299mOcQ6vmZ2ZHAa8AdzrnyzoomOW7K34cE5xCZ98E51+icO5/YgIgXAZ/oxjH75XsTteQeZITKPuWcK/T+FgFvEPuA7DGzYQDe3yKveLL4O1s/PMH63tAXMSc7Riicc3u8/6xNwBPE3ovunMNeYIjFRjhtfw6BRkANwswyiCXFF5xzr3urI/U+JDqHqL0PXsylwHvE6ty7eswwzys0UUvuQUao7DNmdoSZHdW8DHwRWEPbUTJvJlYXibf+m17Lh0uAMu9n8Szgi2Z2rPcT9ovE6uB2ARVmdonX0uGbcfsKW1/EnOwYoWhOWJ6vEHsvmo872mvtcCpwJrGbjQk/Ty5WETqX2Ain7WMNZQRU79/mKWC9c2583KbIvA/JziEq74OZZZrZEG/5MOBqYH03jhnmeYUn7Er83n4QazXwIbG6sbtTHMtpxO6ArwLWNsdDrE7t78Am7+9x3nojNh/tZmA1kB23r/8E8r3Ht+LWZxP7z7EZeIRwbt69SOzncj2xq4tb+yLmZMcI8Rye92LMI/Yfblhc+bu9eDYS1+Io2efJe2+Xeuf2CnCot36w9zzf235aN+P/HLGf4nlArvcYFaX3oZNziMT7AHwaWOnFuQa4p7vHDOu8wnyoh6qISBqKWrWMiIgEoOQuIpKGlNxFRNKQkruISBpSchcRSUNK7iIiaUjJXUQkDSm5i4ikof8D/cJPOkBh2fYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f128ceba9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f134c3797f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f128cdeceb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Initial learning rate and optimizer\n",
    "initial_rate = 0.001\n",
    "opt = optimizers.Adam(lr=initial_rate)\n",
    "\n",
    "#Compiling model\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#Data generator for training data  \n",
    "#No data generator is used for testing data\n",
    "data_generator = ImageDataGenerator(\n",
    "                featurewise_center=False,\n",
    "                samplewise_center = False,\n",
    "                featurewise_std_normalization = False,\n",
    "                samplewise_std_normalization=False,\n",
    "                zca_whitening= False,\n",
    "                rotation_range=0,\n",
    "                width_shift_range=0.1,\n",
    "                height_shift_range=0.1,\n",
    "                horizontal_flip=True,\n",
    "                vertical_flip=False,\n",
    "                )\n",
    "\n",
    "print('Real time data augmentation enabled.\\n')\n",
    "print('Initial Learning rate: ',initial_rate)\n",
    "\n",
    "#Fitting model\n",
    "model.fit_generator(data_generator.flow(X_train, Y_train, batch_size=32),\n",
    "                    validation_data = (X_test, Y_test),\n",
    "                    epochs = 200, \n",
    "                    steps_per_epoch = data_generator.flow(X_train,Y_train,batch_size=32).n/32,\n",
    "                    callbacks = [history_cb])\n",
    "\n",
    "\n",
    "#Model evaluation \n",
    "preds = model.evaluate(X_test, Y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))\n",
    "\n",
    "#Plotting loss and accuracies\n",
    "plt.plot(history_cb.loss)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history_cb.train_acc)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history_cb.val_acc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best model reconstruction from JSON:\n",
    "json_string = pickle.load( open( \"aws_trained/model_epoch127_json.pkl\", \"rb\" ) )\n",
    "model = model_from_json(json_string)\n",
    "model.load_weights('aws_trained/model_epoch127_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Code from http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html \n",
    "\n",
    "\"\"\"\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.1f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[0.92 0.01 0.02 0.01 0.01 0.   0.   0.01 0.01 0.01]\n",
      " [0.   0.96 0.   0.   0.   0.   0.   0.   0.   0.03]\n",
      " [0.03 0.   0.88 0.02 0.03 0.02 0.02 0.01 0.01 0.  ]\n",
      " [0.01 0.   0.02 0.79 0.02 0.09 0.02 0.02 0.01 0.01]\n",
      " [0.01 0.   0.02 0.02 0.92 0.02 0.01 0.01 0.   0.  ]\n",
      " [0.01 0.   0.02 0.07 0.02 0.86 0.01 0.02 0.   0.  ]\n",
      " [0.01 0.   0.02 0.02 0.01 0.01 0.92 0.   0.   0.  ]\n",
      " [0.   0.   0.01 0.01 0.01 0.02 0.   0.94 0.   0.  ]\n",
      " [0.03 0.01 0.   0.   0.   0.   0.   0.   0.94 0.01]\n",
      " [0.01 0.02 0.   0.   0.   0.   0.   0.   0.01 0.95]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb8764c4ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Testing accuracy: \n",
      "0.9088\n"
     ]
    }
   ],
   "source": [
    "#Prediction test set \n",
    "p = model.predict(X_test)\n",
    "#Converting from one hot back to integers\n",
    "y_pred = [np.where(r==np.max(r))[0][0] for r in p]\n",
    "\n",
    "#Ground truth\n",
    "a = Y_test\n",
    "#Converting from one hot back to integers\n",
    "y_true = [np.where(r==1)[0][0] for r in a ]\n",
    "\n",
    "#Caulculating confusion matrix \n",
    "cnf_matrix = confusion_matrix(y_true,y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck'],normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(' Testing accuracy: ')\n",
    "pr = model.predict(X_test)\n",
    "ypred = [np.where(r==np.max(r))[0][0] for r in pr]\n",
    "good = [1 for i in range(0,len(ypred)) if y_true[i]==ypred[i]]\n",
    "accuracy = len(good)/len(ypred)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
