{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考：\n",
    "- [Running Deep Learning models in OpenCV](http://cv-tricks.com/how-to/running-deep-learning-models-in-opencv/?utm_campaign=dep-learning-models-in-op&utm_source=sendpulse&utm_medium=email)\n",
    "- [Darknet yolo](https://pjreddie.com/darknet/yolo/)\n",
    "\n",
    " 目前，OpenCV 支持 Caffe，Torch，Tensorflow 和 Darknet。如果您在生产中部署了基于 OpenCV 的模型，例如 Hog + SVM 分类器或基于 Haar 级联的检测器等，并且您希望将其替换为更准确的适当的基于深度学习的模型，则此功能尤其有用。因此，您可以在自己喜欢的深度学习库中训练模型，并在生产基础架构中部署该模型，而不会中断当前的工作流程。在本系列教程中，我们将学习如何将在其他框架中训练的模型部署到 openCV。特别是在这一个，我们将学习：\n",
    "\n",
    "- 如何在 OpenCV 中部署基于 Darknet 的对象检测模型。我们将部署 Yolov2 并在一些图像和视频上运行它。\n",
    "- 在第 $2$ 部分中，我们将部署Sqeezenet模型到openCV以生成预测。\n",
    "- 在第 $3$ 部分中，我们将在 OpenCV 中部署 Tensorflow 模型。\n",
    "\n",
    "# 在 OpenCV 中部署 YOLO-V2 模型\n",
    "\n",
    "```py\n",
    "import cv2\n",
    "model = 'yolov2.weights'\n",
    "config = 'yolov2.cfg'\n",
    "net = cv2.dnn.readNetFromDarknet(config, model)\n",
    "```\n",
    "This little command will give us the network architecture as specified in config loaded with the trained weights of yolov2.\n",
    "\n",
    "## blobFromImage method\n",
    "下一步是批量加载图像并通过网络运行它们。为此，我们使用 `cv2.dnn.blobFromImage` 方法。此方法从输入图像创建 $4$ 维 `blob`。我们来看看这个方法的签名：`blob = cv.dnn.blobFromImage(image, scalefactor, size, mean, swapRB, crop)`\n",
    "\n",
    "- `image`：是我们想要发送到神经网络进行推理的输入图像。\n",
    "- `scalefactor`：如果我们想通过将它们乘以常数来缩放我们的图像。很多时候我们将所有 `uint8` 图像除以 $255$，这样所有像素都在 $0$ 到 $1$ 之间。默认值为 $1.0$，没有缩放。\n",
    "- `size`：输出图像的空间大小。它将等于后续神经网络作为 `blobFromImage` 输出所需的输入大小。\n",
    "- `swapRB`：布尔值，表示我们是否要交换 $3$ 通道图像中的第一个和最后一个通道。OpenCV 假定图像默认为 BGR 格式，但如果我们想将此顺序交换为RGB，我们可以将此标志设置为 `True`，这也是默认值。\n",
    "- `mean`：为了处理强度变化和归一化，有时我们计算训练数据集上的平均像素值，并在训练期间从每个图像中减去它。如果我们在训练期间进行平均减法，那么我们必须在推理期间应用它。这意味着将是对应于 R，G，B 通道的元组。例如，imagenet 数据集上的平均值是 $R = 103.93，G = 116.77，B = 123.68$。如果我们使用 `swapRB = False`，那么这个顺序将是 `(B, G, R)`。\n",
    "- `crop`：布尔标志，指示我们是否要对裁剪图像进行居中。如果将其设置为 `True`，则输入图像将从中心裁剪，使得较小的尺寸等于相应的尺寸尺寸，而其他尺寸等于或大于此尺寸。但是，如果我们将其设置为 `False`，它将保留纵横比并仅调整尺寸大小。\n",
    "\n",
    "YOLO-V2 模型需要大小为 (416,416) 的输入图像，并通过将它们除以 $255$ 来缩放图像。因此，我们使用它的方式如下：\n",
    "`blob = cv.dnn.blobFromImage(frame, 1.0/255.0, (416, 416), True, crop=False)`\n",
    "\n",
    "最后，我们得到输出预测并在输入图像上绘制它们。\n",
    "\n",
    "```py\n",
    "net.setInput(blob)\n",
    "# Run the preprocessed input blog through the network\n",
    "predictions = net.forward()\n",
    "probability_index=5\n",
    "\n",
    "for i in range(predictions.shape[0]):\n",
    "    prob_arr=predictions[i][probability_index:]\n",
    "    confidence=np.amax(prob_arr)\n",
    "    if confidence > min_confidence:\n",
    "        x_center=predictions[i][0]*width\n",
    "        y_center=predictions[i][1]*height\n",
    "        width_box=predictions[i][2]*width\n",
    "        height_box=predictions[i][3]*height\n",
    "        \n",
    "        x1=int(x_center-width_box * 0.5)\n",
    "        y1=int(y_center-height_box * 0.5)\n",
    "        x2=int(x_center+width_box * 0.5)\n",
    "        y2=int(y_center+height_box * 0.5)\n",
    "     \n",
    "        cv.rectangle(frame,(x1,y1),(x2,y2),(0,255,0),1)\n",
    "cv.imshow(winName, frame)\n",
    "```\n",
    "\n",
    "这篇文章的代码可以在 github 上的[代码库](https://github.com/sankit1/cv-tricks.com/tree/master/OpenCV/Running_YOLO)中找到。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
