{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型预设"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-26T07:44:13.510504Z",
     "start_time": "2018-10-26T07:44:10.523632Z"
    },
    "code_folding": [
     118,
     145
    ]
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torchvision import models, transforms\n",
    "from sklearn.semi_supervised import LabelSpreading\n",
    "from sklearn import preprocessing, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Bunch(dict):\n",
    "    '''\n",
    "    分支结构\n",
    "    '''\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.__dict__ = self\n",
    "\n",
    "\n",
    "def use_gpu(use_gpu=True):\n",
    "    '''\n",
    "    指定运算设备\n",
    "    '''\n",
    "    device = torch.device('cuda' if use_gpu else 'cpu')\n",
    "    return device\n",
    "\n",
    "\n",
    "# 数据增强\n",
    "data_transforms = {\n",
    "    'train':\n",
    "    transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "\n",
    "def aug_imgs(X, dataType):\n",
    "    '''\n",
    "    对 X 做预处理\n",
    "    '''\n",
    "    return np.stack([data_transforms[dataType](Image.fromarray(x)) for x in X])\n",
    "\n",
    "\n",
    "class Loader(dict):\n",
    "    \"\"\"\n",
    "    方法\n",
    "    ========\n",
    "    L 为该类的实例\n",
    "    len(L)::返回 batch 的批数\n",
    "    iter(L)::即为数据迭代器\n",
    "\n",
    "    参数\n",
    "    =============\n",
    "    type: 'train', 'test'\n",
    "\n",
    "    Return\n",
    "    ========\n",
    "    可迭代对象（numpy 对象）\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, batch_size, X, Y=None, shuffle=True, *args, **kwargs):\n",
    "        '''\n",
    "        X, Y 均为类 numpy, 可以是 HDF5 \n",
    "        '''\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.__dict__ = self\n",
    "        self.batch_size = batch_size\n",
    "        if shuffle:\n",
    "            self.type = 'train'\n",
    "        else:\n",
    "            self.type = 'test'\n",
    "\n",
    "        self.X = X[:]\n",
    "        self.nrows = self.X.shape[0]\n",
    "        if Y is not None:\n",
    "            self.Y = Y[:]\n",
    "        else:\n",
    "            self.Y = None\n",
    "\n",
    "    def __iter__(self):\n",
    "        idx = np.arange(self.nrows)\n",
    "        if self.type == 'train':\n",
    "            np.random.shuffle(idx)\n",
    "\n",
    "        for start in range(0, self.nrows, self.batch_size):\n",
    "            end = min(start + self.batch_size, self.nrows)\n",
    "            K = idx[start:end].tolist()\n",
    "            if self.Y is None:\n",
    "                yield np.take(self.X[:], K, 0)\n",
    "            else:\n",
    "                yield np.take(self.X[:], K, 0), np.take(self.Y[:], K, 0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return round(len(self.X) / self.batch_size)\n",
    "\n",
    "\n",
    "def cnn_feature(model, batch_size, Xs):\n",
    "    '''\n",
    "    特征提取器\n",
    "    '''\n",
    "    model.eval()\n",
    "    for xs in Loader(batch_size, Xs, shuffle=False):\n",
    "        imgs = torch.tensor(aug_imgs(xs, 'test')).cuda()\n",
    "        out = model(imgs).cpu().detach().numpy()\n",
    "        yield np.squeeze(out)\n",
    "\n",
    "# CNN 训练\n",
    "def train_model(model, loader, num_epochs):\n",
    "    '''\n",
    "    NN 训练\n",
    "    '''\n",
    "    # opt\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    # Observe that all parameters are being optimized\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "    # Decay LR by a factor of 0.1 every 7 epochs\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "    device = use_gpu(True)\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        if loader.type == 'train':\n",
    "            scheduler.step()\n",
    "            model.train()  # Set model to training mode\n",
    "        else:\n",
    "            model.eval()  # Set model to evaluate mode\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        m = 0\n",
    "        # Iterate over data.\n",
    "        for inputs, labels_ in loader:\n",
    "            inputs = aug_imgs(inputs, loader.type)\n",
    "            inputs = torch.from_numpy(inputs)\n",
    "            inputs = inputs.to(device)\n",
    "            labels = torch.LongTensor(labels_).to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            # track history if only in train\n",
    "            with torch.set_grad_enabled(loader.type == 'train'):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                if loader.type == 'train':\n",
    "                    # backward + optimize only if in training phase\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "            # statistics\n",
    "            running_loss += loss.item()\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            m += inputs.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(loader)\n",
    "        epoch_acc = running_corrects.double() / m\n",
    "        print('{} Loss: {:.4f} Acc: {:.4f}'.format(loader.type, epoch_loss,\n",
    "                                                   epoch_acc))\n",
    "\n",
    "        # deep copy the model\n",
    "        if epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据集划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-26T07:44:16.240034Z",
     "start_time": "2018-10-26T07:44:13.512984Z"
    }
   },
   "outputs": [],
   "source": [
    "import tables as tb\n",
    "\n",
    "\n",
    "# 载入数据集\n",
    "data_path = 'E:/xdata/X.h5'\n",
    "dataset = tb.open_file(data_path).root.cifar10\n",
    "xTr = dataset.trainX[:]\n",
    "yTr = dataset.trainY[:]\n",
    "\n",
    "# 数据集划分操作\n",
    "batch_size = 32\n",
    "numLabels = 800\n",
    "test_size = xTr.shape[0] - numLabels\n",
    "\n",
    "trainX, testX, trainY, testY = train_test_split(\n",
    "    xTr, yTr, test_size=test_size, random_state=42, shuffle=True)\n",
    "\n",
    "# 数据集封装\n",
    "trainset = Loader(batch_size, trainX, trainY, shuffle=True)  # 训练集\n",
    "valset = Loader(batch_size, dataset.testX, dataset.testY, shuffle=False)  # 验证集\n",
    "# 测试集，用来做 SSL 的无标签数据集\n",
    "testset = Loader(10000, testX, testY, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-26T07:44:20.982702Z",
     "start_time": "2018-10-26T07:44:16.242501Z"
    }
   },
   "outputs": [],
   "source": [
    "# 模型初始化\n",
    "model = models.resnet50(pretrained=True)\n",
    "num_inFeats = model.fc.in_features\n",
    "model.fc = torch.nn.Linear(num_inFeats, 10)\n",
    "device = use_gpu(True)\n",
    "model = model.to(device)\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-10-26T07:44:12.286Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0\n",
      "^=^^=^^=^^=^^=^^=^^=^^=^^=^^=^^=^^=^^=^^=^^=^^=^^=^^=^^=^^=^\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    features = torch.nn.Sequential(*list(model.children())[:-1])\n",
    "    xTr_features = np.concatenate(\n",
    "        [x for x in cnn_feature(features, batch_size, trainX)])\n",
    "    \n",
    "    print('Iter: %i'%epoch)\n",
    "    print('^=^'*20)\n",
    "    for xTe, yTe in testset:\n",
    "        xTe_features = np.concatenate(\n",
    "            [x for x in cnn_feature(features, batch_size, xTe)])\n",
    "        # SSL, obtain psudo-labels of unlabeled samples\n",
    "        dataX = np.vstack((xTr_features, xTe_features)).astype('float')\n",
    "        dataY = np.concatenate((trainY, yTe))\n",
    "        numSamples = len(dataY)\n",
    "        ind_unlabeled = np.arange(numLabels, numSamples)\n",
    "        dataY[ind_unlabeled] = -1\n",
    "        cls = LabelSpreading(max_iter=150, kernel='rbf', gamma=0.003)\n",
    "        cls.fit(preprocessing.scale(dataX), dataY)\n",
    "        predicted_labels = cls.transduction_[ind_unlabeled]\n",
    "        print()\n",
    "        print(\"SSL: accuracy:%f\" %metrics.accuracy_score(yTe, predicted_labels))\n",
    "        \n",
    "        print('*'*50)\n",
    "        print('Train:')\n",
    "        model = train_model(model, trainset, 10)\n",
    "        print('*'*50)\n",
    "        print('Validate:')\n",
    "        model = train_model(model, valset, 1)\n",
    "        print('*'*50)\n",
    "        print('伪标签训练: ')\n",
    "        unlabelset = Loader(batch_size, xTe, predicted_labels, shuffle=True)\n",
    "        model = train_model(model, unlabelset, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
