{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T13:37:20.119091Z",
     "start_time": "2018-09-27T13:37:17.631707Z"
    }
   },
   "outputs": [],
   "source": [
    "# 导入pandas与numpy工具包。\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 创建特征列表。\n",
    "column_names = [\n",
    "    'Sample code number', 'Clump Thickness', 'Uniformity of Cell Size',\n",
    "    'Uniformity of Cell Shape', 'Marginal Adhesion',\n",
    "    'Single Epithelial Cell Size', 'Bare Nuclei', 'Bland Chromatin',\n",
    "    'Normal Nucleoli', 'Mitoses', 'Class'\n",
    "]\n",
    "\n",
    "# 使用pandas.read_csv函数从互联网读取指定数据。\n",
    "data = pd.read_csv(\n",
    "    'https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data',\n",
    "    names=column_names)\n",
    "\n",
    "# 将?替换为标准缺失值表示。\n",
    "data = data.replace(to_replace='?', value=np.nan)\n",
    "# 丢弃带有缺失值的数据（只要有一个维度有缺失）。\n",
    "data = data.dropna(how='any')\n",
    "\n",
    "# 输出data的数据量和维度。\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T13:37:20.220866Z",
     "start_time": "2018-09-27T13:37:20.200841Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据集的简介见：[breast-cancer-wisconsin](https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.names)\n",
    "\n",
    "我们得知该数据集共有 $699$ 个样本，$11$ 个特征，其中一列特征表示检索的 id, $9$ 列与肿瘤相关的医学特征以及一列表示肿瘤类型的数值。`2` 表示 benign (良性), `4` 表示 malignant (恶性). 该数据集中有 $16$ 个缺失值，并使用 `?` 标出。\n",
    "\n",
    "## 划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T13:37:22.788247Z",
     "start_time": "2018-09-27T13:37:22.414204Z"
    }
   },
   "outputs": [],
   "source": [
    "# 使用sklearn.cross_valiation里的train_test_split模块用于分割数据。\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 随机采样25%的数据用于测试，剩下的75%用于构建训练集合。\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data[column_names[1:10]],\n",
    "    data[column_names[10]],\n",
    "    test_size=0.25,\n",
    "    random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T13:37:23.180156Z",
     "start_time": "2018-09-27T13:37:23.174173Z"
    }
   },
   "outputs": [],
   "source": [
    "# 查验训练样本的数量和类别分布。\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T13:37:23.582116Z",
     "start_time": "2018-09-27T13:37:23.575134Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 查验测试样本的数量和类别分布。\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集的标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T13:37:33.397492Z",
     "start_time": "2018-09-27T13:37:33.344589Z"
    }
   },
   "outputs": [],
   "source": [
    "# 从sklearn.preprocessing里导入StandardScaler。\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# 从sklearn.linear_model里导入LogisticRegression与SGDClassifier。\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# 标准化数据，保证每个维度的特征数据方差为1，均值为0。使得预测结果不会被某些维度过大的特征值而主导。\n",
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用 sklearn 进行  Logistics Regression 学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T13:37:50.705826Z",
     "start_time": "2018-09-27T13:37:50.701869Z"
    }
   },
   "outputs": [],
   "source": [
    "# 初始化LogisticRegression与SGDClassifier。\n",
    "lr = LogisticRegression()\n",
    "sgdc = SGDClassifier(max_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T13:38:36.454818Z",
     "start_time": "2018-09-27T13:38:28.913947Z"
    }
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# 调用LogisticRegression中的fit函数/模块用来训练模型参数。\n",
    "lr.fit(X_train, y_train)\n",
    "# 使用训练好的模型lr对X_test进行预测，结果储存在变量lr_y_predict中。\n",
    "lr_y_predict = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T13:38:44.759542Z",
     "start_time": "2018-09-27T13:38:39.828728Z"
    }
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# 调用SGDClassifier中的fit函数/模块用来训练模型参数。\n",
    "sgdc.fit(X_train, y_train)\n",
    "# 使用训练好的模型sgdc对X_test进行预测，结果储存在变量sgdc_y_predict中。\n",
    "sgdc_y_predict = sgdc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T13:38:53.182993Z",
     "start_time": "2018-09-27T13:38:53.174986Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 从sklearn.metrics里导入classification_report模块。\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 使用逻辑斯蒂回归模型自带的评分函数score获得模型在测试集上的准确性结果。\n",
    "print('Accuracy of LR Classifier:', lr.score(X_test, y_test))\n",
    "# 利用classification_report模块获得LogisticRegression其他三个指标的结果。\n",
    "print(\n",
    "    classification_report(\n",
    "        y_test, lr_y_predict, target_names=['Benign', 'Malignant']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T13:38:54.094782Z",
     "start_time": "2018-09-27T13:38:54.087791Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 使用随机梯度下降模型自带的评分函数score获得模型在测试集上的准确性结果。\n",
    "print('Accuarcy of SGD Classifier:', sgdc.score(X_test, y_test))\n",
    "# 利用classification_report模块获得SGDClassifier其他三个指标的结果。\n",
    "print(\n",
    "    classification_report(\n",
    "        y_test, sgdc_y_predict, target_names=['Benign', 'Malignant']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般说来，`SGDClassifier` 训练速度快于 `LogisticRegression`，适用于 $10$ 万量级的数据；而 `LogisticRegression` 的参数是采用精确解析的方式,模型的精度会相对高一点, 但是对于 $10$ 万量级的数据内存开销很大，有点不切实际。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---------------------\n",
    "\n",
    "# 使用 MXNet 实现 Logistics Regression\n",
    "\n",
    "使用 SGD 进行优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T13:50:05.940198Z",
     "start_time": "2018-09-27T13:50:05.933216Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import mxnet as mx\n",
    "from mxnet import autograd, nd\n",
    "\n",
    "\n",
    "def data_iter(batch_size, features, labels, trainable=True):\n",
    "    '''\n",
    "    数据迭代器\n",
    "    '''\n",
    "    num_examples = len(features)\n",
    "    indices = np.arange(num_examples)\n",
    "    if trainable:\n",
    "        random.shuffle(indices)  # 样本的读取顺序是随机的。\n",
    "    for i in range(0, num_examples, batch_size):\n",
    "        j = np.array(indices[i: min(i + batch_size, num_examples)])\n",
    "        # take 函数根据索引返回对应元素。\n",
    "        yield features.take(j, axis=0), labels.take(j, axis=0)\n",
    "\n",
    "\n",
    "def LR(X, w, b):\n",
    "    '''\n",
    "    Logistics Regression\n",
    "    '''\n",
    "    z = nd.dot(X, w) + b\n",
    "    exp = 1 / (1 + z.exp())\n",
    "    return exp\n",
    "\n",
    "\n",
    "def squared_loss(y_hat, y):\n",
    "    '''\n",
    "    损失函数\n",
    "    '''\n",
    "    return (y_hat - y.reshape(y_hat.shape)) ** 2 / 2\n",
    "\n",
    "\n",
    "def sgd(params, lr, batch_size):\n",
    "    '''\n",
    "    优化算法\n",
    "    '''\n",
    "    for param in params:\n",
    "        param[:] = param - lr * param.grad / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T13:50:06.771220Z",
     "start_time": "2018-09-27T13:50:06.765238Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_features = X_train.shape[1]\n",
    "w = nd.random.normal(shape=(num_features, 1))+0.001\n",
    "b = nd.zeros(1)\n",
    "w.attach_grad()\n",
    "b.attach_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T13:51:42.858234Z",
     "start_time": "2018-09-27T13:51:40.146486Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "num_epochs = 100\n",
    "batch_size = 64\n",
    "\n",
    "for epoch in range(num_epochs):  # 训练模型一共需要 num_epochs 个迭代周期。\n",
    "    # 在一个迭代周期中，使用训练数据集中所有样本一次（假设样本数能够被批量大小整除）。\n",
    "    # X 和 y 分别是小批量样本的特征和标签。\n",
    "    for X, y in data_iter(32, X_train, y_train):\n",
    "        X = nd.array(X)/255\n",
    "        y = nd.array(y)\n",
    "        with autograd.record():\n",
    "            y_hat = LR(X, w, b)\n",
    "            L = squared_loss(y_hat, y)\n",
    "        L.backward()\n",
    "        sgd([w, b], lr, batch_size)  # 使用小批量随机梯度下降迭代模型参数。\n",
    "    train_l = squared_loss(LR(X, w, b), y)\n",
    "    print('epoch %d, loss %f' % (epoch + 1, train_l.mean().asnumpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T13:51:48.677019Z",
     "start_time": "2018-09-27T13:51:48.671037Z"
    }
   },
   "outputs": [],
   "source": [
    "LR_y_predict = LR(nd.array(X_test), w, b).asnumpy()\n",
    "LR_y_predict = np.where(LR_y_predict > .5, 2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T13:51:49.368205Z",
     "start_time": "2018-09-27T13:51:49.361193Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 从sklearn.metrics里导入classification_report模块。\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\n",
    "    classification_report(\n",
    "        y_test<3, LR_y_predict<3, target_names=['Benign', 'Malignant']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T13:20:18.424503Z",
     "start_time": "2018-09-27T13:20:18.407524Z"
    }
   },
   "outputs": [],
   "source": [
    "y_hat = nd.array([[0.1, 0.3, 0.6], [0.3, 0.2, 0.5]])\n",
    "y = nd.array([0, 1])\n",
    "nd.pick(y_hat, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T13:20:20.891257Z",
     "start_time": "2018-09-27T13:20:20.886269Z"
    }
   },
   "outputs": [],
   "source": [
    "y_hat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
