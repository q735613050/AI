# 『统计学习方法』笔记

统计学习包括监督学习、非监督学习、半监督学习及强化学习. 下面主要讨论监督学习.

在监督学习中, 将输入与输出所有可能取值的集合分别称为**输入空间** (input space) 与**输出空间** (output space).

每个具体的输入是一个实例 (instance), 通常由特征向量 (feature vector) 表示. 这时, 所有特征向量存在的空间称为特征空间 (feature space). 特征空间的每一维对应于一个特征. 有时假设输入空间与特征空间为相同的空间, 对它们不予区分; 有时假设输入空间与特征空间为不同的空间, 将实例从输入空间映射到特征空间. **模型实际上都是定义在特征空间上的**.

在监督学习过程中, 将输入与输出看作是定义在输入 (特征) 空间与输出空间上的随机变量的取值. 输入、输出变量用大写字母表示, 习惯上输入变量写作 $X$，输出变量写作 $Y$. 输入、输出变量所取的值用小写字母表示, 输入变量的取值写作 $x$, 输出变量的取值写作 $y$. 变量可以是标量或向量, 都用相同类型字母表示. 除特别声明外，本书中向量均为列向量，输入实例 $x$ 的特征向量记作

$$
x = (x^{(1)}, x^{(2)}, \cdots, x^{(n)})^T
$$

其中 $x^{(i)}$ 表示 $x$ 的第 $i$ 个特征. 注意, $x^{(i)}$ 与 $x_i$ 不同, 本书通常用 $x_i$ 表示多个输入变量中的第 $i$ 个, 即

$$
x_i = (x_i^{(1)}, x_i^{(2)}, \cdots, x_i^{(n)})^T
$$

监督学习从训练数据 (training data) 集合中学习模型, 对测试数据 (test data) 进行预测. 训练数据由输入 (或特征向量) 与输出对组成, 训练集通常表示为

$$
T = \{(x_1,y_1), (x_2,y_2), \cdots, (x_m,y_m)\}
$$

测试数据也由相应的输入与输出对组成. 输入与输出对又称为样本 (sample) 或样本点.

对预测任务给予不同的名称: 输入变量与输出变量均为连续变量的预测问题称为**回归问题**; 输出变量为有限个离散变量的预测问题称为**分类问题**; 输入变量与输出变量均为变量序列的预测问题称为**标注问题**.

## 模型

监督学习的目的在于学习一个由输入到输出的映射, 这一映射由**模型**来表示. 换句话说, 学习的目的就在于找到最好的这样的模型. 模型属于由输入空间到输出空间的映射的集合, 这个集合就是**假设空间** (hypothesis space). 假设空间的确定意味着学习范围的确定. 假设空间用 $\mathcal{F}$ 表示. 假设空间可以定义为决策函数的集合

$$
\mathcal{F} = \{f:Y = f(X)\}
$$

其中, $X$ 和 $Y$ 是定义在输入空间 $\mathcal{X}$ 和输出空间 $\mathcal{Y}$ 上的变量. 这时 $\mathcal{F}$ 通常是由一个参数向量决定的函数族:

$$
\mathcal{F} = \{f:Y = f_{\theta}(X), \theta \in \mathbb{R}^n\}
$$

参数向量 $\theta$ 取值于 $n$ 维欧氏空间 $\mathbb{R}^n$, 称为**参数空间** (parameter space). 假设空间也可以定义为条件概率的集合

$$
\mathcal{F} = \{P:P(Y|X)\}
$$

其中, $X$ 和 $Y$ 是定义在输入空间 $\mathcal{X}$ 和输出空间 $\mathcal{Y}$ 上的随机变量. 这时 $\mathcal{F}$ 通常是由一个参数向量决定的条件概率分布族:

$$
\mathcal{F} = \{P:P_{\theta}(Y|X), \theta \in \mathbb{R}^n\}
$$

## 策略

有了模型的假设空间, 统计学习接着需要考虑的是按照什么样的准则学习或选择最优的模型. 统计学习的目标在于从假设空间中选取最优模型.

首先引入损失函数与风险函数的概念. 损失函数度量模型一次预测的好坏, 风险函数度量平均意义下模型预测的好坏.

### 1．损失函数和风险函数

监督学习问题是在假设空间 $\mathcal{F}$ 中选取模型 $f$ 作为决策函数, 对于给定的输入$X$，由 $f(X)$ 给出相应的输出 $Y$. 这个输出的预测值 $f(X)$ 与真实值 $Y$ 可能一致也可能不一致, 用一个**损失函数** (loss function) 或**代价函数** (cost function) 来度量预测错误的程度. 损失函数是 $f(X)$ 和 $Y$ 的非负实值函数, 记作 $L(Y,f(X))$.

统计学习常用的损失函数有以下几种:

- 0-1损失函数 (0-1 loss function)

$$
L(Y,f(X)) = \begin{cases}
0 & Y = f(X) \\
1 & Y \neq f(X)
\end{cases}
$$

- 平方损失函数 (quadratic loss function)

$$
L(Y,f(X)) = (Y - f(X))^2
$$

- 绝对损失函数 (absolute loss function)

$$
L(Y,f(X)) = |Y - f(X)|
$$

- 对数损失函数 (logarithmic loss function) 或对数似然损失函数 (loglikelihood loss function)

$$
L(Y,P(Y|X)) = -\log P(Y|X)
$$

损失函数值越小, 模型就越好. 由于模型的输入、输出 (X,Y) 是随机变量, 遵循联合分布 $P(X,Y)$, 所以损失函数的期望是

$$
\mathcal{R}_{\exp}(f) = \mathbf{E}_P [L(Y,f(X))] = \int_{\mathcal{X \times Y}} L(y, f(x))P(x,y) \text{d}x\text{d}y
$$

这是理论上模型 $f(X)$ 关于联合分布 $P(X,Y)$ 的平均意义下的损失, 称为**风险函数** (risk function) 或**期望损失** (expected loss).

学习的目标就是选择期望风险最小的模型. 给定一个训练数据集

$$
T = \{(x_1,y_1), (x_2,y_2), \cdots, (x_m,y_m)\}
$$

模型 $f(X)$ 关于训练数据集的平均损失称为**经验风险** (empirical risk) 或**经验损失** (empirical loss) 记作 $\mathcal{R}_{\text{emp}}$

$$
\mathcal{R}_{\text{emp}}(f) = \frac{1}{m} \displaystyle\sum_{i=1}^m L(y_i, f(x_i))
$$

期望风险 $\mathcal{R}_{\text{exp}}(f)$ 是模型关于联合分布的期望损失, 经验风险 $\mathcal{R}_{\text{emp}}(f)$ 是模型关于训练样本集的平均损失. 根据大数定律, 当样本容量 $m$ 趋于无穷时, 经验风险 $\mathcal{R}_{\text{emp}}(f)$ 趋于期望风险 $\mathcal{R}_{\text{exp}}(f)$. 所以一个很自然的想法是用经验风险估计期望风险. 但是, 由于现实中训练样本数目有限, 便有**经验风险最小化**和**结构风险最小化**.

### 2. 经验风险最小化与结构风险最小化

在假设空间、损失函数以及训练数据集确定的情况下, 经验风险函数式就可以确定. 经验风险最小化 (empirical risk minimization, ERM) 的策略认为, 经验风险最小的模型是最优的模型. 根据这一策略, 按照经验风险最小化求最优模型就是求解最优化问题

$$
\min_{f \in \mathcal{F}} \frac{1}{m} \displaystyle\sum_{i=1}^m L(y_i, f(x_i))
$$

当样本容量足够大时, 经验风险最小化能保证有很好的学习效果, 在现实中被广泛采用. 比如, 极大似然估计 (maximum likelihood estimation) 就是经验风险最小化的一个例子. **当模型是条件概率分布, 损失函数是对数损失函数时, 经验风险最小化就等价于极大似然估计.**

但是, 当样本容量很小时, 经验风险最小化学习的效果就未必很好, 会产生后面将要叙述的“过拟合(over-fitting)”现象.

**结构风险最小化** (structural risk minimization, SRM) 是为了防止过拟合而提出来的策略. 结构风险最小化等价于正则化 (regularization). 结构风险在经验风险上加上表示模型复杂度的正则化项 (regularizer) 或罚项 (penalty term). 在假设空间、损失函数以及训练数据集确定的情况下, 结构风险的定义是

$$
\mathcal{R}_{\text{srm}}(f) = \frac{1}{m} \displaystyle\sum_{i=1}^m L(y_i, f(x_i)) + \lambda J(f)
$$

其中 $J(f)$ 表示模型的复杂度. 是定义在假设空间 $\mathcal{F}$ 上的泛函. 模型 $f$ 越复杂, 复杂度 $J(f)$ 就越大; 反之, 模型 $f$ 越简单，复杂度 $J(f)$ 就越小. 也就是说, 复杂度表示了对复杂模型的惩罚.  $\lambda$ 是系数, 用以权衡经验风险和模型复度. 结构风险小需要经验风险与模型复杂度同时小. 结构风险小的模型往往对训练数据以及未知的测试数据都有较好的预测. 比如, 贝叶斯估计中的最大后验概率估计 (maximum posterior probability estimation, MAP) 就是结构风险最小化的一个例子. **当模型是条件概率分布、损失函数是对数损失函数、模型复杂度由模型的先验概率表示时, 结构风险最小化就等价于最大后验概率估计.**

结构风险最小化的策略认为结构风险最小的模型是最优的模型. 所以求最优模型, 就是求解最优化问题:

$$
\min_{f \in \mathcal{F}} \frac{1}{m} \displaystyle\sum_{i=1}^m L(y_i, f(x_i)) + \lambda J(f)
$$

这样, 监督学习问题就变成了经验风险或结构风险函数的最优化问题. 这时经验或结构风险函数是最优化的目标函数.

### 3. 算法

算法是指学习模型的具体计算方法. 统计学习基于训练数据集, 根据学习策略, 从假设空间中选择最优模型, 最后需要考虑用什么样的计算方法求解最优模型.

这时, 统计学习问题归结为最优化问题, 统计学习的算法成为求解最优化问题的算法. 如果最优化问题有显式的**解析解**, 这个最优化问题就比较简单. 但通常解析解不存在, 这就需要用数值计算的方法求解. 如何保证找到全局最优解, 并使求解的过程非常高效, 就成为一个重要问题. 统计学习可以利用已有的最优化算法, 有时也需要开发独自的最优化算法.

统计学习方法之间的不同, 主要来自其模型、策略、算法的不同. 确定了模型、策略、算法, 统计学习的方法也就确定了. 这也就是将其称为**统计学习三要素**的原因.

通常将学习方法对未知数据的预测能力称为**泛化能力** (generalization ability).

![过拟合判断](https://i.loli.net/2018/09/08/5b93cd67f1861.png)

## 模型选择方法

### 正则化

正则化是结构风险最小化策略的实现, 是在经验风险上加一个正则化项或罚项. 正则化项一般是模型复杂度的单调递增函数, 模型越复杂, 正则化值就越大. 比如, 正则化项可以是模型参数向量的范数.

正则化的作用是选择经验风险与模型复杂度同时较小的模型. 正则化符合奥卡姆剃刀 (Occam's razor) 原理. 奥卡姆剃刀原理应用于模型选择时变为以下想法: 在所有可能选择的模型中, 能够很好地解释已知数据并且十分简单才是最好的模型, 也就是应该选择的模型. 从贝叶斯估计的角度来看, 正则化项对应于模型的先验概率. 可以假设复杂的模型有较小的先验概率, 简单的模型有较大的先验概率.

### 交叉验证

另一种常用的模型选择方法是交叉验证 (cross validation).

如果给定的样本数据充足, 进行模型选择的一种简单方法是随机地将数据集切分成三部分, 分别为训练集 (training set) 、验证集 (validation set) 和测试集 (test set). 训练集用来训练模型, 验证集用于模型的选择, 而测试集用于最终对学习方法的评估. 在学习到的不同复杂度的模型中, 选择对验证集有最小预测误差的模型. 由于验证集有足够多的数据, 用它对模型进行选择也是有效的.

但是，在许多实际应用中数据是不充足的。为了选择好的模型，可以采用交叉验证方法。交叉验证的基本想法是重复地使用数据；把给定的数据进行切分，将切分的数据集组合为训练集与测试集，在此基础上反复地进行训练、测试以及模型选择。

1. 简单交叉验证: 首先随机地将已给数据分为两部分，一部分作为训练集，另一部分作为测试集（例如，$70\%$ 的数据为训练集，$30\%$ 的数据为测试集）；然后用训练集在各种条件下（例如，不同的参数个数）训练模型，从而得到不同的模型；在测试集上评价各个模型的测试误差，选出测试误差最小的模型。
2. 应用最多的是 $S$ 折交叉验证（S-fold cross validation），方法如下：首先随机地将已给数据切分为 $S$ 个互不相交的大小相同的子集；然后利用 $S-1$ 个子集的数据训练模型，利用余下的子集测试模型；将这一过程对可能的S种选择重复进行；最后选出 $S$ 次评测中平均测试误差最小的模型。
3. $S$ 折交叉验证的特殊情形是 $S＝N$，称为留一交叉验证（leave-one-out cross validation），往往在数据缺乏的情况下使用。这里，$N$ 是给定数据集的容量。


## 生成模型和判别模型

监督学习方法又可以分为生成方法（generative approach）和判别方法（discriminative approach）。所学到的模型分别称为**生成模型**（generative model）和**判别模型**（discriminative model）。

生成方法由数据学习联合概率分布 $P(X,Y)$，然后求出条件概率分布 $P(Y|X)$ 作为预测的模型，即生成模型：

这样的方法之所以称为生成方法，是因为模型表示了给定输入 $X$ 产生输出 $Y$ 的生成关系。典型的生成模型有：朴素贝叶斯法和隐马尔可夫模型，将在后面章节进行相关讲述。

判别方法由数据直接学习决策函数 $f(X)$ 或者条件概率分布 $P(Y|X)$ 作为预测的模型，即判别模型。判别方法关心的是对给定的输入 $X$，应该预测什么样的输出 $Y$。典型的判别模型包括：k 近邻法、感知机、决策树、逻辑斯谛回归模型、最大熵模型、支持向量机、提升方法和条件随机场等，将在后面章节讲述。

## 分类问题

分类是监督学习的一个核心问题。在监督学习中，当输出变量 $Y$ 取有限个离散值时，预测问题便成为分类问题。这时，输入变量 $X$ 可以是离散的，也可以是连续的。监督学习从数据中学习一个分类模型或分类决策函数，称为**分类器**（classifier）。分类器对新的输入进行输出的预测（prediction），称为**分类**（classification）。可能的输出称为**类**（class）。分类的类别为多个时，称为多类分类问题。本书主要讨论二类分类问题。

分类问题包括学习和分类两个过程。在学习过程中，根据已知的训练数据集利用有效的学习方法学习一个分类器；在分类过程中，利用学习的分类器对新的输入实例进行分类。

![分类](https://i.loli.net/2018/09/08/5b93d2a171dc4.png)

## 标注问题

**标注**（tagging）也是一个监督学习问题。可以认为标注问题是分类问题的一个推广，标注问题又是更复杂的结构预测（structure prediction）问题的简单形式。标注问题的输入是一个观测序列，输出是一个标记序列或状态序列。标注问题的目标在于学习一个模型，使它能够对观测序列给出标记序列作为预测。注意，可能的标记个数是有限的，但其组合所成的标记序列的个数是依序列长度呈指数级增长的。

标注问题分为学习和标注两个过程。首先给定一个训练数据集 $T =\{(x_i,y_i)\}_{i=1}^m$, 其中 $x_i = (x_i^{(1)}, x_i^{(2)}, \cdots, x_i^{(n)})^T$ 是输入观测序列，$y_i = (y_i^{(1)}, y_i^{(2)}, \cdots, y_i^{(n)})^T$ 是相应的输出标记序列，$n$ 是序列的长度，对不同样本可以有不同的值。学习系统基于训练数据集构建一个模型，表示为条件概率分布：

$$
P(Y^{(1)}, Y^{(2)}, \cdots, Y^{(n)}|X^{(1)}, X^{(2)}, \cdots, X^{(n)})
$$

这里，每一个 $X^{(i)}$ 取值为所有可能的观测，每一个 $Y^{(i)}$ 取值为所有可能的标记，一般 $n＝m$. 标注系统按照学习得到的条件概率分布模型，对新的输入观测序列找到相应的输出标记序列。

![0](https://i.loli.net/2018/09/08/5b93d56265e04.png)

![1](https://i.loli.net/2018/09/08/5b93d5f28b020.png)

## 回归问题

回归（regression）是监督学习的另一个重要问题。回归用于预测输入变量（自变量）和输出变量（因变量）之间的关系，特别是当输入变量的值发生变化时，输出变量的值随之发生的变化。回归模型正是表示从输入变量到输出变量之间映射的函数。

![2](https://i.loli.net/2018/09/08/5b93d67db5b36.png)