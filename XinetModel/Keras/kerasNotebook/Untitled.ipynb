{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def get_dir_names(root):\n",
    "    dir_names = []\n",
    "    for k in os.listdir(root):\n",
    "        if os.path.isdir(root + k):   # 判断是否是目录\n",
    "            dir_names.append(root + k)\n",
    "    return dir_names\n",
    "\n",
    "\n",
    "def split_names(file_names, prob=0.8):\n",
    "    np.random.shuffle(file_names)\n",
    "    size = len(file_names)\n",
    "    m = int(prob * size)\n",
    "    train_names, val_names = file_names[:m], file_names[m:]\n",
    "    return train_names, val_names\n",
    "\n",
    "class Bunch(dict):\n",
    "    def __init__(self, *args, **kwds):\n",
    "        super().__init__(*args, **kwds)\n",
    "        self.__dict__ = self\n",
    "\n",
    "        \n",
    "class FileName:\n",
    "    def __init__(self, root):\n",
    "        self.B = Bunch\n",
    "        self.root = root\n",
    "        self.target_names = os.listdir(self.root)\n",
    "        self.target_dict= self.B({target_name : self.B({\n",
    "            i : self.root + target_name + '/' + name \\\n",
    "            for i, name in enumerate(os.listdir(self.root + target_name))})\n",
    "                            for target_name in self.target_names})\n",
    "        \n",
    "    def split_file_names(self, prob = 0.2):\n",
    "        '''\n",
    "        将训练集随机划分，返回 Bunch 实例\n",
    "        \n",
    "        属性\n",
    "        =======\n",
    "        train_name::训练集的名字\n",
    "        val_name::验证集的名字\n",
    "        '''\n",
    "        train_dict, val_dict = {}, {}\n",
    "        for target_name in self.target_names:\n",
    "            train_dict[target_name], val_dict[target_name] \\\n",
    "            = train_test_split(f.target_dict[target_name], test_size = prob)  \n",
    "        return self.B(train_name = self.B(train_dict), val_name = self.B(val_dict))\n",
    "    \n",
    "    def get_set_size(self, set_name):\n",
    "        '''\n",
    "        示例\n",
    "        =======\n",
    "        bunch = self.split_file_names()\n",
    "        name:: bunch.train_name 或 bunch.val_name\n",
    "        '''\n",
    "        set_size = {}\n",
    "        for target_name in self.target_names:\n",
    "            set_size[target_name] = len(set_name[target_name])\n",
    "        return set_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'D:/MLBook/chapter02/train_corpus_small/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = FileName(root)\n",
    "bunch = f.split_file_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.get_set_size(bunch.train_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f.get_set_size(bunch.val_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'D:/MLBook/chapter02/train_corpus_small/'\n",
    "f = FileName(root)\n",
    "train_names, val_names = f.split_names()\n",
    "train_dict, val_dict = f.split_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "import jieba\n",
    "from sklearn.datasets.base import Bunch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import feature_extraction  \n",
    "from sklearn.feature_extraction.text import TfidfTransformer  \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "\n",
    "from filename import FileName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_class = []\n",
    "for name in z.Z.namelist():\n",
    "    if name.endswith('.txt') or name.endswith('.jpg'):\n",
    "        continue\n",
    "    else:\n",
    "        dir_class.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_annot, test_annot = z.annotated('.txt')\n",
    "train_dict = z.get_train_dict(train_annot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for name in train_dict.keys():\n",
    "    img = z.buffer2array('datasets/train/' + name)\n",
    "    print(img.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "size_dict = z.get_size(train_annot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "df = z.plot_size_dict(size_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bunch = z.sampling(train_annot, 'over')\n",
    "train_bunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_bunch.names['34'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 划分数据集\n",
    "X, Y = np.array(list(trainset.values())).T\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z.get_size(train_bunch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_dict(self, train_annot):\n",
    "        train_dict = {}\n",
    "        for name in train_annot:\n",
    "            K = name.split(' ')\n",
    "            train_dict[K[0]] = K[1]\n",
    "        return train_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_dict = z.get_size(train_dict)\n",
    "size = np.min(list(size_dict.values()))\n",
    "balanced_bunch = z.B(file_names={}, name_dict=train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in train_dict.keys():\n",
    "    name_dir = 'datasets/train/' + name\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "names = list(train_dict.keys())\n",
    "np.random.shuffle(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for name, label in train_dict.items():\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = np.max(list(size_dict.values()))\n",
    "names = list(train_dict.keys())\n",
    "k = size - len(names)\n",
    "if k > 0:\n",
    "    names = np.random.choice(names, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "size_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def oversampling(self, root, train_dict):\n",
    "    size_dict = self.get_size(train_dict)\n",
    "    size = np.max(list(size_dict.values()))\n",
    "    names = list(train_dict.keys())\n",
    "    np.random.shuffle(names)\n",
    "    balanced_bunch = self.B({root + name : train_dict[name] \\\n",
    "                             for name in names[:size] if })\n",
    "    return balanced_bunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
