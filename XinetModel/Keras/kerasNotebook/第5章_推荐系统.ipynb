{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本代码应用 movielens 的数据集，讲解如何利用深度学习构造推荐系统模型。推荐系统的目标函数有很多，比如推荐评分最高的，或者推荐点击率最高的等等。有时候我们还会兼顾推荐内容的多样性。我们在这里讲解的是最根本的基于用户给内容打分的情形。这里的核心思想是对用户和内容建模，从而预测用户对未看过内容的打分。推荐系统进而会把预测的高分内容呈现给用户。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CNTK backend\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dropout, Dense, Reshape\n",
    "from keras.layers.merge import Dot, Concatenate\n",
    "from keras.models import Model, Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "依常规，我们首先得进行探索性分析，看看数据集和评分分布长什么样子的。借此我们还要计算评分稀疏性，因为所有的推荐系统都是基于大量缺失数据的。在这里，我们的思路是预测整个评分表，把缺失数据还原。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6040, 3952, 1000209]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.581564453029317\n"
     ]
    }
   ],
   "source": [
    "ratings = pd.read_csv('./data/ratings.dat', sep = '::', \\\n",
    "    engine='python',names = ['user_id','movie_id','rating','timestamp'])\n",
    "n_users = np.max(ratings['user_id'])\n",
    "n_movies = np.max(ratings['movie_id'])\n",
    "print([n_users, n_movies, len(ratings)])\n",
    "\n",
    "plt.hist(ratings['rating'])\n",
    "plt.show()\n",
    "print(np.mean(ratings['rating']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来我们进行对**用户**和**内容**的建模，使用的是我们熟悉的 Emdbedding 思想。我们使用的 Embedding 维度为128。读者可以自行调整。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Embedding`（嵌入层）是使用在模型第一层的一个网络层，其目的是将所有索引标号映射到紧致的低维向量中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 128    \n",
    "model1 = Sequential()\n",
    "model1.add(Embedding(n_users + 1, k, input_length = 1))\n",
    "model1.add(Reshape((k,)))\n",
    "model2 = Sequential()\n",
    "model2.add(Embedding(n_movies + 1, k, input_length = 1))\n",
    "model2.add(Reshape((k,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Input('embedding_2_input', [#], [1]),\n",
       " Composite(Reshape): Input('embedding_2_input', [#], [1]) -> Output('Reshape21_Output_0', [#], [128]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.input, model2.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们的思路是通过计算用户和内容的向量乘积，得出评分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "m = Dot(axes=1)([model1.output, model2.output])\n",
    "model_output = m\n",
    "model = Model([model1.input, model2.input], model_output)\n",
    "model.compile(loss = 'mse', optimizer = 'adam')\n",
    "#model.compile(loss = 'mse', optimizer = 'rmsprop')\n",
    "#model.compile(loss = 'mse', optimizer = 'adagrad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "准备好训练数据，代入模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = ratings['user_id'].values\n",
    "movies = ratings['movie_id'].values\n",
    "X_train = [users, movies]\n",
    "y_train = ratings['rating'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1000209/1000209 [==============================] - 29s 29us/step - loss: 4.2396\n",
      "Epoch 2/50\n",
      "1000209/1000209 [==============================] - 29s 29us/step - loss: 0.8231\n",
      "Epoch 3/50\n",
      "1000209/1000209 [==============================] - 29s 29us/step - loss: 0.7453\n",
      "Epoch 4/50\n",
      "1000209/1000209 [==============================] - 29s 29us/step - loss: 0.6807\n",
      "Epoch 5/50\n",
      "1000209/1000209 [==============================] - 29s 29us/step - loss: 0.6159\n",
      "Epoch 6/50\n",
      "1000209/1000209 [==============================] - 29s 29us/step - loss: 0.5457\n",
      "Epoch 7/50\n",
      "1000209/1000209 [==============================] - 29s 29us/step - loss: 0.4744\n",
      "Epoch 8/50\n",
      "1000209/1000209 [==============================] - 30s 30us/step - loss: 0.4080\n",
      "Epoch 9/50\n",
      "1000209/1000209 [==============================] - 30s 30us/step - loss: 0.3519\n",
      "Epoch 10/50\n",
      "1000209/1000209 [==============================] - 29s 29us/step - loss: 0.3076\n",
      "Epoch 11/50\n",
      "1000209/1000209 [==============================] - 30s 30us/step - loss: 0.2733\n",
      "Epoch 12/50\n",
      "1000209/1000209 [==============================] - 30s 30us/step - loss: 0.2472\n",
      "Epoch 13/50\n",
      "1000209/1000209 [==============================] - 29s 29us/step - loss: 0.2269\n",
      "Epoch 14/50\n",
      "1000209/1000209 [==============================] - 30s 30us/step - loss: 0.2113\n",
      "Epoch 15/50\n",
      "1000209/1000209 [==============================] - 30s 30us/step - loss: 0.1985\n",
      "Epoch 16/50\n",
      "1000209/1000209 [==============================] - 32s 32us/step - loss: 0.1880\n",
      "Epoch 17/50\n",
      "1000209/1000209 [==============================] - 30s 30us/step - loss: 0.1793\n",
      "Epoch 18/50\n",
      "1000209/1000209 [==============================] - 29s 29us/step - loss: 0.1718\n",
      "Epoch 19/50\n",
      "1000209/1000209 [==============================] - 29s 29us/step - loss: 0.1654\n",
      "Epoch 20/50\n",
      "1000209/1000209 [==============================] - 28s 28us/step - loss: 0.1598\n",
      "Epoch 21/50\n",
      "1000209/1000209 [==============================] - 28s 28us/step - loss: 0.1550\n",
      "Epoch 22/50\n",
      "1000209/1000209 [==============================] - 28s 28us/step - loss: 0.1507\n",
      "Epoch 23/50\n",
      "1000209/1000209 [==============================] - 28s 28us/step - loss: 0.1468\n",
      "Epoch 24/50\n",
      "1000209/1000209 [==============================] - 28s 28us/step - loss: 0.1433\n",
      "Epoch 25/50\n",
      "1000209/1000209 [==============================] - 28s 28us/step - loss: 0.1404\n",
      "Epoch 26/50\n",
      "1000209/1000209 [==============================] - 28s 28us/step - loss: 0.1373\n",
      "Epoch 27/50\n",
      "1000209/1000209 [==============================] - 28s 28us/step - loss: 0.1348\n",
      "Epoch 28/50\n",
      "1000209/1000209 [==============================] - 29s 29us/step - loss: 0.1325\n",
      "Epoch 29/50\n",
      "1000209/1000209 [==============================] - 30s 30us/step - loss: 0.1302\n",
      "Epoch 30/50\n",
      "1000209/1000209 [==============================] - 29s 29us/step - loss: 0.1283\n",
      "Epoch 31/50\n",
      "1000209/1000209 [==============================] - 28s 28us/step - loss: 0.1265\n",
      "Epoch 32/50\n",
      "1000209/1000209 [==============================] - 28s 28us/step - loss: 0.1247\n",
      "Epoch 33/50\n",
      "1000209/1000209 [==============================] - 29s 29us/step - loss: 0.1232\n",
      "Epoch 34/50\n",
      "1000209/1000209 [==============================] - 28s 28us/step - loss: 0.1218\n",
      "Epoch 35/50\n",
      "1000209/1000209 [==============================] - 28s 28us/step - loss: 0.1204\n",
      "Epoch 36/50\n",
      "1000209/1000209 [==============================] - 29s 29us/step - loss: 0.1190\n",
      "Epoch 37/50\n",
      "1000209/1000209 [==============================] - 29s 29us/step - loss: 0.1179\n",
      "Epoch 38/50\n",
      "1000209/1000209 [==============================] - 28s 28us/step - loss: 0.1167\n",
      "Epoch 39/50\n",
      "1000209/1000209 [==============================] - 28s 28us/step - loss: 0.1157\n",
      "Epoch 40/50\n",
      "1000209/1000209 [==============================] - 28s 28us/step - loss: 0.1146\n",
      "Epoch 41/50\n",
      "1000209/1000209 [==============================] - 29s 29us/step - loss: 0.1137\n",
      "Epoch 42/50\n",
      "1000209/1000209 [==============================] - 28s 28us/step - loss: 0.1127\n",
      "Epoch 43/50\n",
      "1000209/1000209 [==============================] - 29s 29us/step - loss: 0.1119\n",
      "Epoch 44/50\n",
      "1000209/1000209 [==============================] - 28s 28us/step - loss: 0.1111\n",
      "Epoch 45/50\n",
      "1000209/1000209 [==============================] - 28s 28us/step - loss: 0.1103\n",
      "Epoch 46/50\n",
      "1000209/1000209 [==============================] - 28s 28us/step - loss: 0.1096\n",
      "Epoch 47/50\n",
      "1000209/1000209 [==============================] - 28s 28us/step - loss: 0.1089\n",
      "Epoch 48/50\n",
      "1000209/1000209 [==============================] - 28s 28us/step - loss: 0.1083\n",
      "Epoch 49/50\n",
      "1000209/1000209 [==============================] - 28s 28us/step - loss: 0.1075\n",
      "Epoch 50/50\n",
      "1000209/1000209 [==============================] - 28s 28us/step - loss: 0.1069\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2bb288c7f98>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size = 500, epochs = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们看下模型预测效果。注意到我们这里作为演示，只做了模型拟合程度，读者可以把原始数据集分成训练，校对和测试数据集，评估模型准确率。我们这里看一个例子，预测第 `10` 号用户对第 `99` 号内容的打分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=10\n",
    "j=99\n",
    "pred = model.predict([np.array([users[i]]), np.array([movies[j]])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.25138307]]\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们计算模型在训练数据集上的均方差。这告诉我们拟合程度的好坏。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000209/1000209 [==============================] - 23s 23us/step\n",
      "0.0862701111813\n"
     ]
    }
   ],
   "source": [
    "mse = model.evaluate(x=X_train, y = y_train, batch_size=128)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们接下来构建深度学习模型。这里的想法与上述稍微不同。我们把用户和内容的 Embedding 合并在一起（concatenate)，作为输入层，然后通过网络模型提取一层层特征，最后用线性变换得出预测评分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 128\n",
    "input_1 = Input(shape=(1,))\n",
    "model1 = Embedding(n_users + 1, k, input_length = 1)(input_1)\n",
    "model1 = Reshape((k,))(model1)\n",
    "input_2 = Input(shape=(1,))\n",
    "model2 = Embedding(n_movies + 1, k, input_length = 1)(input_2)\n",
    "model2 = Reshape((k,))(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Input('input_1', [#], [1]),\n",
       " Input('input_2', [#], [1]),\n",
       " Composite(Reshape): Input('input_1', [#], [1]) -> Output('Reshape450_Output_0', [#], [128]),\n",
       " Composite(Reshape): Input('input_2', [#], [1]) -> Output('Reshape460_Output_0', [#], [128]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_1,input_2, model1,model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Concatenate()([model1, model2])\n",
    "model = Dropout(0.2)(model)\n",
    "model = Dense(k, activation = 'relu')(model)\n",
    "model = Dropout(0.5)(model)\n",
    "model = Dense(int(k/4), activation = 'relu')(model)\n",
    "model = Dropout(0.5)(model)\n",
    "model = Dense(int(k/16), activation = 'relu')(model)\n",
    "model = Dropout(0.5)(model)\n",
    "yhat = Dense(1, activation = 'linear')(model)\n",
    "model = Model([input_1, input_2], yhat)\n",
    "model.compile(loss = 'mse', optimizer = \"adam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "和之前一样，我们准备好训练数据集，代入模型训练。并通过均方差计算模型的拟合程度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = ratings['user_id'].values\n",
    "movies = ratings['movie_id'].values\n",
    "label = ratings['rating'].values\n",
    "X_train = [users, movies]\n",
    "y_train = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1000209/1000209 [==============================] - 20s 20us/step - loss: 3.8554\n",
      "Epoch 2/50\n",
      "1000209/1000209 [==============================] - 20s 20us/step - loss: 2.1430\n",
      "Epoch 3/50\n",
      "1000209/1000209 [==============================] - 20s 20us/step - loss: 1.4905\n",
      "Epoch 4/50\n",
      "1000209/1000209 [==============================] - 24s 24us/step - loss: 1.1942 0s - loss: 1.\n",
      "Epoch 5/50\n",
      "1000209/1000209 [==============================] - 22s 22us/step - loss: 1.0134\n",
      "Epoch 6/50\n",
      "1000209/1000209 [==============================] - 22s 22us/step - loss: 0.9326\n",
      "Epoch 7/50\n",
      "1000209/1000209 [==============================] - 20s 20us/step - loss: 0.9102\n",
      "Epoch 8/50\n",
      "1000209/1000209 [==============================] - 20s 20us/step - loss: 0.9028\n",
      "Epoch 9/50\n",
      "1000209/1000209 [==============================] - 20s 20us/step - loss: 0.8967\n",
      "Epoch 10/50\n",
      "1000209/1000209 [==============================] - 20s 20us/step - loss: 0.8925\n",
      "Epoch 11/50\n",
      "1000209/1000209 [==============================] - 21s 21us/step - loss: 0.8872\n",
      "Epoch 12/50\n",
      "1000209/1000209 [==============================] - 21s 21us/step - loss: 0.8831\n",
      "Epoch 13/50\n",
      "1000209/1000209 [==============================] - 25s 25us/step - loss: 0.8808\n",
      "Epoch 14/50\n",
      "1000209/1000209 [==============================] - 23s 23us/step - loss: 0.8769\n",
      "Epoch 15/50\n",
      "1000209/1000209 [==============================] - 22s 22us/step - loss: 0.8750\n",
      "Epoch 16/50\n",
      "1000209/1000209 [==============================] - 20s 20us/step - loss: 0.8706\n",
      "Epoch 17/50\n",
      "1000209/1000209 [==============================] - 20s 20us/step - loss: 0.8695 \n",
      "Epoch 18/50\n",
      "1000209/1000209 [==============================] - 21s 21us/step - loss: 0.8675\n",
      "Epoch 19/50\n",
      "1000209/1000209 [==============================] - 20s 20us/step - loss: 0.8640\n",
      "Epoch 20/50\n",
      "1000209/1000209 [==============================] - 21s 21us/step - loss: 0.8620\n",
      "Epoch 21/50\n",
      "1000209/1000209 [==============================] - 22s 22us/step - loss: 0.8605\n",
      "Epoch 22/50\n",
      "1000209/1000209 [==============================] - 21s 21us/step - loss: 0.8586 0s - loss: 0.\n",
      "Epoch 23/50\n",
      "1000209/1000209 [==============================] - 22s 22us/step - loss: 0.8567\n",
      "Epoch 24/50\n",
      "1000209/1000209 [==============================] - 20s 20us/step - loss: 0.8549\n",
      "Epoch 25/50\n",
      "1000209/1000209 [==============================] - 23s 23us/step - loss: 0.8519\n",
      "Epoch 26/50\n",
      "1000209/1000209 [==============================] - 19s 19us/step - loss: 0.8518\n",
      "Epoch 27/50\n",
      "1000209/1000209 [==============================] - 19s 19us/step - loss: 0.8496\n",
      "Epoch 28/50\n",
      "1000209/1000209 [==============================] - 20s 20us/step - loss: 0.8484\n",
      "Epoch 29/50\n",
      "1000209/1000209 [==============================] - 20s 20us/step - loss: 0.8462\n",
      "Epoch 30/50\n",
      "1000209/1000209 [==============================] - 19s 19us/step - loss: 0.8443\n",
      "Epoch 31/50\n",
      "1000209/1000209 [==============================] - 19s 19us/step - loss: 0.8439\n",
      "Epoch 32/50\n",
      "1000209/1000209 [==============================] - 19s 19us/step - loss: 0.8427\n",
      "Epoch 33/50\n",
      "1000209/1000209 [==============================] - 20s 20us/step - loss: 0.8396\n",
      "Epoch 34/50\n",
      "1000209/1000209 [==============================] - 19s 19us/step - loss: 0.8390\n",
      "Epoch 35/50\n",
      "1000209/1000209 [==============================] - 20s 20us/step - loss: 0.8369\n",
      "Epoch 36/50\n",
      "1000209/1000209 [==============================] - 19s 19us/step - loss: 0.8356\n",
      "Epoch 37/50\n",
      "1000209/1000209 [==============================] - 19s 19us/step - loss: 0.8355\n",
      "Epoch 38/50\n",
      "1000209/1000209 [==============================] - 20s 20us/step - loss: 0.8333\n",
      "Epoch 39/50\n",
      "1000209/1000209 [==============================] - 19s 19us/step - loss: 0.8324\n",
      "Epoch 40/50\n",
      "1000209/1000209 [==============================] - 19s 19us/step - loss: 0.8324\n",
      "Epoch 41/50\n",
      "1000209/1000209 [==============================] - 20s 20us/step - loss: 0.8302\n",
      "Epoch 42/50\n",
      "1000209/1000209 [==============================] - 20s 20us/step - loss: 0.8284\n",
      "Epoch 43/50\n",
      "1000209/1000209 [==============================] - 21s 21us/step - loss: 0.8275\n",
      "Epoch 44/50\n",
      "1000209/1000209 [==============================] - 22s 22us/step - loss: 0.8258 0s - l\n",
      "Epoch 45/50\n",
      "1000209/1000209 [==============================] - 20s 20us/step - loss: 0.8265\n",
      "Epoch 46/50\n",
      "1000209/1000209 [==============================] - 21s 21us/step - loss: 0.8252\n",
      "Epoch 47/50\n",
      "1000209/1000209 [==============================] - 20s 20us/step - loss: 0.8238\n",
      "Epoch 48/50\n",
      "1000209/1000209 [==============================] - 21s 21us/step - loss: 0.8235\n",
      "Epoch 49/50\n",
      "1000209/1000209 [==============================] - 20s 20us/step - loss: 0.8212\n",
      "Epoch 50/50\n",
      "1000209/1000209 [==============================] - 21s 21us/step - loss: 0.8207\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2bb289b94a8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size = 1000, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000209/1000209 [==============================] - 33s 33us/step\n",
      "0.682069986752\n"
     ]
    }
   ],
   "source": [
    "i,j = 10,99\n",
    "pred = model.predict([np.array([users[i]]), np.array([movies[j]])])\n",
    "\n",
    "mse = model.evaluate(x=X_train, y=y_train, batch_size=128)\n",
    "print(mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
