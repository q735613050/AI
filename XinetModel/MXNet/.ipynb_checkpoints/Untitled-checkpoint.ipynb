{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('E:/xinlib')\n",
    "import xcv\n",
    "\n",
    "from xcv import LoaderImage, Trainer\n",
    "from mxnet.gluon.data.vision import transforms\n",
    "\n",
    "from mxnet import nd\n",
    "from datax.tabx import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_pytables_version'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-8dfe2a69123e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtables\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\tables\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;31m# Necessary imports to get versions stored on the cython extension\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m from .utilsextension import (\n\u001b[0m\u001b[0;32m     94\u001b[0m     \u001b[0mget_pytables_version\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_hdf5_version\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblosc_compressor_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[0mblosc_compcode_to_compname_\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mblosc_compcode_to_compname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'get_pytables_version'"
     ]
    }
   ],
   "source": [
    "import tables as tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loader(DataLoader):\n",
    "    '''\n",
    "    name in ['cifar10', 'cifar100', 'fashion_mnist', 'mnist', 'boston_housing']\n",
    "    将 HDF5 数据库中的数据集转换为迭代器。\n",
    "    在采用 MXNet 训练结束后，需要运行 `myh5.close()` 关闭数据库。\n",
    "    '''\n",
    "\n",
    "    def __init__(self,\n",
    "                 name,\n",
    "                 temp_name,\n",
    "                 ctx=try_gpu(),\n",
    "                 source='E:/Data/HDF5/xindatasets.h5'):\n",
    "        super().__init__(name, temp_name=temp_name, source=source)\n",
    "        self.ctx = ctx\n",
    "\n",
    "    def get_dataset(self, batch_size, is_augs=False, *args):\n",
    "        '''\n",
    "        return：train_iter, valid_iter, test_iter\n",
    "        is_augs = False：不使用数据增强，且无需传入 `*args` 参数\n",
    "        args = [crop_size, *resize_list]：crop_size 是 int, resize_list 是 int 列表 或者 None\n",
    "        '''\n",
    "        train_iter, valid_iter = self.get_iter(batch_size)\n",
    "        if is_augs == False:\n",
    "            train_iter = data_iter(train_iter)\n",
    "            valid_iter = data_iter(valid_iter)\n",
    "        elif is_augs == True:\n",
    "            train_iter = data_iter(train_iter, 'train', *args)\n",
    "            valid_iter = data_iter(valid_iter, 'valid', *args)\n",
    "        return train_iter, valid_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(Loader):\n",
    "    '''\n",
    "    name in ['cifar10', 'cifar100', 'fashion_mnist', 'mnist', 'boston_housing']\n",
    "    将 HDF5 数据库中的数据集转换为迭代器。\n",
    "    在采用 MXNet 训练结束后，需要运行 `myh5.close()` 关闭数据库。\n",
    "    '''\n",
    "\n",
    "    def __init__(self,\n",
    "                 name,\n",
    "                 temp_name,\n",
    "                 net,\n",
    "                 ctx=try_gpu(),\n",
    "                 source='E:/Data/HDF5/xindatasets.h5'):\n",
    "        super().__init__(name, temp_name, source)\n",
    "        self.ctx = ctx\n",
    "        self.dataDtype = name\n",
    "        self.logdir = 'D:/logs'\n",
    "        self.log_interval = 200\n",
    "        self.net = net\n",
    "        self.metric = mx.metric.Accuracy()\n",
    "        self.sw = SummaryWriter(self.logdir, flush_secs=20)\n",
    "\n",
    "    def test(self, val_data):\n",
    "        metric = mx.metric.Accuracy()\n",
    "        for data, label in val_data:\n",
    "            data = data.as_in_context(self.ctx)\n",
    "            label = label.as_in_context(self.ctx)\n",
    "            output = self.net(data)\n",
    "            metric.update([label], [output])\n",
    "        return metric.get()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
