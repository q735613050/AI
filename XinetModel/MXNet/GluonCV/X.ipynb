{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T08:50:00.459273Z",
     "start_time": "2018-10-07T08:49:36.358676Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('E:/zlab/')\n",
    "from loader import Loader\n",
    "# ----------------\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tables as tb\n",
    "import mxnet as mx\n",
    "from mxnet import nd, autograd, gluon\n",
    "import gluonbook as gb\n",
    "from mxnet import gluon, init, nd\n",
    "from mxnet.gluon import data as gdata, loss as gloss, model_zoo, nn\n",
    "from sklearn.semi_supervised.label_propagation import LabelSpreading\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from mxboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 载入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T08:50:00.547038Z",
     "start_time": "2018-10-07T08:50:00.462276Z"
    }
   },
   "outputs": [],
   "source": [
    "import tables as tb\n",
    "\n",
    "h5 = tb.open_file('E:/xdata/X.h5')\n",
    "#h5 = tb.open_file('./X.h5')\n",
    "\n",
    "data = h5.root.cifar10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T08:50:03.097729Z",
     "start_time": "2018-10-07T08:50:00.549033Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.trainX[:]\n",
    "y = data.trainY[:]\n",
    "X_train, X_unlabel, y_train, y_unlabel = train_test_split(\n",
    "    X, y, test_size=0.98, random_state=42)\n",
    "\n",
    "batch_size = 32\n",
    "trainset = Loader(batch_size, X_train, y_train, shuffle=True, name='train')\n",
    "testset = Loader(\n",
    "    batch_size, data.testX, data.testY, shuffle=False, name='test')\n",
    "unlabelset = Loader(\n",
    "    batch_size,\n",
    "    X_unlabel[:10000],\n",
    "    y_unlabel[:10000],\n",
    "    shuffle=False,\n",
    "    name='agent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T08:50:04.069133Z",
     "start_time": "2018-10-07T08:50:03.099724Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for imgs, labels in iter(trainset):\n",
    "    trainset.show_imgs(data.label_names, imgs.astype(np.uint8), labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型的配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T08:50:04.664546Z",
     "start_time": "2018-10-07T08:50:04.101048Z"
    }
   },
   "outputs": [],
   "source": [
    "class SemiModel(nn.HybridBlock):\n",
    "    def __init__(self, features, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.features = features\n",
    "        self.output = nn.Dense(10)\n",
    "        \n",
    "    def hybrid_forward(self, F, x):\n",
    "        x = self.features(x)\n",
    "        return self.output(x)\n",
    "\n",
    "pretrain_net = model_zoo.vision.resnet50_v2(pretrained=False)\n",
    "net = SemiModel(pretrain_net.features)\n",
    "\n",
    "# 网络预设\n",
    "_net = model_zoo.vision.resnet50_v2(pretrained=True)\n",
    "net.features = _net.features\n",
    "#net.features.add(nn.Flatten())\n",
    "#net.features[-1].initialize(init.Xavier(magnitude=2.24))\n",
    "net.output.initialize(init.Xavier(magnitude=2.24))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型超参数设定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T08:50:09.785856Z",
     "start_time": "2018-10-07T08:50:04.667535Z"
    }
   },
   "outputs": [],
   "source": [
    "from xtrain import XModel\n",
    "\n",
    "# 超参数设定\n",
    "epochs = 500\n",
    "learning_rate = 0.1\n",
    "model = XModel(learning_rate)\n",
    "ctx = model.ctx\n",
    "print('training on', ctx)\n",
    "net.collect_params().reset_ctx(ctx)\n",
    "net.hybridize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据打包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T08:50:27.135495Z",
     "start_time": "2018-10-07T08:50:09.789845Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class DataLoader(dict):\n",
    "    def __init__(self, ctx, batch_size, trainset, unlabelset, *args, **kwargs):\n",
    "        '''\n",
    "        初始化数据迭代器和标签传播算法\n",
    "        '''\n",
    "        self.__dict__ = self\n",
    "        self.ctx = ctx\n",
    "        self.train = trainset\n",
    "        self.unlabel = unlabelset\n",
    "        self.X_l = Loader(\n",
    "            batch_size, self.train.X, shuffle=False, name='x_train')\n",
    "        self.X_u = Loader(\n",
    "            batch_size, self.unlabel.X, shuffle=False, name='x_test')\n",
    "        self.features_u = self.unlabel.X.reshape((-1, 32 * 32 * 3))\n",
    "        self.features_l = self.train.X.reshape((-1, 32 * 32 * 3))\n",
    "        _min_max_scaler = MinMaxScaler()\n",
    "        self.features_l = _min_max_scaler.fit_transform(self.features_l)\n",
    "        self.features_u = _min_max_scaler.transform(self.features_u)\n",
    "        self.y_agent = -np.ones_like(self.unlabel.Y)\n",
    "        self._lbp = LabelSpreading(gamma=0.007, n_jobs=-1, max_iter=100)\n",
    "        self.ssl()\n",
    "\n",
    "    def ssl(self):\n",
    "        '''\n",
    "        标签传播\n",
    "        '''\n",
    "        X = np.concatenate([self.features_l, self.features_u])\n",
    "        y_ = np.concatenate([trainset.Y, self.y_agent])\n",
    "        self._lbp.fit(X, y_)  # 必须将 X 缩放到 [0,1]\n",
    "        self.y_hats = self._lbp.transduction_[self.train.Y.shape[0]:]\n",
    "        \n",
    "        if np.unique(self.y_hats).size == 10:\n",
    "            print('分类指标：')\n",
    "            print(classification_report(self.unlabel.Y, self.y_hats))\n",
    "        else:\n",
    "            print('SSL 失败！')\n",
    "\n",
    "    def get_features(self, net, data_iter):\n",
    "        for x in data_iter:\n",
    "            x = nd.array(x, ctx=self.ctx).transpose((0, 3, 1, 2))\n",
    "            features = net.features(x)\n",
    "            yield features\n",
    "\n",
    "    def agent(self, net):\n",
    "        '''\n",
    "        net:: 神经网络\n",
    "        inference::输出 net 的 features\n",
    "        '''\n",
    "        # 提取有标签数据的特征\n",
    "        self.features_l = np.concatenate(\n",
    "            [f.asnumpy() for f in dataset.get_features(net, dataset.X_l)]).astype(np.uint8)\n",
    "        # 提取无标签数据的特征\n",
    "        self.features_u = np.concatenate(\n",
    "            [f.asnumpy() for f in dataset.get_features(net, dataset.X_u)]).astype(np.uint8)\n",
    "        self.ssl()\n",
    "        self.agency_acc = accuracy_score(dataset.unlabel.Y, self.y_hats)\n",
    "\n",
    "dataset = DataLoader(ctx, batch_size, trainset, unlabelset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练和调优"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-10-07T08:49:43.239Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logdir = 'D:/graph/'\n",
    "sw = SummaryWriter(logdir, flush_secs=5)  # 可视化\n",
    "y_pre = dataset.y_hats  # 微调前的预测标签\n",
    "dataset.agent(net)\n",
    "sw.add_scalar('accuracy_curves',\n",
    "              {unlabelset.name + '_SSL': dataset.agency_acc}, 0)\n",
    "epoch = 1\n",
    "while epoch < 100:\n",
    "    print('微调带有代理标签数据')\n",
    "    print('~_~' * 25)\n",
    "    X_u_set = Loader(\n",
    "        batch_size,\n",
    "        dataset.unlabel.X,\n",
    "        dataset.y_hats,\n",
    "        shuffle=True,\n",
    "        name='train_agent')\n",
    "    net = model.train(net, X_u_set, testset, epochs=1, start=epoch)\n",
    "    dataset.agent(net)\n",
    "    dataset.y_agent = y_pre\n",
    "    dataset.y_agent[dataset.y_hats != y_pre] = -1\n",
    "    sw.add_scalar('accuracy_curves',\n",
    "                  {unlabelset.name + '_SSL': dataset.agency_acc}, epoch)\n",
    "    if -1 in dataset.y_agent:\n",
    "        print(unlabelset.name + '_SSL: ', dataset.agency_acc)\n",
    "        print('-_' * 50)\n",
    "        print('微调有标签数据')\n",
    "        epoch += 1\n",
    "        net = model.train(net, dataset.train, testset, epochs=10, start=epoch)\n",
    "        dataset.agent(net)\n",
    "        dataset.y_agent = y_pre\n",
    "        dataset.y_agent[dataset.y_hats != y_pre] = -1\n",
    "        sw.add_scalar('accuracy_curves',\n",
    "                      {unlabelset.name + '_SSL': dataset.agency_acc}, epoch)\n",
    "        epoch += 10\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-07T05:49:37.716617Z",
     "start_time": "2018-10-07T05:40:59.577142Z"
    }
   },
   "source": [
    "logdir = 'D:/graph/'\n",
    "sw = SummaryWriter(logdir, flush_secs=5)  # 可视化\n",
    "for epoch in range(1, epochs, 20):\n",
    "    if epoch == 1:\n",
    "        n = 5\n",
    "    else:\n",
    "        n = 10\n",
    "    # 训练带有代理标签的数据\n",
    "    print('~_~' * 25)\n",
    "    print('微调带有代理标签数据')\n",
    "    y_pre = dataset.y_hats  # 微调前的预测标签\n",
    "    X_u_set = Loader(\n",
    "        batch_size, dataset.unlabel.X, dataset.y_hats, shuffle=True, name='train_agent')\n",
    "    net = model.train(net, X_u_set, testset, epochs=n, start=epoch)\n",
    "    \n",
    "    dataset.agent(net)\n",
    "    sw.add_scalar('accuracy_curves', {unlabelset.name+'_SSL': dataset.agency_acc}, epoch)\n",
    "    y_back_u = dataset.y_hats  # 微调后的预测标签\n",
    "    # 训练有标签数据\n",
    "    print('-_' * 50)\n",
    "    print('微调有标签数据')\n",
    "    net = model.train(net, dataset.train, dataset.unlabel, epochs=10, start=epoch+n)\n",
    "    print('\\nSSL:')\n",
    "    dataset.agent(net)\n",
    "    sw.add_scalar('accuracy_curves', {unlabelset.name+'_SL': dataset.agency_acc}, epoch)\n",
    "    y_back_l = dataset.y_hats\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
