{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**特征选择**是选取重要的特征子集，**特征提取**则由原始输入形成较少的新特征，理想情况下，无论是分类还是回归，我们不应该将特征选择或特征提取作为一个单独的进程，分类或者回归方法应该能够利用任何必要的特征，而丢弃不相关的特征。但是，考虑到算法存储量和时间的复杂度，或者输入不必要的特征等原因，还是需要降维。较简单的模型在小数据上更为鲁棒，有小方差，模型的变化更依赖于样本的特殊性，包括噪声，离群点等。同时，低纬度描述数据，方便我们队数据绘图，可视化分析数据结构和离群点。\n",
    "\n",
    "按监督和非监督分为： \n",
    "- 非监督：PCA、FA、LLE\n",
    "- 监督：LDA、MDS \n",
    "\n",
    "其中，PCA、FA、MDS、LDA，都是线性投影方法，非线性维度规约有等距特征映射，局部线性嵌入 LLE。\n",
    "\n",
    "**维度归约**使用数据编码或变换，以便得到原数据的归约或“压缩”表示。如果原数据可以由压缩数据重新构造而不丢失任何信息，则该数据归约是**无损的**。如果我们只能重新构造原数据的近似表示，则该数据归约是**有损的**。\n",
    "\n",
    "# 特征选择，即子集选择\n",
    "\n",
    "在子集选择中，我们选择最佳子集，其含的维度最少，但对正确率的贡献最大。在维度较大时，采用启发式方法，在合理的时间内得到一个合理解（但不是最优解）。维度较小时，对所有子集做检验。\n",
    "\n",
    "有两种方法:\n",
    "- **向前选择**，即从空集开始逐渐增加特征，每次添加一个降低误差最多的变量，直到进一步添加不会降低误差或者降低很少。同时，可以用浮动搜索，每一步可以改变增加和去掉的特征数量，以此来加速。\n",
    "- **向后选择**，从所有变量开始，逐个排除他们，每次排除一个降低误差最多的变量，直到进一步的排除会显著提高误差。如果我们预料有许多无用特征时，向前选择更可取。 \n",
    "\n",
    "在两种情况下，误差检测都应在不同于训练集的验证集上做，因为我们想要检验泛化准确率。使用更多的特征，我们一般会有更低的训练误差，但不一定有更低的验证误差。 \n",
    "\n",
    "像人脸识别这样的应用中，特征选择不是很好的降维方法，因为个体像素本身并不携带很多识别信息，携带脸部识别信息的是许多像素值的组合。这可以用特征提取来归约。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
